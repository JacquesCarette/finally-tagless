\documentclass{elsart}

% Reduce display spacing
\divide\abovedisplayskip 2
\divide\belowdisplayskip 2
\divide\abovedisplayshortskip 2
\divide\belowdisplayshortskip 2

\usepackage{hyphenat}
\usepackage{comment}
\usepackage{amsmath,amssymb}
\usepackage{amstext}
\usepackage{url}
\usepackage[dvips]{color}

\usepackage{ifpdf}
\ifpdf
    \pdfpageheight=11in
    \pdfpagewidth=8.5in
\fi

%\usepackage{refrange}

%\usepackage[medium,compact]{titlesec}

\usepackage{fancyvrb}
\DefineShortVerb{\|}
\DefineVerbatimEnvironment{code}{Verbatim}{xleftmargin=\ourmathindent,commandchars=\\\{\},fontsize=\small}
\DefineVerbatimEnvironment{code2}{Verbatim}{xleftmargin=\ourmathindent,commandchars=\\\{\},fontsize=\scriptsize}
\newcommand{\evalresult}[1]{\ensuremath{\Longrightarrow}\textcolor{red}{#1}}
% \setlength{\parskip}{0pt}
\parskip=0pt
\newlength{\ourmathindent}
\setlength{\ourmathindent}{1em}

% \usepackage[backref,colorlinks,bookmarks=true]{hyperref}

% Reduce list spacing
%% \makeatletter
%% \renewcommand\@@listI{\leftmargin\leftmargini
%% \parsep \z@@
%% \topsep 3\p@@ \@@plus\p@@ \@@minus 2\p@@
%% \itemsep 2\p@@ \@@plus\p@@ \@@minus\p@@}
%% \let\@@listi\@@listI
%% \@@listi
%% \makeatother

% \parskip 0pt plus 1pt minus 2pt
\textfloatsep 4pt plus 2pt minus 3pt % Less space around figures
%\abovecaptionskip 0pt plus 0pt minus 2pt
%\belowcaptionskip 0pt plus 0pt minus 2pt

% \intextsep 2pt plus 0pt minus 1pt

\renewcommand\floatpagefraction{.95}
\renewcommand\topfraction{.95}
\renewcommand\bottomfraction{.95}
\renewcommand\textfraction{.05}   
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}

\newcommand{\omitnow}[1]{}
\newcommand{\oleg}[1]{{\it [Oleg says: #1]}}
\newcommand{\jacques}[1]{{\it [Jacques says: #1]}}

%
% Useful abbreviations
%
\newcommand{\floats}{\mathbb{F}}
\newcommand{\reals}{\mathbb{R}}

\journal{Science of Computer Programming}

\begin{document}
%\title{Functors, CPS and monads, or how to generate efficient
%code from abstract designs}
\begin{frontmatter}
\title{Multi-stage programming with functors and monads:
eliminating abstraction overhead from generic code}
\author{Jacques Carette\thanksref{1}}
\address{McMaster University,
1280 Main St. West, Hamilton, Ontario Canada L8S 4K1}
\ead{carette@mcmaster.ca}
\ead[url]{http://www.cas.mcmaster.ca/\textasciitilde carette}
\author{Oleg Kiselyov}
\address{FNMOC, Monterey, CA 93943}
\ead{oleg@pobox.com}
\ead[url]{http://pobox.com/\textasciitilde oleg/ftp/}

\hyphenation{ne-ces-sa-ry}
\hyphenation{ana-lysis theo-ry}

\thanks[1]{Supported in part by NSERC Discovery Grant RPG262084-03.}

\begin{abstract}
We use multi-stage programming, monads and Ocaml's
advanced module system to demonstrate how to eliminate all
abstraction overhead while avoiding any inspection of the resulting
code.  We demonstrate this clearly with LU decomposition as a 
representative family of symbolic and numeric algorithms. 
We parameterize our code to a great extent --
over domain, input and permutation matrix representations, 
determinant and rank tracking, 
pivoting policies, result types, etc. -- at no run-time cost.  Because
the resulting code is generated just right and not changed afterwards,
MetaOCaml guarantees that the generated code is well-typed.
We further demonstrate that various abstraction parameters (aspects)
can be made orthogonal and compositional, even in the presence of
name-generation for temporaries, and 
``interleaving'' of aspects.  We also show how to encode some
domain-specific knowledge so that ``clearly wrong'' compositions can
be rejected at or before generation time, rather than during
the compilation or running of the generated code.
\end{abstract}

\begin{keyword}
MetaOCaml \sep linear algebra \sep genericity \sep generative \sep staging
\sep Functor \sep symbolic.
\end{keyword}
% Should use either PACS or MSC scheme
\end{frontmatter}

\section{Introduction}

In high-performance symbolic and numeric computing, there is a
well-known issue of balancing between maximal performance and the
level of abstraction at which code is written. Widely used Gaussian
Elimination (GE) -- the running example of our paper -- is typically
presented in textbooks as a closely related family of algorithms for
solving simultaneous linear equations, LU matrix decomposition, and
computing the determinant and the rank of a matrix. All members of
the family share the same pattern of applying elementary row
operations to rows of the matrix in a particular order. The individual
algorithms differ in their output, in application of pivoting, in
algebraic domain and the use of full division. Modern architectures
demand further divisions of the family for particular matrix layouts, e.g.,
sparsed or tiled.

A survey \cite{Carette06} of
Gaussian elimination implementations in the industrial package Maple
\cite{Monagan:2001:M7P}
found 6 clearly identifiable aspects and 35 different implementations of the
algorithm, as well as 45 implementations of directly related
algorithms such as Cholesky decomposition, and so on.  We could
manually write each of these implementations optimizing for particular aspects
and using cut-and-paste to ``share'' similar pieces of code.
Or we can write a very generic procedure that accounts for
all the aspects with appropriate abstractions \cite{Gruntz:1994:IG,Axiom}. The
abstraction mechanisms however -- be they procedure, method or a
function call -- have a significant cost, especially for
high-performance numerical computing \cite{Carette06}. Eliminating
this abstraction overhead involves either complex analyses or
domain-specific knowledge (or both!)
\cite{Kennedy01Telescoping,Veldhuizen:2004,scp-CohenDGHKP06},
and so we can not rely on a general
purpose compiler to assuredly perform such optimizations 

A more appealing approach is generative programming
\cite{Czarnecki,Veldhuizen:1998:ISCOPE,musser89generic,musser94algorithmoriented,BOOST,POOMA,ATLAS}.
The approach is not without problems, e.g., making sure that the
generated code is well-formed. This is a challenge in string-based
generation systems, which generally do not offer any guarantees and
therefore make it very difficult to determine which part of the
generator is at fault when the generated code cannot be parsed. Other
problems are preventing accidental variable capture (so-called hygiene
\cite{HygienicMacros}) and ensuring the generated code is
well-typed. Lisp-style macros, Scheme hygienic macros, the camlp4
preprocessor \cite{camlp4}, C++ template meta-programming, and Template
Haskell \cite{conf/dagstuhl/CzarneckiOST03} solve some of the above
problems. Of the widely available maintainable languages, only
MetaOCaml \cite{CTHL03,metaocaml-org}  solves all the above problems
including the well-typing of both the generator and 
the generated code \cite{TahaSheard97,TahaThesis}.

But more difficult problems remain. Is the generated code optimal? Do
we still need post-processing to eliminate common subexpressions,
fold constants, and remove redundant bindings? Is the generator readable?
Does it bear resemblance to the original algorithm? Is the generator
extensible? Are the aspects truly modular? Can we add another aspect or
another instance of the existing aspect without affecting the existing ones?
Finally, can we express domain-specific knowledge (for instance one should not
attempt to use full division when dealing with matrices of exact integers, nor
is it worthwhile to use full pivoting on a matrix over $\mathbb Q$)?

MetaOCaml is purely \emph{generative}: generated code can only be treated as
a black box: in other words, it cannot be inspected and it cannot be
post-processed (i.e., no intensional analysis). This approach gives a stronger
equational theory \cite{Taha2000}, and avoids the danger of creating
unsoundness \cite{TahaThesis}. Furthermore, intensional code analysis
essentially requires one to insert both an optimizing compiler and an
automated theorem proving system into the code generating system
\cite{Pueschel:05,Kennedy01Telescoping,dongarra7,Veldhuizen:2004}.
While this is potentially extremely powerful and an exciting area of
research, it is also extremely complex, which means that it is
currently more error-prone and difficult to ascertain the correctness
of the resulting code.

Therefore, in MetaOCaml, code must be generated just right (see
\cite{TahaThesis} for many simple examples).  For more complex
examples, new techniques are necessary, e.g., abstract interpretation
\cite{KiselyovTaha}.  But more problems remain
\cite{scp-CohenDGHKP06}: generating binding forms (``names'')
when generating loop bodies or conditional branches, and making
continuation-passing style (CPS) code clear.  Many authors
understandably shy away from CPS code as it quickly becomes
unreadable.  But this is needed for proper name generation.
To be able to build modular code generators, three important problems
remain: compositionality, expressing dependencies, and integration of
domain-specific knowledge.

In this paper, we report on our continued progress \cite{CaretteKiselyov05}%
\footnote{We describe here a new version of our generator
  dealing with the complete LU decomposition algorithm, as well as
  linear solving. We worked out previously missing aspects of in-place
  updates, representing permutation matrices, dealing with augmented 
  input matrix, and back-propagation. We have also changed the representation
  of domain-specific knowledge about permissible compositions of aspects.
  Also included is a careful description of all the aspects involved, as
  well as documenting our development methodology for highly parametric
  scientific software.}
in using code generation for scientific (both numeric and symbolic)
software.  We will use the algorithm family of LU decomposition 
and linear system solving as our running examples to demonstrate our
techniques.  Specifically, our contributions are:
\begin{itemize}
    \item Extending a let-insertion, memoizing monad of
      \cite{KiselyovTaha,SwadiMonadic06} for generating control structures
      such as loops and conditionals. The extension is non-trivial
      because of control dependencies and because let-insertion, as we argue,
      is a control effect on its own: for example
      \texttt{let x = exp in \dots} has a different \emph{effect} within a
      conditional branch.
    \item Implementation of the |perform|-notation (patterned after
      the |do|-notation of Haskell) to make monadic code readable.
    \item Use of functors (including higher-order functors) to
      modularize the generator, express aspects (including results of
      various types) and \emph{insure composability of aspects} even
      for aspects that use state and have to be accounted for in many
      places in the generated code.
    \item Encode domain-specific knowledge in the generators so as to
      catch domain-specific instantiation errors at generation
      time.
    \item Provide a thorough classification of the family of LU decomposition
      algorithms.
\end{itemize}

We also used the same technology to implement a Runge-Kutta solver for
ordinary differential equations, as well as a reimplementation of
the FFT algorithm from~\cite{KiselyovTaha}.  The technology presented
here was amply sufficient for these implementations.  Since our current
implementations of these algorithms are rather straightforward compared to 
our versions of LU decomposition, we will not mention them further 
(the code is available at \cite{metamonadsURL}).

The rest of this paper is structured as follows: The next section
gives an overview of the design space of LU decomposition algorithms.
Section~\ref{CPS}
introduces code generation in MetaOCaml, the problem of name
generation, and the continuation-passing style (CPS) as a general
solution.  We also present the key monad and the issues of generating
control statements. Section~\ref{functors} describes the use of
parametrized modules of OCaml to encode all of the aspects of the
LU decomposition algorithm family as separate
modules.  We discuss related work in
Section~\ref{related} and outline future work. In our
conclusion (Section~\ref{conclusion}) we comment
on programming with aspects and sum up our guiding methodology.
Appendices give samples of the generated code, available in
full at \cite{metamonadsURL}.

\section{The design space}\label{design}

Before investigating implementation approaches, it is worthwhile to
carefully study the design space involved.  A preliminary
study~\cite{Carette06} revealed a number of aspects of the family of
Gaussian Elimination algorithms.  In the present work, we outline a
number of additional aspects involved in the family of LU
decomposition algorithms.  These will first be presented in a somewhat
ad hoc manner, roughly corresponding to the order in which they were
``discovered''.  We then reorganize them into groups of
semantically related aspects to form the basis of our design.

Throughout, we assume that the reader is familiar with the basic LU
decomposition algorithm, which factors a invertible matrix $A$ into a unit
lower triangular matrix $L$ and (usually) an upper triangular matrix $U$,
such that $A = LU$.  Pivoting adds a unitary matrix $P$ such
that the factorization is now $A = PLU$.  The case of numeric matrices is well
covered in~\cite{Golub-vanLoan}.  When $A$ is singular, one can still get
a $PLU$ decomposition with $L$ remaining unit lower-triangular. However, 
$U$ is no longer upper triangular but rather ``staggered''
in the upper triangle.

\subsection{Aspects}

We reuse the English word ``aspect'' for the various facets of the family
of LU decomposition algorithms.  While our use shares the 
spirit of aspect-oriented programming (AOP)~\cite{kiczales97aspectoriented},
our implementation methodology is radically different\footnote{However it seems
that we are closer to the original ideas of AOP~\cite{709568,mendhekar97rg}
which were also concerned with scientific software.}.  We firmly believe that
our typed generative methodology is much better suited to functional
programming, compared to attempts to graft the program-trace-based
methodology of object-oriented versions of AOP.  

At this point in time, it is better to think of aspects as purely
design-time entities.  Here we are firmly influenced by Parnas' original
view of modules and information hiding~\cite{journals/cacm/parnas72a} as well
as his view of product families \cite{journals/tse/Parnas76}, and by
Dijkstra's ideas on separation of concerns \cite{EWD:EWD447}.
To apply these principles to the study of LU decomposition, we need
to understand what are the changes between different implementations, and 
what concerns need to be addressed.  We also need to study the degree
to which these concerns are independent.

The various aspects listed below all come from variations found in actual
implementations (in various languages and settings).

\newcounter{naspects}
\begin{enumerate}
    \item \textbf{Domain}: the (algebraic) domain of matrix
        elements.  Some implementations were very specific
        ($\mathbb{Z}, \mathbb{Q}, \mathbb{Z_p}, 
        \mathbb{Z}_p\left[\alpha_1,\ldots,\alpha_n\right], 
        \mathbb{Z}\left[x\right]$, $\mathbb{Q}\left(x\right)$, 
        $\mathbb{Q}\left[\alpha\right]$, and floating point numbers 
        ($\floats$) for 
        example), while others were generic for elements of a field,
        multivariate polynomials over a field, or elements of a division ring
        with possibly undecidable zero-equivalence.  In the roughly 85 pieces
        of code we surveyed, 20 different domains were encountered.
    \item \textbf{Representation of the matrix}: Whether the matrix
        was represented as an array of arrays, a
        one-dimensional array with C or Fortran indexing styles, 
        a hash table, etc. Efficient row exchanges, if available for a
        particular representation, were sometimes used.
    \item \textbf{Fraction-free}: Whether the 
        algorithm is allowed to use unrestricted division, or only
        exact (remainder-free) division.
    \item \textbf{Length measure (for pivoting)}:  For stability reasons
        (whether numerical or coefficient growth), if a domain 
        possesses an appropriate length measure, it was sometimes used to
        choose an ``optimal'' pivot.  Not all domains have such a measure.
    \item \textbf{Full division}: Whether the input domain supports full
        division (i.e. is a \emph{field} or pretends to be ($\floats$)) 
        or only exact division (i.e. a \emph{division ring}).
    \item \textbf{Domain normalization}: Whether the arithmetic operations
        of the base domain keep the results in normal form, or whether
        an extra normalization step is required.  For example, some 
        representations of polynomials require an extra step for
        zero-testing.
    \item \textbf{Output choices}:  Just the reduced matrix
        (the `U' factor) or both L and U factors. The output
      choices also include
        the rank, the determinant, and the sequence of 
        pivots.  For example, Maple's
        \texttt{LinearAlgebra:\hyp LUDecomposition} routine has
        $2^6 + 2^5 + 2^2 = 100$ possible outputs, depending on whether
        one chooses a $PLU$, $PLUR$ or \emph{Cholesky} 
        decomposition.  We chose to only consider $PLU$ for now.
    \item \textbf{Rank}: Whether to explicitly track the rank of the matrix
        as the algorithm proceeds.
    \item \textbf{Determinant}:  Whether to explicitly track the determinant
        of the matrix as the algorithm proceeds.
    \item \textbf{Code representation}: the form and the language
      for the generated code (OCaml, C, Fortran, etc.). A
      degenerate case, useful for testing, is for the generator
      to run the LU algorithm directly (albeit with great
      abstraction overhead).
    \item \textbf{Zero-equivalence}: Whether the 
        arithmetic operations require a specialized zero-equivalence 
        routine.  For certain classes
        of \emph{expressions}, it turns out convenient to use 
        a zero-equivalence
        test that is separate from the domain normalization.  This is
        usually the case when zero-equivalence is formally undecidable
        but semi-algorithms or probabilistic algorithms do exist.
        See~\cite{ZhCaJeMo06a} for an example.
    \item \textbf{Pivoting}: Whether to use no, 
        column-wise, or full pivoting.
    \item \textbf{Augmented Matrices}: Whether all or only some
      columns of the matrix participate in elimination.
    \item \textbf{Pivot representation}: Whether the pivot is represented
      as a list of row and column exchanges, as a unitary matrix,
      or as a permutation vector.
  \item \textbf{Lower matrix}: whether the matrix $L$ should be tracked
      as the algorithm proceeds, reconstructed at the end of the
      algorithm, or not tracked at all.
  \item \textbf{Input choices}: Grouping all the potential
      choices of inputs -- currently only augmented matrices require
      an extra input.
  \item \textbf{Packed}: Whether the output matrices $L$ and $U$ are
      packed into a single matrix for output.
\setcounter{naspects}{\value{enumi}}
\end{enumerate}

The aspects in the following group have also been observed in
practice but we have not yet implemented them:
\begin{enumerate}
\setcounter{enumi}{\value{naspects}}
\item \textbf{Logging}, a classical cross-cutting concern.
\item \textbf{Sparsity}: If a matrix is known to be sparse, at least
the traversal should be sparse. Maximal preservation of the sparsity
is desirable. 
\item \textbf{Other structure}: If a matrix is known in
advance to be real symmetric tri-diagonal, LU decomposition can be
done in $O(n^2)$ rather than $O(n^3)$ time, at an additional $O(n)$
storage cost.
\item \textbf{Warnings}: In a domain with only heuristic zero
testing, it is customary to issue a warning (or otherwise log) when 
a potentially zero pivot is chosen.
\item \textbf{In-place}: offering an option of in-place decomposition,
  re-using the input matrix as the storage for the output.
\item \textbf{Error-on-singular}: Raise an exception when the input
  matrix is (near) singular.
\setcounter{naspects}{\value{enumi}}
\end {enumerate}

Most of these aspects are inter-dependent. For example, if the
determinant is part of the output, the determinant should be
tracked during the decomposition. Determinant should also be tracked
if the fraction-free aspect is chosen. The availability of the length
measure in the domain influences pivoting, \emph{if} pivoting
is to be performed. One could therefore select aspects that turn out
incompatible, and we have to prevent this. 
More precisely, our goal is to detect the selection of
incompatible aspects long before the generated code is run.

\subsection{Organizing aspects}

Further investigation revealed the following grouping of aspects:%
\footnote{This grouping showed that some of our implementation did not
separate distinct concerns well. In
particular, our implementation of ``containers'' 
mixed representation (i.e. data-structure) issues with abstraction
domain issues.  We hope to rectify this in the future.}

\begin{enumerate}
    \item \textbf{Abstract domain}.  This group includes
      `mathematical' aspects: domain of matrix elements, length
      measure, full division, normalization, zero testing,
      symmetry and other matrix structure.
    \item \textbf{Concrete representation}: choosing data
      structures for domains, containers, permutation
      matrices. This group also includes packing, in-place
      decomposition, and the
      representation of sparse matrices.
    \item \textbf{Interface} of each generated function, including
      the input and output choices, logging and error reporting.
    \item \textbf{Algorithmic Strategy}, such as fraction-free
      updates, pivoting strategies, augmented matrices.
    \item \textbf{Tracking}, of determinant, rank, or pivot, etc.
    \item \textbf{Staging}: whether the result is the program or a
      generator that will produce the program.
\end{enumerate}

%% \oleg{In-place updates is also the issue of concrete
%%   representation! As well as of the abstract domains:
%%   for some domains we just can't run LU with no extra
%%   storage.} 
%% \jacques{Correct.  There are issues which are ``relational'' rather
%% than being completely independent.  The above categories seem to 
%% be independent, but that is too simplistic.  Some aspects, like
%% in-place, have quite a number of pre-conditions on other aspects
%% before they can be realized.}

The groupings are not entirely orthogonal (for example, in-place
decomposition is possible only for specific domains), yet are useful
as guidance in creating the modular LU generator discussed in 
Section~\ref{functors}.

\section{Generating binding statements, CPS, and monad}\label{CPS}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We build large code generators out of primitive generators using 
combinators. MetaOCaml, as an instance of a multi-stage
programming system \cite{TahaThesis}, provides exactly the needed
features: to construct a code expression, to combine them, and to
execute them. The following shows the simplest code generator |one|,
and the simplest code combinator\footnote{%
$\Longrightarrow$ under an expression shows the result of its evaluation}:

\begin{code}
let one = .<1>. and plus x y = .<.~x + .~y>.
let simplest_code = let gen x y = plus x (plus y one) in
  .<fun x y -> .~(gen .<x>. .<y>.)>.
\evalresult{.<fun x_1 -> fun y_2 -> (x_1 + (y_2 + 1))>.}
\end{code}

We use MetaOCaml brackets |.<...>.| to generate code expressions,
i.e., to construct future-stage computations. MetaOCaml provides only
one mechanism of combining code expressions, by splicing one
piece of code into
another. The power of that operation, called escape |.~|, comes from
the fact that the expression to be spliced in (inlined) can be
computed: escape lets us perform an arbitrary immediate code-generating
computation \emph{while} we are
building the future-stage computation. The immediate computation in
|simplest_code| is the evaluation of the function |gen|, which in turn
applies |plus|. The function |gen| receives code expressions |.<x>.|
and |.<y>.| as arguments. At the generating stage, we can manipulate
code expressions as (opaque) values. The function |gen| returns a code
expression, which is inlined in the place of the escape. MetaOCaml can
print out code expressions, so we can examine the final generated code. It
has no traces of |gen| or |plus|: they are generation stage computations.

The final MetaOCaml feature, |.!| (pronounced ``run'') 
executes a code expression: |.! simplest_code| is a function of two
integers, which we can apply: |(.! simplest_code) 1 2|. The original
|simplest_code| is not a function on integers -- it is a code
expression which \emph{represents} (or encodes) a function.

By parametrizing our code, we can make the benefits of code generation
evident:

\begin{code}
let simplest_param_code plus one =
  let gen x y = plus x (plus y one) in
  .<fun x y -> .~(gen .<x>. .<y>.)>.
\end{code}
and use it to generate code that operates on integers, floating point
numbers or booleans -- in general, any domain that implements |plus|
and |one|:
\begin{code}
let plus x y = .<.~x +. .~y>. and one = .<1.0>. in
  simplest_param_code plus one
let plus x y = .<.~x || .~y>. and one = .<true>. in
  simplest_param_code plus one
\end{code}
Running the former expression yields a function on |float|s, whereas
the latter expression is the code expression for a boolean function.
This clearly shows the separation of concerns for domain
operations.

Let us consider a more complex expression:
\begin{code}
let param_code1 plus one =
  let gen x y = plus (plus y one) (plus x (plus y one)) in
  .<fun x y -> .~(gen .<x>. .<y>.)>.
\end{code}
with two occurrences of |plus y one|,
which may be a rather complex computation which we would rather not do
twice. We may be tempted to rely on the compiler's
common-subexpression elimination optimization. When the generated code is
very complex, however, the compiler may overlook common subexpressions.  Or the
subexpressions may occur in an imperative context where the compiler
might not be able to determine whether lifting them is sound. So, being
conservative, the optimizer will leave the duplicates as they are. 
We may attempt to eliminate subexpressions as follows: 
\begin{code}
let param_code1' plus one =
  let gen x y = let ce = (plus y one) in  plus ce (plus x ce) in
  .<fun x y -> .~(gen .<x>. .<y>.)>.
param_code1' plus one
\evalresult{.<fun x_1 -> fun y_2 -> ((y_2 + 1) + (x_1 + (y_2 + 1)))>.}
\end{code}
However,
the result of |param_code1' plus one| still exhibits duplicate
sub-expressions.  Our |let|-insertion optimization only saved the
computation at the generating stage.  We need a combinator that
inserts the |let| expression in the generat\emph{ed} code. We need a
combinator |letgen| to be used as
\begin{code}
let ce = letgen (plus y one) in plus ce (plus x ce)
\end{code}
yielding code like 
\begin{code}
.<let t = y + 1 in t + (x + t)>.
\end{code}
But that seems impossible because |letgen exp| has to generate
the expression |.<let t = exp in body>.| but |letgen| does not yet
have the |body|. The body needs a temporary identifier |.<t>.|
that is supposed to be the result of |letgen| itself.  Certainly
|letgen| cannot generate only part of a let-expression, without the
|body|, as all generated expressions in MetaOCaml are well-formed and
complete.

The solution to this problem is to use continuation-passing style (CPS). Its
benefits were first pointed out by \cite{Bondorf:92} in the context of partial
evaluation, and extensively used by \cite{SwadiMonadic06,KiselyovTaha} for
code generation. Like \cite{conf/pepm/BondorfD94}, we use this in the 
context of writing a cogen by hand.  Now, |param_code2 plus one| gives us the
desired code.

\begin{code}
let letgen exp k = .<let t = .~exp in .~(k .<t>.)>.
let param_code2 plus one =
  let gen x y k = letgen (plus y one)
                         (fun ce -> k (plus ce (plus x ce)))
  and k0 x = x
  in .<fun x y -> .~(gen .<x>. .<y>. k0)>.
param_code2 plus one
\evalresult{.<fun x_1 -> fun y_2 -> let t_3 = (y_2 + 1) in (t_3 + (x_1 + t_3))>.}
\end{code}

\subsection{Monadic notation, making CPS code clear}\label{monadicnotation}

Comparing the let-insertion in the generator
\begin{code}
let ce = (plus y one) in  plus ce (plus x ce)
\end{code}
with the corresponding code generating let-insertion for a future
stage
\begin{code}
letgen (plus y one) (fun ce -> k (plus ce (plus x ce)))
\end{code}
clearly shows the difference between  direct-style and CPS code.
What was |let ce = init in ...| in direct style became
|init' (fun ce -> ...)| in CPS. For one, |let| became
``inverted''. For another, what used to be an expression that yields
a value, |init|, became an expression that takes an extra argument,
the continuation, and invokes it. The differences look negligible in
the above example. In larger expressions with many let-forms, the
number of parentheses around |fun| increases, the need to add and
then invoke the |k| continuation argument become increasingly annoying. The
inconvenience is great enough for some people to explicitly avoid CPS
or claim that numerical programmers (our users) cannot or will not
program in CPS. Clearly a better notation is needed.

The |do|-notation of Haskell \cite{Haskell98Report} shows that it is possible
to write CPS code in a conventional-looking style. The
|do|-notation is the notation for monadic code \cite{moggi-notions}.
Not only can monadic code represent CPS \cite{Filinski:Representing},
it also helps with composability by giving complete control over how
different effects are layered
(state, exception, non-determinism, etc.) on top of the
basic monad \cite{liang-interpreter}.

A monad \cite{moggi-notions} is an abstract data type representing
computations that yield a value and may have an \emph{effect}.
The data type must have at least two operations, |return| to build
trivial effect-less computations and |bind| for combining
computations. These operations must satisfy \emph{monadic laws}:
|return| being the left and the right unit of |bind| and |bind| being
associative. Figure~\ref{ourmonad} defines the monad used throughout
the present paper and shows its implementation.

\begin{figure}
\begin{code}
type ('p,'v) monad = 's -> ('s -> 'v -> 'w) -> 'w
    constraint 'p = <state : 's; answer : 'w; ..>

let ret (a :'v) : ('p,'v) monad = fun s k -> k s a
let bind (m : ('p,'v) monad) (f : 'v -> ('p,'u) monad) : ('p,'u) monad
  = fun s k -> m s (fun s' b -> f b s' k)
let fetch s k = k s s  and  store v _ k = k v ()

let k0 _ v = v
let runM m = fun s0 -> m s0 k0 

let retN (a : ('c,'v) code) : 
 (<classif: 'c; answer: ('c,'w) code; ..>,('c,'v) code) monad 
   = fun s k -> .<let t = .~a in .~(k s .<t>.)>.

let ifL test th el = ret .< if .~test then .~th else .~el >.
let ifM test th el = fun s k -> 
  k s .< if .~test then .~(th s k0) else .~(el s k0) >.
\end{code}
\caption{Our monad}\label{ourmonad}
\end{figure}

Our monad encapsulates two kinds of computational effects: reading and
writing a computation-wide state, and control effects. The latter are
normally associated with exceptions, forking of computations, etc. --
in general, whenever a computation ends with something other than
invoking its natural continuation in the tail position. In our case
the control effects manifest themselves as code generation.

In Figure~\ref{ourmonad}, the monad (yielding values of type |v|)
is implemented as a function of two
arguments: the state (of type |s|) and the continuation. The
continuation receives the current state and a value, and
yields an answer of type |w|.  The monad is polymorphic over the
three type parameters, which would require |monad| to be a type
constructor with three arguments. When we use this monad for code
generation, we will need yet another type variable for the environment
classifiers \cite{taha-environment} (such as the type variable |'c| 
in the type of |retN| in Figure~\ref{ourmonad}).
With type constructors taking more
and more arguments, it becomes increasingly difficult to read and write
types -- which we will be doing extensively when writing module
signatures in Section~\ref{functors}. The fact that OCaml renames all type
variables when printing out types confuses matters further. An elegant
solution to these sorts of problems has been suggested by 
Jacques Garrigue on the Caml mailing list.
%% (cited from
%% \url{http://groups.google.com/group/fa.caml/msg/e80b1245702d6b24}
%% no date, no exact ref). 
%
We use a single type parameter |'p| to
represent all parameters of our monad (all parameters but the type of
the monadic value |'v|). The type variable |'p| is constrained to be
the type of an object with methods (fields) |state| and |answer|. The
object may include more fields, represented by |..|. Values of that
type are not part of our computations and need not exist. We merely
use the object type, as an convenient way to specify extensible
\emph{type-level} records in OCaml.     

Our monad could be implemented in other ways. Except for the code in
Figure~\ref{ourmonad}, the rest of our code treats the monad as a
truly abstract data type. The implementation of the basic monadic
operations |ret| and |bind| is conventional and clearly satisfies the
monadic laws. Other monadic operations construct computations that do
have specific effects.  Operations |fetch| and |store v| construct
computations that read and write the state.

The operation |retN a| is the let-insertion operation, whose simpler
version we called |letgen| earlier. It is the first computation with a
control effect: indeed, the result of |retN a| is \emph{not} the
result of invoking its continuation |k|. Rather, its result is a |let|
code expression. Such behavior is symptomatic of control operators (in
particular, |abort|).  The name can be taken to mean \emph{return a
  Named computation}; the name allows for proper sharing, but
otherwise |retN| is used in writing generators in the same way as
|ret|. The type of |retN| is a specialization of the type of |ret|:
the computation |retN| deals specifically with code values. The types
of code values must include the environment classifier 
(such as |'c|), which denotes
the scope of free variables that may occur in the code value. The
argument type of |retN| and the answer type of |retN| computation must
have the same classifier -- which, informally, means that all free
variables in the argument of |retN| are preserved in the answer of
|retN|'s computation. When writing, for clarity, the type annotations
of |retN| we see the benefits of type-level records: we introduce a
new component of the record to specify the environment classifier
|'c|, and we update the |answer| component of the record to specialize
the answer type to be the type of code. The |state| component of the
record is not affected, and so remains hidden in the ellipsis |..|. The
number of parameters to the type constructor |monad| remains the same.

Finally, |runM| runs our monad, that is, given the initial state,
it performs the computation of
the monad and returns its result, which in our case is a code
expression. We run the monad by passing it the initial state and the
initial continuation |k0|. We can now re-write our |param_code2|
example of the previous section as |param_code3|.
\begin{code}
let param_code3 plus one =
  let gen x y = bind (retN (plus y one)) (fun ce -> 
                ret (plus ce (plus x ce)))
  in .<fun x y -> .~(runM (gen .<x>. .<y>.) ())>.
\end{code}
% param_code3 plus one;;
%
That does not seem like much of an improvement. With the help of
camlp4 pre-processor, we introduce the |perform|-notation \cite{metamonadsURL},
patterned after the |do|-notation of Haskell (see App.~\ref{app:perform}).
\begin{code}
let param_code4 plus one =
  let gen x y = perform ce <-- retN (plus y one);
                        ret (plus ce (plus x ce))
  in .<fun x y -> .~(runM (gen .<x>. .<y>.) ())>.
\end{code}
The function
|param_code4|, written using the |perform|-notation, is equivalent to
|param_code3| -- in fact, the camlp4 preprocessor will convert the
former into the latter. And yet, |param_code4| looks far more
conventional, as if it were indeed in direct style.

\subsection{Generating control statements}
We can write operations that generate code other than let-statements,
e.g., conditionals: see |ifL| in Figure~\ref{ourmonad}. The function |ifL|, 
albeit straightforward, is not as general as we wish: its arguments are
already generated pieces of code rather than monadic values. We
can ``lift it'':
\begin{code}
let ifM' test th el = perform
  testc <-- test; thc <-- th; elc <-- el;
  ifL testc thc elc
\end{code}
However we also need another |ifM| function, with the same
interface (see Figure~\ref{ourmonad}).
The difference between them is apparent from the following example:
\begin{code}
let gen a i = ifM' (ret .<(.~i) >= 0>.) 
                   (retN .<Some (.~a).(.~i)>.) (ret .<None>.)
 in .<fun a i -> .~(runM (gen .<a>. .<i>.) ())>.
\evalresult{.<fun a_1 i_2 ->}
\textcolor{red}{      let t_3 = (Some a_1.(i_2)) in if (i_2 >= 0) then t_3 else None>.}
let gen a i = ifM (ret .<(.~i) >= 0>.) 
                  (retN .<Some (.~a).(.~i)>.) (ret .<None>.)
 in .<fun a i -> .~(runM (gen .<a>. .<i>.) ())>.
\evalresult{.<fun a_1 i_2 ->}
\textcolor{red}{      if (i_2 >= 0) then let t_3 = (Some a_1.(i_2)) in t_3 else None>.}
\end{code}
%
If we use |ifM'| to generate guarded array access code, the let-insertion
happened \emph{before} the if-expression, that is, before the test that
the index |i| is positive. If |i| turned out
negative, |a.(i)| would generate an out-of-bound array access
error. On the other hand, the code with |ifM| accesses the array only
when we have verified that the index is non-negative. This example
makes it clear that code generation (such as the one in |retN|) is 
truly an effect, and we have to be clear about the sequencing of
effects when generating control constructions such as conditionals.
The form |ifM| handles such effects correctly. 

We need similar operators for other OCaml control forms: for
generating sequencing, case-matching statements and |for|- and |while|-loops.
\begin{code}
let seqM a b = fun s k -> 
  k s .< begin .~(a s k0) ; .~(b s k0) end >.

let whileM cond body = fun s k -> 
  k s .< while .~(cond) do .~(body s k0) done >.

let matchM x som non = fun s k -> k s .< match .~x with
           | Some i -> .~(som .<i>. s k0)
           | None   -> .~(non s k0) >.

let genrecloop gen rtarg = fun s k -> 
  k s .<let rec loop j = .~(gen .<loop>. .<j>. s k0) in loop .~rtarg>.
\end{code}

\section{Aspects and Functors}\label{functors}

The monad represents fine-scale code generation. We need tools for
larger-scale modularization; we can use any abstraction
mechanisms we want to structure our code generators, as long as none
of those abstractions infiltrate the generated code. The ML module system
turns out to be most convenient.

\subsection{Domains}\label{sec:domains}

We start by abstracting out domains. We have already seen the simplest
case of domain abstraction in |param_code1|, which took
code-generators such as |plus| and |one| as arguments.  We need far
more than two parameters: our domains should include $0$, $1$, $+$,
$*$, (unary and binary) $-$, at least \emph{exact} division,
normalization, and potentially a relative size measure. We could group
these parameters in tuples or records.  Instead, we use OCaml
\emph{structures} (i.e., modules) so we can take advantage of
extensibility, type abstraction and constraints, and especially
parameterized structures (\emph{functors}).  We define the type,
the signature |DOMAIN|, which different domains must satisfy:

\begin{code}
type domain_kind = Domain_is_Ring | Domain_is_Field

module type DOMAIN = sig
  type v
  val kind : domain_kind
  val zero : v
  val one  : v
  val plus : v -> v -> v
  val times  : v -> v -> v
  val minus  : v -> v -> v
  val uminus : v -> v
  val div    : v -> v -> v
  val better_than : (v -> v -> bool) option
  val normalizer  : (v -> v) option
end 

module IntegerDomain : DOMAIN = struct
  type v = int
  let kind = Domain_is_Ring
  let zero = 0 and one = 1
  let plus x y = x + y  and  minus x y = x - y
  let times x y = x * y and  div x y = x / y
  let uminus x = -x
  let normalizer = None
  let better_than = Some (fun x y -> abs x > abs y)
end
\end{code}

One particular domain instance is |IntegerDomain|. The type annotation
|DOMAIN| in the definition of |IntegerDomain| makes the 
compiler verify that the defined structure is indeed of a type |DOMAIN|. 
\jacques{In fact, it seems that this annotation cannot be put there
because that will make type v abstract, which will result in compilation
errors for the "lifted" domain which needs to have this type be
available.}
The annotation may be omitted (see |ZpMake| below), in which
case the compiler will verify the type when we try to use that structure as a
|DOMAIN|. In any case, the errors such as missing ``methods'' or
methods with incorrect types will be caught statically, 
\emph{before} any code generation takes place. The variant
|Domain_is_Ring| of |IntegerDomain.domain_kind| encodes a semantic constraint:
that full division
is not available. While the |DOMAIN| type may have looked daunting to
some, the implementation is quite straightforward.  Other domains such
as |float| and arbitrary precision exact rational numbers |Num.num|
are equally simple.

A more complex domain is |Zp|, the field of integers in prime
characteristic:
\begin{code}
module ZpMake(P:sig val p:int end) = struct
    type v = int
    let kind = Domain_is_Field
    let zero = 0 and one = 1
    let plus x y = (x + y) mod P.p
    let times x y = (x * y) mod P.p
    \dots
    let normalizer = None and better_than = None
    let () = assert (is_prime P.p)
end
\end{code}
This domain is parametrized by an integer |p|. 
To be more precise, the structure |ZpMake| is
parameterized over another structure of the type described by
the signature |P|, which has one field, the |int| value |p|.
Such a parameterized structure (or, a function from structures to
structures) is a \emph{functor}. The result of |ZpMake| is a domain which is a
field with no defined order. Hence
|normalizer| and |better_than| are set to |None|. |Zp| forms
a field only when |p| is prime\footnote{or a prime power, a case we do
not treat here.}.  Since we intend to make a field of prime characteristic, 
we must check this, as is done
in the last line of the above code. That line differs from the other 
bindings in |ZpMake| in that it neither defines a function, such as
|plus|, nor binds a value, such as |zero|. This non-value
expression |assert (is_prime P.p)|, which we will call an initializing
expression, will be evaluated
when the corresponding module is instantiated.
\begin{code}
module Z19 = ZpMake(struct let p = 19 end)
\end{code}
If we
replace |p = 19| with |p = 9| above, we receive a run-time
error. However, it is raised as we instantiate and combine modules that
will \emph{eventually} make the generator.  Although the error is reported at
``run-time'' rather than during compilation as one might have hoped, the error
is raised when \emph{generating the generator} -- well before the
generation of the target code could begin.  In our code we make
extensive use of these ``preflight checks'', which are performed as part of
module initialization. These checks seem to offer a good compromise:
they are dynamic and so do not require a complicated type system; on
the other hand, the checks are run quite early, when building
code generators, and so ensure that no code violating the
corresponding \emph{semantic} constraints will be generated. Although
some may frown on the use of module initializing expressions 
as this requires careful attention to sharing and multiple instantiations
of a module, these concerns do not apply in our case: our preflight
checks are all idempotent and maintain no state.

\subsection{Abstract code and lifted domains}\label{sec:lifteddomains}
We will be using MetaOCaml operations to build code expressions, values
of type |('a,'v) code|. However, we wish to make our generators
abstract over particular code representations. Therefore, when writing
the LU generator (Section~\ref{sec:det} and below), instead of
MetaOCaml brackets and escapes we will be using the code combinators
described below. These combinators are functions that produce and
combine values of the type of \emph{abstract code}. 

This encapsulation of staging annotations into code combinators lets
us easily change the output form of our generated LU programs.  For example,
we may use single-stage thunks rather than MetaOCaml staged |('a,'v) code|
values, for benchmarking and regression tests purposes. We could also use
code combinators producing C or Fortran code.

Our code combinator library includes operations to create, dereference
and mutate reference cells, compare values, and manipulate values used
for indexing arrays. The following is the implementation of sample
combinators, in the case of the abstract code being MetaOCaml code. 
We basically need to ``lift'' most the underlying programming language
into combinators.
\begin{code}
let lift x = .< x >.

let cunit = .< () >.  and unitL = fun s k -> k s .< () >.

let liftRef x = .< ref .~x >.  and   liftGet x = .< ! .~x >. 
let liftPair x = (.< fst .~x >., .< snd .~x >.)

module Logic = struct
  let notL a        = .< not .~a >.
  let equalL a b    = .< .~a = .~ b >.
  let notequalL a b = .< .~a <> .~ b >.
  let andL a b     = .< .~a && .~b >. 
end

module Idx = struct
  let zero = .< 0 >. and one = .< 1 >. and minusone = .< -1 >.
  let succ a = .< .~a + 1 >.  and  pred a = .< .~a - 1 >.
  let less a b = .< .~a < .~b >.
  let uminus a = .< - .~a >.  and  add a b = .< .~a + .~b >.
end

let update a f = let b = f (liftGet a) in .< .~a := .~b >.
let assign a b = .< .~a := .~b >.
let apply  f x = .< .~f .~x >.
let updateM a f = ret (update a f)
let assignM a b = ret (assign a b)
let applyM  f x = ret (apply f x)
\end{code}


\noindent  The types above are
generally lifted in two ways: once from the value domain |v| to the code
domain |('a,'v) code|, and once more from values to monadic computations
|('p,'v) monad|. 

We now convert the domains of values from the previous section into
lifted domains, of abstract code values. We define the signature
|DOMAINL|:
\begin{code}
module S(T: sig type ('a, 'b) rep  end) = struct
open T
module type DOMAINL = sig
  include DOMAIN
  type 'a vc = ('a,v) rep
  val zeroL : 'a vc
  val oneL  : 'a vc
  val ( +^ ) : 'a vc -> 'a vc -> 'a vc
  val ( *^ ) : 'a vc -> 'a vc -> 'a vc
  val ( -^ ) : 'a vc -> 'a vc -> 'a vc
  val uminusL : 'a vc -> 'a vc
  val divL    : 'a vc -> 'a vc -> 'a vc
  val better_thanL : ('a vc -> 'a vc -> ('a,bool) rep) option
  val normalizerL  : ('a vc -> 'a vc) option
end 
\end{code}
(part of a larger module |Domains_sig|) that is parameterised by
the type of abstract code, |('a, 'b) rep|. The line |include DOMAIN|
says that lifted domains include all members of non-lifted domains,
including the initializing expressions with preflight checks.
The following is a particular instance of |DOMAINL|, the lifted
version of |IntegerDomain| of the previous section, in the particular
case of abstract code being MetaOCaml code values |('a, 'b) code|:
\begin{code}
module T = Domains_sig.S(struct type ('a, 'b) rep = ('a, 'b) code end)
open T
module IntegerDomainL = struct
    include IntegerDomain
    type 'a vc = ('a,v) code
    let zeroL = .< 0 >.  and oneL = .< 1 >. 
    let (+^) x y = .<.~x + .~y>. and ( -^ ) x y = .<.~x - .~y>.
    let ( *^ ) x y = .<.~x * .~y>. and divL x y = .<.~x / .~y>. 
    let uminusL x = .<- .~x>.
    let normalizerL = None
    let better_thanL = Some (fun x y -> .<abs .~x > abs .~y >. )
end
\end{code}
Such lifting is completely straightforward.  However, it is a
program-text to program-text transformation over modules, and as such could
only be automated (currently) by further use of camlp4.

In fact, our implementation requires another level of indirection, and
in fact reads
\begin{code}
module Make(CODE: Coderep.T) = struct
  module D = Domains_sig.S(
      struct type ('a, 'v) rep = ('a,'v) CODE.abstract 
    end)
open D
open CODE
...
\end{code}
where |CODE| is a module which implements a type |abstract| and various
facilities over it, like the modules |Logic| and |Idx| mentioned above.
For simplicity, we open |CODE| to allow access to the actual type |abstract|.

To further trim down on the size of the signatures for various modules,
we introduce two variants of |monad|, specialized for our purpuses.  The
first is used when we are always generating (abstract) code, while the second
helps when we might generate (abstract) code.
\begin{code}
type ('pc,'v) cmonad = 
  ('p,('a,'v) abstract) monad
    constraint
      'p = <state : 's list; answer : ('a,'w) abstract>
    constraint
      'pc = <classif : 'a; answer : 'w; state : 's; ..>
       
type ('pc,'v) omonad = 
  ('p,('a,'v) abstract option) monad
    constraint
      'p = <state : 's list; answer : ('a,'w) abstract>
    constraint
      'pc = <classif : 'a; answer : 'w; state : 's; ..>
\end{code}
\subsection{Containers}

For our purposes, a container is an abstraction of an $n$-dimensional
vector space, which we here specialize for $n=1,2$.  The $2$ dimensional
case is our main interest, and its signature contains many functions particular
to $n=2$.  For examples, we have rows and columns and operations specialized
for them.  A container explicitly abstracts the underlying representation 
of the data-structure, while offering an interface which is better-suited
to linear algebra.

The signature |CONTAINER2D| below specifies that a container must provide
functions |dim1| and |dim2| to extract the dimensions, functions |getL|
to generate container getters, the cloning
generator |copy| and functions that generate code for row and column
swapping. The inclusion of these functions in the signature of all
containers makes it simpler to optimize the relevant functions
depending on the actual representation of the container while not
burdening the users of containers with efficiency details.  Note that
this module type is also abstract over the actual representation 
|rep| of the generator data-structure.

\begin{code}
module type CONTAINER2D = sig
  module Dom:DOMAINL
  type contr
  type 'a vc = ('a,contr) rep
  type 'a vo = ('a,Dom.v) rep
  val getL : 'a vc -> ('a,int) rep -> ('a,int) rep -> 'a vo
  val dim1 : 'a vc -> ('a,int) rep
  val dim2 : 'a vc -> ('a,int) rep
  val mapper : ('a vo -> 'a vo) option -> 'a vc -> 'a vc
  val copy : 'a vc -> 'a vc
  val init : ('a,int) rep -> ('a, int) rep -> 'a vc
  val augment : 'a vc -> ('a,int) rep -> ('a, int) rep -> 'a vc ->
                ('a, int) rep -> 'a vc
  val identity : ('a,int) rep -> ('a, int) rep -> 'a vc
  val swap_rows_stmt : 'a vc -> ('a, int) rep -> ('a, int) rep -> 
                       ('a,unit) rep
  val swap_cols_stmt : 'a vc -> ('a, int) rep -> ('a, int) rep -> 
                       ('a,unit) rep
  val row_head : 'a vc -> ('a, int) rep -> ('a, int) rep -> 'a vo
  val col_head_set : 'a vc -> ('a,int) rep -> ('a,int) rep -> 'a vo -> 
            ('a,unit) rep
end
\end{code}

The type of our containers include the lifted domain |Dom| as one of
the components. This is quite convenient since operations on containers
are usually accompanied by the operations on the retrieved and stored
values. Our containers are parametric over a |DOMAINL|, i.e., functors
from a |DOMAINL| module to the actual implementation of a
container. For example, the following functor defines a matrix
container represented as arrays of rows.

\begin{code}
module GenericArrayContainer(Dom:DOMAINL) =
  struct
  module Dom = Dom
  type contr = Dom.v array array (* Array of rows *)
  type 'a vc = ('a,contr) code
  type 'a vo = ('a,Dom.v) code
  let getL x n m = .< (.~x).(.~n).(.~m) >.
  let dim2 x = .< Array.length .~x >.       (* number of rows *)
  let dim1 x = .< Array.length (.~x).(0) >. (* number of cols *)
  \dots
\end{code}
%
The accompanying code\cite{metamonadsURL} includes containers whose
elements are stored in a 1D array, in a
row-wise (C-like) or column-wise (Fortran-like) modes.

\subsection{Maintaining an extensible state}

Various aspects of our LU generator such as determinant, rank, 
and permutation tracking may need to keep a state during
code generation. For example, the initializing section of the LU
generator will invoke a function (|decl|) of the determinant aspect 
which ``declares'' whether tracking the determinant is needed, 
so that the
latter may generate let-binding for reference cells that track the
magnitude and the sign of the determinant. The generator of the
row-swapping code will notify the determinant aspect so that the
latter may insert code that flips the sign of the tracked
determinant. The final section of the LU generator will ask the
determinant aspect to generate code producing the final, signed value
of the determinant. Clearly the determinant aspect needs to maintain
state from one invocation of its functions to another; this state should
include the ``names'' of mutable variables accumulating the sign and the
magnitude of the determinant.

The simplest method of keeping the state of the generator is by using
mutable variables, private to the Determinant module (aspect). That,
however, makes our aspects stateful. Although we are generating
imperative code, we would like to keep our generators stateless and
purely functional, for ease of comprehension and reasoning.  Our main
program may include several LU generators referring to one Determinant
aspect -- which may be present in one shared instance or in
several. That is of no concern if the Determinant module is
stateless. With stateful modules, the issues of aliasing or separate
instantiation are the source of very subtle problems.

We therefore chose a different way of maintaining the generator state,
using a monad. We already need a monad for let-insertion; we add state as
an additional monad parameter (Fig.~\ref{ourmonad}) and monadic
actions |fetch| and |store| to access that monadic state. The state is
threaded throughout the entire code-generation computation. 

This monadic state has to accommodate several distinct pieces of state, for
various aspects. We should be able to add a new aspect -- which may need
to keep its own state as part of the overall monadic state -- without
modifying or even recompiling the rest of the code. Thus our monadic
state should be extensible. We could use an extensible
record: an OCaml object. Each aspect would have its own field; record
subtyping would assure modularity. Alas, this approach makes it
difficult to create an initial state, to pass to the monad's |runM|
method. We would be required to know the names of all fields and should know
the proper initial value for these fields, which breaks modularity.

The MLton team suggests a better approach: property 
lists~\cite{mlton-proplist}.  A property list also represents an
extensible object but by its dual, namely a list of polymorphic variants.  The
initial object is just the empty list.  Unfortunately, we cannot apply
MLton's approach litterally to our case.  MetaOCaml's environment classifiers
require type universes parameterized by classifiers. The MLton
approach uses generativity of exceptions or reference cells to
generate property names, i.e., fields of an extensible record. Using this
technique would make our aspects stateful modules, something we do not
want, as we wish our generator to be purely functional [even though it is
generating imperative code].
Fortunately, OCaml offers a way to build open unions with
polymorphic variants. Each variant is identified by a manifest tag,
e.g., |`Tdet|, and may include a value. The tags are not generative and
provide a form of manifest naming, similar to symbols of
Lisp and Scheme.

Below is the implementation of our open records with manifest
naming: functions |orec_store| to add a new field to the open record
and |orec_find| to obtain the value associated with a particular field
name. Each ``field'' is characterized by a triple: an injection function, 
a projection function and the string name. The latter is used for 
printing error messages. For example, for the
determinant tracking aspect, this triple has the form
\begin{code}
let ip = 
  (fun x -> `TDet x), (function `TDet x -> Some x | _ -> None), "Det"
\end{code}
We combine these functions with monadic
actions to access monadic state and so obtain 
|mo_extend| and |mo_lookup| to store and retrieve one component 
of the monadic state.
\begin{code}
type ('a,'b) open_rec = ('a -> 'b) * ('b -> 'a option)  * string

let rec lookup ((_,prj,_) as ip:(('a,'b) open_rec) )
   : 'b list -> 'a = 
   function [] -> raise Not_found
   | (h::t) -> (match prj h with Some x -> x | _ -> lookup ip t)

let orec_store ((inj,_,name) as ip:(('a,'b) open_rec)) (v:'a) (s:'b list) 
   : 'b list =
  let () = 
    try let _ = lookup ip s in 
        failwith ("The field of an open record is already present: " ^ name)
    with Not_found -> () in
  (inj v)::s

let orec_find ((_,_,name) as ip:(('a,'b) open_rec)) (s:'b list) : 'a =
  try lookup ip s 
  with Not_found -> failwith ("Failed to locate orec field: " ^ name)

let mo_extend (ip:('a,'b) open_rec) (v:'a) : ('c, 'd) monad = 
  perform s <-- fetch; store (orec_store ip v s)

let mo_lookup (ip:('a,'b) open_rec) : ('c, 'd) monad =
  perform s <-- fetch; ret (orec_find ip s)
\end{code}
%
Currently, we check at generation-time that one should not add an
already existing field to an open record, nor should one attempt to
look up a field that does not exist. It is possible to make these
checks static.

\subsection{Determinant aspect}
\label{sec:det}
To track the determinant, we should be able to generate code
for: defining variables used for tracking (|decl|),
updating the sign (|upd_sign|) or the absolute
value of the determinant, and converting the tracking state
to the final determinant value of type |outdet|. LU of a
floating-point matrix with no determinant tracking uses the
instantiation of |DETERMINANT| (see definition below) where |outdet| is |unit|
and all the
functions of that module generate no code. For integer matrices, and
in general whenever the matrix elements do not form a field, we
have to track some aspects of the determinant, even if we do not output
it, as the fraction-free update needs those aspects. The determinant tracking
aspect is complex because tracking variables, if any, are to be declared at the
beginning of LU; the sign
of the determinant has to be updated on each row or column
permutation; the value of the determinant should be updated per each
pivoting. We use |lstate| to pass the tracking state, e.g., a piece of
code for the value of the type |Dom.v ref|, among
various determinant-tracking functions. The |lstate| is a part of the
overall monadic state. 
Other aspects follow a similar outline.

\begin{code}
module type DETERMINANT = sig
  type tdet = C.Dom.v ref
  type 'a lstate
  type ('pc,'v) lm = ('pc,'v) cmonad
    constraint 'pc = <state : [> `TDet of 'a lstate ]; classif : 'a; ..>
  type ('pc,'v) om = ('pc,'v) omonad
    constraint 'pc = <state : [> `TDet of 'a lstate ]; classif : 'a; ..>
  val decl      : unit -> ('b,unit) lm
  val upd_sign  : unit -> ('b,unit) om
  val zero_sign : unit -> ('b,unit) lm
  val acc_magn  : ('a,C.Dom.v) abstract -> (<classif : 'a; ..>,unit) lm
  val get_magn  : unit -> ('b,tdet) lm
  val set_magn  : ('a,C.Dom.v) abstract -> (<classif : 'a; ..>,unit) lm
  val fin       : unit -> ('b,C.Dom.v) lm
end
\end{code}

We have two instances of the above. The first one is used to specify
no determinant tracking, and so no code is
generated. The methods just return without executing any
code-generation actions.
\begin{code}
module NoDet =
  struct
  type tdet = C.Dom.v ref
  type 'a lstate = unit
  let decl () = unitL
  let upd_sign () = ret None
  let zero_sign () = unitL
  let acc_magn _ = unitL
  let get_magn () = ret (liftRef C.Dom.zeroL)
  let set_magn _ = unitL
  let fin () = failwith "Determinant is needed but not computed"
end
\end{code}

The second instance does track the determinant. The |decl| method
generates two let-bindings for mutable variables tracking the
magnitude and the sign of the determinant, and places the names of
these variables in the monadic state. The |upd_sign| method, invoked
from row- or column-swap generators, retrieves the name of the
sign-accumulating variable and generates the code to update the
sign. The |fin| method retrieves the names of both accumulators and
generates code to compute the final, signed determinant value.
\begin{code}
module AbstractDet =
  struct
  open C.Dom
  type tdet = v ref
  type 'a lstate = ('a,int ref) abstract * ('a,tdet) abstract
  let decl () = perform
      magn <-- retN (liftRef oneL);    (* track magnitude *)
      sign <-- retN (liftRef Idx.one); (* track the sign: +1, 0, -1 *)
      mo_extend ip (sign,magn);
      unitL
  let upd_sign () = perform
      (sign,_) <-- mo_lookup ip;
      ret (Some (assign sign (Idx.uminus (liftGet sign))))
  let fin = fun () -> perform
      (sign,magn) <-- mo_lookup ip;
      ifM (Logic.equalL (liftGet sign) Idx.zero) (ret zeroL)
      (ifM (Logic.equalL (liftGet sign) Idx.one) (ret (liftGet magn))
          (ret (uminusL (liftGet magn))))
  \dots
end
\end{code}

\subsection{Output}

More interesting is the aspect of what to return
from the LU algorithm.  One could create an algebraic data type (as
was done in \cite{Carette06}) to encode the various choices: the
matrix, the matrix and the rank, the matrix and the determinant, the
matrix, rank and determinant, and so on. This is wholly unsatisfying
as we know that for any single use, only one of the choices is ever
possible, yet any routine which calls the generated code must deal
with these unreachable options.  Instead we use a module type with an
\emph{abstract} type |res| for the result type; different instances of
the signature set the result type differently. Given below is this
module type and one instantiation, which specifies the output of a LU
algorithm as a 3-tuple |contr * Det.outdet * int| of the U-factor, the
determinant and the rank.

\begin{code}
module type OUTPUTDEP = sig 
    module PivotRep : PIVOTKIND 
    module Det      : DETERMINANT
end
module type INTERNAL_FEATURES = sig
  module R      : TrackRank.RANK
  module P      : TRACKPIVOT
  module L      : LOWER
end
module type OUTPUT = functor(OD : OUTPUTDEP) -> sig
  module IF : INTERNAL_FEATURES
  type res
  val make_result : 'a wmatrix -> (<classif: 'a;\dots>,res) cmonad
end
module OutDetRank(OD : OUTPUTDEP) = struct
  module IF = struct
    module R   = Rank
    module P   = DiscardPivot
    module L   = NoLower end
  type res = C.contr * C.Dom.v * int
  let make_result m = perform
    det  <-- OD.Det.fin ();
    rank <-- IF.R.fin ();
    ret (Tuple.tup3 m.matrix det rank)
  let _ = OD.Det.fin ()
  let _ = IF.R.fin ()
end
\end{code}

The initialization expressions |OD.Det.fin ()| and |IF.R.fin ()| are
the preflight checks. As we saw in the previous section, 
both instances of |DETERMINANT| contain a |fin ()| function to generate
code representing the computed determinant. Only the |NoDet| does not
track any determinant, and so |fin ()| raises an error. The code 
|let _ = OD.Det.fin ()| in |OutDetRank| invokes this |fin| function, which will
produce the monadic code generating action, or raise an error. We do
not run the action at that time -- we only make sure there is an
action to run. This is another preflight check, to rule out the
semantic error where a user specifies that the determinant should be computed
and returned, and yet specifies the |NoDet| aspect which tracks no
determinant at all.

The type |wmatrix| is for convenience, a bundling of several pieces
of data which are needed by both the |OUTPUT| aspect and the |PIVOT| 
aspect.  It is defined as
\begin{code}
type 'a wmatrix = {matrix: 'a C.vc; numrow: ('a,int) abstract; 
                   numcol: ('a,int) abstract}
\end{code}

The module of signature |INTERNAL_FEATURES| bundles information
tracking aspects. The latter are not directly selectable by the
user. Rather, they are \emph{functions} of other user choices. The
implementations of the tracking aspects such as |Rank|, |NoRank|,
|PackedLower| are quite similar (and simpler) than the implementation
of the |AbstractDet| and |NoDet| aspects in Section~\ref{sec:det}. The
choice of a particular tracking aspect may depend on all other choices
(e.g., it is not possible to extract the |L| factor if the domain is
not a field). Currently we use preflight checks to ensure consistency
of tracking aspects. Previously~\cite{CaretteKiselyov05} we tried to
implement all our preflight tests at the (module) type level, using
sharing constraints and module computations. That lead to obscure
code, long impenetrable type error messages and made compilation very
slow.  Furthermore, at least in OCaml, type-level computations are not
powerful enough to help us with tasks such as verifying that an integer
is prime, as required in section~\ref{sec:domains}.

\subsection{Main generation}
We combine all user-selectable aspects in a record, which serves as a ``keyword
argument'' list to the |GenGE| functor below.
\begin{code}
module type FEATURES = sig
  module Det       : DETERMINANT
  module PivotF    : PIVOT
  module PivotRep  : PIVOTKIND
  module Update    : UPDATE
  module Input     : INPUT
  module Output    : OUTPUT
end
\end{code}

\begin{code}
module GVC_I = GenericVectorContainer(IntegerDomainL)
module G_GVC_I = GenLA(GVC_I)
open G_GVC_I
open G_GVC_I.GE
module GenIV5 = GenGE(struct 
    module Det = AbstractDet
    module PivotF = FullPivot
    module PivotRep = PermList
    module Update = FractionFreeUpdate
    module Input = InpJustMatrix
    module Output = OutDetRank end)
let instantiate gen =
    .<fun a -> .~(runM (gen .<a>.) []) >.;;
let resIV5 = instantiate GenIV5.gen ;;
\end{code}
%
We first instantiate the container |GVC_I| for a vector over an
integer domain.  |GenGE| is then one functor of many algorithm
generators from a linear algebra library; since all our linear algebra codes
are parameterized by the container and the domain included in it,
We pass the container to the main functor |GenLA|.
We open the resulting |G_GVC_I| module
to make all its components easily available. One of those components
is the GE generator, |GE| (which we open as well). Besides |GE|, the
module |G_GVC_I| includes the generator for GE-based solvers.  The main
generator functor is |GenGE|, shown later.  We instantiate the
generator by passing to the functor the ``record'' of various aspects; the
order is irrelevant, but all aspects such as |Det| must be
specified. In the code above, we request GE generation with full
pivot, fraction-free update, operate on non-augmented matrix and
return the |U| factor, determinant and the rank. We run the monad
passing the initial state |[]| and obtain the code, which we can see
by printing |resIV5|. The code can then be ``compiled'' as |!. resIV5|
or with offshoring\cite{offshoring}. The code for |resIV5|
(App.~\ref{app:code-GenIV5}) shows full
pivoting, determinant and rank tracking. The code for all these
aspects is fully inlined; no extra functions are invoked and no tests
other than those needed by the LU algorithm itself are performed. The
resulting function returns a triple |int array * int * int| of the
U-factor, determinant and the rank.

The following is another instantiation of the GE generator, with a
different set of aspects.
\begin{code}
module GAC_F = GenericArrayContainer(FloatDomainL)
module G_GAC_F = GenLA(GAC_F)
open G_GAC_F
open G_GAC_F.GE
module GenFA9 = GenGE(struct 
    module Det = NoDet
    module PivotF = RowPivot
    module PivotRep = PermList
    module Update = DivisionUpdate
    module Input = InpJustMatrix
    module Output = Out_LU_Packed end)
\end{code}
The code generated by |GenFA9| (App.~\ref{app:code-GenFA9}) shows no traces of
determinant tracking whatsoever: no declaration of spurious variables,
no extra tests, etc. The code appears as if the determinant tracking
aspect did not exist at all. The generated code for the above and
other instantiations of |Gen| can be examined at
\cite{metamonadsURL}. The website also contains benchmark code and
timing comparisons.

The LU generator functor (called |GenGE| below) itself is 
parameterized by the domain, container, pivoting policy (full, row,
nonzero, no pivoting), update policy (with either `fraction-less'
or full division), and the output specification. Some of the
argument modules such as |PIVOT| are functors themselves (parameterized
by the domain, the container, and the determinant functor). It is 
worthwhile noting that we make sure of module subtyping -- |F| is of
type |FEATURES| while |F.Output| is expecting an |OUTPUTDEP|, but
|OUTPUTDEP| is a subtype of |FEATURES|.

\begin{code2}
module GenGE(F : FEATURES) = struct
  module O = F.Output(F)

  let wants_pack = O.IF.L.wants_pack
  let can_pack   = 
    let module U = F.Update(F.Det) in
    (U.upd_kind = DivisionBased)
  (* some more preflight tests *)
  let _ = ensure ((not wants_pack) || can_pack) 
         "Cannot return a packed L in this case"

  let zerobelow mat pos = 
    let module IF = O.IF in
    let module U = F.Update(F.Det) in
    let innerbody j bjc = perform
      whenM (Logic.notequalL bjc C.Dom.zeroL ) (perform
        det <-- F.Det.get_magn ();
        optSeqM (Iters.col_iter mat.matrix j (Idx.succ pos.p.colpos) 
         (Idx.pred mat.numcol) C.getL
              (fun k bjk -> perform
              brk <-- ret (C.getL mat.matrix pos.p.rowpos k);
              U.update bjc pos.curval brk bjk 
                (fun ov -> C.col_head_set mat.matrix j k ov) det) UP )
              (IF.L.updt mat.matrix j pos.p.colpos C.Dom.zeroL 
                (* this makes no sense outside a field! *)
                (C.Dom.divL bjc pos.curval))) in
      perform
        seqM (Iters.row_iter mat.matrix pos.p.colpos
               (Idx.succ pos.p.rowpos)
               (Idx.pred mat.numrow) C.getL innerbody UP)
             (U.update_det pos.curval)

 let init input = perform
    let module IF = O.IF in
      (a,rmar,augmented) <-- F.Input.get_input input;
      r <-- IF.R.decl ();
      c <-- retN (liftRef Idx.zero);
      b <-- retN (C.mapper C.Dom.normalizerL (C.copy a));
      m <-- retN (C.dim1 a);
      rmar <-- retN rmar;
      n <-- if augmented then retN (C.dim2 a) else ret rmar;
      F.Det.decl ();
      IF.P.decl rmar;
      _ <-- IF.L.decl (if wants_pack then b else C.identity rmar m);
      let mat = \{matrix=b; numrow=n; numcol=m\} in
      ret (mat, r, c, rmar)

 let forward_elim (mat, r, c, rmar) = perform
    let module IF = O.IF in
      whileM (Logic.andL (Idx.less (liftGet c) mat.numcol)
                          (Idx.less (liftGet r) rmar) )
       ( perform
       rr <-- retN (liftGet r);
       cc <-- retN (liftGet c);
       let cp  = \{rowpos=rr; colpos=cc\} in
       let module Pivot = F.PivotF(F.Det)(IF.P) in
       pivot <-- bind (Pivot.findpivot mat cp) retN;
       seqM (matchM pivot (fun pv -> 
              seqM (zerobelow mat \{p=cp; curval=pv\} )
                   (IF.R.succ ()) )
              (F.Det.zero_sign () ))
            (updateM c Idx.succ) )

 let gen input = perform
    (mat, r, c, rmar) <-- init input;
    seqM 
      (forward_elim (mat, r, c, rmar))
      (O.make_result mat)
end
\end{code2}

A careful reading of this code will reveal that the core of the 
Gaussian Elimination algorithm is still visible in this code generator:
the |forward_elim| function iterates over the columns and rows of the
matrix, finding a pivot, and zeroing the appropriate entries.

There are more preflight checks for various ``semantic'' constraints, shown
in the following structure of the |UPDATE| signature:
\begin{code}
module DivisionUpdate(Det:DETERMINANT) =
  struct
  open C.Dom = struct 
  let _ = assert (C.Dom.kind = Domains_sig.Domain_is_Field)
end
\end{code}
%
This structure implements an update policy relying on
unrestricted |Dom.div|. Many domains provide |Dom.div|, for example,
the integer domain. The latter however assumes that division is applied
only if the dividend is the exact multiple of the divisor. Thus if we
specified |module Update = DivisionUpdate| when instantiating |GenIV5|
above, we would have received an error because |IntegerDomainL| is not
a field. That run-time error occurs before any code is produced (i.e.,
before |resIV5| is computed).

\section{Related and future work}\label{related}

The monad in this paper is similar to the one described in
\cite{SwadiMonadic06,KiselyovTaha}.  However those papers used only
|retN| and fixpoints (for generation-time iterations).  This paper
does not involve monadic fixpoints because the generator is not
recursive, but heavily relies on monadic operations for generating
conditionals and loops.

|Blitz++| \cite{Veldhuizen:1998:ISCOPE} and {C++} template
meta-programming in general similarly eliminate levels
of abstraction.  With traits and concepts, some domain-specific
knowledge can also be encoded.  However overhead elimination
critically depends on full inlining of all methods by the compiler,
which has been reported to be challenging to insure. Furthermore, all
errors (such as type errors and concept violation errors, i.e.,
composition errors) are detected only when compiling the generated
code. It is immensely difficult to correlate errors (e.g., line
numbers) to the ones in the generator itself.

ATLAS \cite{ATLAS} is another successful project in this area.
However they use much simpler weaving technology, which leads them to
note that \emph{generator complexity tends to go up along with
  flexibility, so that these routines become almost insurmountable
  barriers to outside contribution}. Our results show how to surmount
this barrier, by building modular, composable generators. A
significant part of ATLAS' complexity is that the generator is
extremely error-prone and difficult to debug.  Indeed, when generating
C code in C using |printf|, nothing prevents producing code that
misses semicolons, open or close parentheses or variable
bindings. MetaOCaml gives us assurance that these errors, and more
subtle type errors, shall not occur in the generated code.  SPIRAL
\cite{Pueschel:05} is another even more ambitious project.  But
SPIRAL does intentional code analysis, relying on a set of code
transformation ``rules'' which make sense, but which are not proven to
be either complete or confluent.  The strength of both of these
project relies on their platform-specific optimizations performed via
search techniques, something we have not attempted here.

The highly parametric version of our Gaussian Elimination is directly
influenced by the generic implementations available in Axiom
\cite{Axiom} and Aldor \cite{Watt:2002:HCA}.  Even though the Aldor
compiler can frequently optimize away a lot of abstraction overhead, 
it does not provide any guarantees that it will do so, unlike our
approach.

We should also mention early work \cite{Gluck95} on automatic
specialization of mathematical algorithms. Although it can eliminate
some overhead from a very generic implementation (e.g., by inlining
aspects implemented as higher-order functions), specialization cannot
change the type of the function and cannot efficiently handle aspects
that communicate via a private shared state.

The paper \cite{GluckJ97} describes early simple experiments in
\emph{automatic} and manual staging, and the multi-level language
based on an annotated subset of Scheme (which is untyped and has no
imperative features). The generated code requires post-processing to
attain efficiency.  

Our code was initially motivated by trying to unify the various
implementations in Maple.  Interestingly, when we compare our end 
result with the options available from Maple's \texttt{LUDecomposition}
algorithm, we notice a great deal of similarity.  The biggest difference
is that in Maple, all the choices are done dynamically (and are dynamically
typed), while ours choices are done statically, in a statically typed
environment.  To us, this shows that the
design space along the dynamic--static dimension is quite large and
versatile.

Unlike traditional approaches
\cite{journals/cacm/parnas72a}, the interfaces of our generated
routines vary depending on the choices of input and output
aspects. Dynamic approaches in Object-oriented languages (late binding
and dynamic dispatch) or functional languages (Haskell's
dictionary-based \emph{type classes}) also offer flexibility of
interfaces. In our approach, however, it is the generator that
produces code whose interfaces depend on the arguments of the
generator. The interfaces of the generated routines are all fixed and
hence efficient.

To the best of our knowledge, nobody has yet used functors to
abstract code generators, or even mixed functors and 
multi-stage programming.

It would be interesting to implement a camlp4 extension that 
automates the lifting of (simple) modules as done in 
section~\ref{sec:lifteddomains},
first to the code level, and then to monadic values.  Even more
interesting would be a (typed) extension to MetaOCaml that would 
allow us to write such code with the same guarantees that the rest of
MetaOCaml already affords us.

We plan to further investigate the connection between delimited
continuations and our implementations of code generators like
|ifM|. The ultimate (and plausible) goal is to write a numerical
algorithm in (almost) regular OCaml once, and being able to either
run it as a regular OCaml program, or turn into a code generating
aspect.

There are many more aspects which can also be handled:
error reporting (i.e. asking for the determinant of a 
non-square matrix), memory hierarchy issues, loop-unrolling
\cite{scp-CohenDGHKP06},
warnings when zero-testing is undecidable and
a value is only probabilistically non-zero, etc.

\section{Conclusion}\label{conclusion}
In this paper we have demonstrated numerical code extensively parameterized
by complex aspects at no run-time overhead.  The combination of
stateless functors and structures, and our monad with
compositional state makes aspects composable without having to
worry about value aliasing. The only constraints to compositionality
are the typing ones plus the constraints we specifically
impose, including semantic constraints (e.g., rings do not have full
division).

\subsection{On aspects}

There is an interesting relation with aspect-oriented code
\cite{kiczales97aspectoriented}: in AspectJ, 
aspects are (comparatively) lightly typed, and are post-facto extensions of
potential program traces, specified in a particular language; these tend
to be created to follow the operational behaviour of existing code, but
is not restricted to such a setting.
In our work, aspects are weaved together ``from scratch'' to
make up a piece of code.  One can understand previous work to be
more akin to dynamically typed, and dynamically specified aspect weaving, while
we have started investigating statically typed and statically specified
aspect weaving.

While the first two families of aspects (abstract domain and concrete
representation) are the most obvious, it is quite difficult to
separate them out cleanly. Attempts at such a separation in a
non-staged setting, have lead to fantastically inefficient code,
unacceptable for scientific computation. Staging permitted us, perhaps
for the first time, to think in terms of an ideal design without
worrying about abstraction penalties.  Interestingly, in conversations
of the first author with D. Parnas, we discovered this is
apparently what~\cite{journals/cacm/parnas72a} was advocating.  We
believe that we are taking the first steps towards a \emph{typed yet
  efficient} realization of these ideas, where the various design-time
entities can be directly encoded in machine-checkable form.

\subsection{Methodology}

Our overall approach can best be described as a combination 
of two approaches: hand-writing a code generator (cogen) suitable
for multi-level specialization \cite{Gluck95,GluckJ97} and creating
an embedded domain-specific language (EDSL) \cite{edsl,WhenHowDSL}.
Our approach, using staging, monads and functors, seems to permit 
an extensible set of aspects and appears flexible enough for iterative
improvement in the design.

%\oleg{I'm inclined to suggest to omit the following, or at least
%  abbreviate. The omitting may be the best option as we don't have
%  much time for editing. The problem with explaining methodology is
%  like explaining Buddhism: it is all obvious. As I read about Zen
%  Buddhism: its simple truths are understandable if you already know
%  them.}
%
%\jacques{All obvious, but worthwhile documenting anyways.  I really
%  like reading papers where the ``obvious truth'' is explained in
%  clear enough ways that I nevertheless learn something new.  Sometimes,
%  all one really learns is a better vocabulary for describing something
%  known, but that is already quite useful.  So I leave it in.}

As we wanted to ensure that we were indeed firmly in a \emph{cogen} setting,
we abstracted out the underlying programming language completely.  This 
allowed us to both generate (efficient) code and to write a directly
runnable (but highly inefficient) version of the algorithm from the same
generator.  But this
essentially abstracted out all of the syntactic sugar of the underlying
programming language, and all we were left with was function application
and monadic composition.  This means the code for our generator looks mostly
like Scheme with added syntax for monads!

More specifically we start from a \emph{known} set of implementations
of an algorithm, and extract commonalities and variation points.
This is unlike~\cite{journals/tse/Parnas76} and most subsequent
approaches to product families, as we do not over-engineer our design
by imagining variations that are unlikely to come up in realistic
situations, but only create variations when we notice them in actual use.
This approach is quite well-suited to the development of scientific
software, which has a rich history and where most useful variations have
already appeared in some form.

Given a set of commonalities and variation points, the first task is to
find \emph{semantic} reasons for these.  The underlying reason then
forms the basis for the abstraction -- a (potentially higher-order)
module is created to encapsulate the various concepts, and these are
implemented as generators.  It is very important at this stage to
make sure to reify all available \emph{static} information, so that all
of it is available to the generation process.  While we will see that
the technical solutions exist to take advantage of such information,
it is still a difficult design problem to properly encode this information.
One important item is to try to keep the various pieces of generation-time
information as orthogonal as possible.  This is unlike ordinary encodings
of run-time information, where compression and elision frequently lead
to increased efficiency.  Whenever dependency between various bits of
information is
inevitable, then higher-order encodings should be sought.  When choices
need to be made based on some (static) information, it is important to
encode this information by using semantic concepts.

\subsection*{Acknowledgments}
We wish to thank Cristiano Calgano for his help in adapting camlp4 for
use with MetaOCaml. Many helpful discussions with Walid Taha are very
appreciated. The implementation of the monadic notation, |perform|,
was joint work with Lydia van Dijk.

% Embed .bbl file directly to make document self-contained
\bibliography{metamonads}
\bibliographystyle{elsart-num}

%% \begin{thebibliography}{10}
%% \expandafter\ifx\csname url\endcsname\relax
%%   \def\url#1{\texttt{#1}}\fi
%% \expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi

\appendix
\section{The \texttt{perform} monad notation}
\label{app:perform}
We support four different constructs to introduce a monadic
expressions:
\begin{code}
  perform exp
  perform exp1; exp2
  perform x <-- exp1; exp2
  perform let x = foo in exp
\end{code}
which is almost literally the grammar of the Haskell's "do"-notation,
with the differences that Haskell uses |do| and |<-| where we use
|perform| and |<--|.
We support not only |let x = foo in ...|  expressions but arbitrarily
complex let-expressions, including |let rec| and |let module|.

The actual bind function of the monad defaults to |bind| and the
pattern-match--failure function to |failwith| (only used for refutable
patterns).  Extended forms of |perform| let us override these
defaults. For example, to use the function named 
|bind| from module |Mod|, we write
\begin{code}
        perform with module Mod in exp2
\end{code}

\section{Code of the \texttt{GenIV5} algorithm}
\label{app:code-GenIV5}
The code generated for |GenIV5|, fraction-free LU of the integer matrix
represented by a flat vector, full pivoting, returning the |U|-factor,
the determinant and the rank.
\begin{code2}
val resIV5 : ('a, GVC_I.contr -> GenIV5.O.res) code =
  .<fun a_1 ->
   let t_2 = (ref 0) in
   let t_3 = (ref 0) in
   let t_4 = (a_1) \{arr = (Array.copy a_1.arr)\} in
   let t_5 = a_1.m in  (* magnitude of det *)
   let t_6 = a_1.n in  (* sign of the det *)
   let t_7 = (ref 1) in
   let t_8 = (ref 1) in
   while (((! t_3) < t_5) && ((! t_2) < t_6)) do
    let t_13 = (! t_2) in
    let t_14 = (! t_3) in
    let t_15 = (ref (None)) in
    let t_34 =
     begin (* full pivoting, search for the pivot *)
      for j_30 = t_13 to (t_6 - 1) do
       for j_31 = t_14 to (t_5 - 1) do
        let t_32 = (t_4.arr).((j_30 * t_4.m) + j_31) in
        if (t_32 <> 0) then
         (match (! t_15) with
          | Some (i_33) ->
             if ((abs (snd i_33)) > (abs t_32)) then
              (t_15 := (Some ((j_30, j_31), t_32)))
             else ()
          | None -> (t_15 := (Some ((j_30, j_31), t_32))))
        else ()
       done
      done;
      (match (! t_15) with
       | Some (i_16) -> (* swapping of columns *)
          if ((snd (fst i_16)) <> t_14) then begin
           let a_23 = t_4.arr
           and nm_24 = (t_4.n * t_4.m)
           and m_25 = t_4.m in
           let rec loop_26 =
            fun i1_27 ->
             fun i2_28 ->
              if (i2_28 < nm_24) then
               let t_29 = a_23.(i1_27) in
               a_23.(i1_27) <- a_23.(i2_28);
               a_23.(i2_28) <- t_29;
               (loop_26 (i1_27 + m_25) (i2_28 + m_25))
              else () in
           (loop_26 t_14 (snd (fst i_16)));
           (t_8 := (~- (! t_8))) (* adjust the sign of det *)
          end else ();
          if ((fst (fst i_16)) <> t_13) then begin (* swapping of rows *)
           let a_17 = t_4.arr
           and m_18 = t_4.m in
           let i1_19 = (t_13 * m_18)
           and i2_20 = ((snd (fst i_16)) * m_18) in
           for i_21 = 0 to (m_18 - 1) do
            let t_22 = a_17.(i1_19 + i_21) in
            a_17.(i1_19 + i_21) <- a_17.(i2_20 + i_21);
            a_17.(i2_20 + i_21) <- t_22
           done;
           (t_8 := (~- (! t_8)))
          end else ();
          (Some (snd i_16))
       | None -> (None))
     end in
    (match t_34 with
     | Some (i_35) ->
        begin (* elimination loop *)
         for j_36 = (t_13 + 1) to (t_6 - 1) do
          let t_37 = (t_4.arr).((j_36 * t_4.m) + t_14) in
          if (t_37 <> 0) then begin
           for j_38 = (t_14 + 1) to (t_5 - 1) do
            (t_4.arr).((j_36 * t_4.m) + j_38) <-
             ((((t_4.arr).((j_36 * t_4.m) + j_38) * i_35) -
                ((t_4.arr).((t_13 * t_4.m) + j_38) * t_37)) / (! t_7))
           done;
           (t_4.arr).((j_36 * t_4.m) + t_14) <- 0
          end else ()
         done;
         (t_7 := i_35)
        end;
        (t_2 := ((! t_2) + 1)) (* advance the rank *)
     | None -> (t_8 := 0));
    (t_3 := ((! t_3) + 1))
   done;
   (t_4, (* matrix with the U factor *)
    if ((! t_8) = 0) then 0 (* adjust the sign of the determinant *)
    else if ((! t_8) = 1) then (! t_7)
    else (~- (! t_7)), (! t_2))>.
\end{code2}

\section{Code of the \texttt{GenFA9} algorithm}
\label{app:code-GenFA9}
The code generated for |GenFA9|, LU of the floating point
non-augmented matrix
represented by a 2D array, row pivoting, returning the complete
factorization: |L| and |U|
factors packed in a single matrix and the permutation matrix
represented as the list of row number exchanges.
\begin{code2}
val resFA9 : ('a, GAC_F.contr -> GenFA9.O.res) code =
  .<fun a_1 ->
   let t_2 = (ref 0) in
   let t_3 = (ref 0) in
   let t_5 = (Array.map (fun x_4 -> (Array.copy x_4)) (Array.copy a_1)) in
   let t_6 = (Array.length a_1.(0)) in
   let t_7 = (Array.length a_1) in
   let t_8 = (ref ([])) in  (* accumulate permutations in a list *)
   while (((! t_3) < t_6) && ((! t_2) < t_7)) do
    let t_9 = (! t_2) in
    let t_10 = (! t_3) in
    let t_11 = (ref (None)) in
    let t_17 =
     begin   (* row pivoting *)
      for j_14 = t_9 to (t_7 - 1) do
       let t_15 = (t_5.(j_14)).(t_10) in
       if (t_15 <> 0.) then
        (match (! t_11) with
         | Some (i_16) ->
            if ((abs_float (snd i_16)) < (abs_float t_15)) then
             (t_11 := (Some (j_14, t_15)))
            else ()
         | None -> (t_11 := (Some (j_14, t_15))))
       else ()
      done;
      (match (! t_11) with  (* swapping of rows *)
       | Some (i_12) ->
          if ((fst i_12) <> t_9) then begin
           let t_13 = t_5.(t_9) in
           t_5.(t_9) <- t_5.(fst i_12);
           t_5.(fst i_12) <- t_13;  (* and accumulate permutations *)
           (t_8 := ((RowSwap ((fst i_12), t_9)) :: (! t_8)))
          end else ();
          (Some (snd i_12))
       | None -> (None))
     end in
    (match t_17 with  (* elimination loop *)
     | Some (i_18) ->
        begin
         for j_19 = (t_9 + 1) to (t_7 - 1) do
          let t_20 = (t_5.(j_19)).(t_10) in
          if (t_20 <> 0.) then
           for j_21 = (t_10 + 1) to (t_6 - 1) do
            (t_5.(j_19)).(j_21) <-
             ((t_5.(j_19)).(j_21) -. ((t_20 /. i_18) *. (t_5.(t_9)).(j_21)))
           done
          else ()
         done;
         ()
        end;
        (t_2 := ((! t_2) + 1))
     | None -> ());
    (t_3 := ((! t_3) + 1))
   done;
   (t_5, (! t_8))>. (* return both L and U factors, list permutations *)
\end{code2}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% all the text that used to be here is now in unused.tex
% same with any text in an \omitnow

