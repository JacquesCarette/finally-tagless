\documentclass[draft]{elsart}

% Reduce display spacing
\divide\abovedisplayskip 2
\divide\belowdisplayskip 2
\divide\abovedisplayshortskip 2
\divide\belowdisplayshortskip 2

\usepackage{hyphenat}
\usepackage{comment}
\usepackage{amsmath,amssymb}
\usepackage{amstext}
\usepackage{url}
\usepackage[dvips]{color}

\usepackage{ifpdf}
\ifpdf
    \pdfpageheight=11in
    \pdfpagewidth=8.5in
\fi

%\usepackage{refrange}

%\usepackage[medium,compact]{titlesec}

\usepackage{fancyvrb}
\DefineShortVerb{\|}
\DefineVerbatimEnvironment{code}{Verbatim}{xleftmargin=\ourmathindent,commandchars=\\\{\},fontsize=\small}
\DefineVerbatimEnvironment{code2}{Verbatim}{xleftmargin=\ourmathindent,commandchars=\\\{\},fontsize=\small}
\newcommand{\evalresult}[1]{\ensuremath{\Longrightarrow}\textcolor{red}{#1}}
% \setlength{\parskip}{0pt}
\newlength{\ourmathindent}
\setlength{\ourmathindent}{1em}

% \usepackage[backref,colorlinks,bookmarks=true]{hyperref}

% Reduce list spacing
%% \makeatletter
%% \renewcommand\@@listI{\leftmargin\leftmargini
%% \parsep \z@@
%% \topsep 3\p@@ \@@plus\p@@ \@@minus 2\p@@
%% \itemsep 2\p@@ \@@plus\p@@ \@@minus\p@@}
%% \let\@@listi\@@listI
%% \@@listi
%% \makeatother

% \parskip 0pt plus 1pt minus 2pt
\textfloatsep 4pt plus 2pt minus 3pt % Less space around figures
%\abovecaptionskip 0pt plus 0pt minus 2pt
%\belowcaptionskip 0pt plus 0pt minus 2pt

% \intextsep 2pt plus 0pt minus 1pt

\renewcommand\floatpagefraction{.95}
\renewcommand\topfraction{.95}
\renewcommand\bottomfraction{.95}
\renewcommand\textfraction{.05}   
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}

\newcommand{\omitnow}[1]{}
\newcommand{\oleg}[1]{{\it [Oleg says: #1]}}
\newcommand{\jacques}[1]{{\it [Jacques says: #1]}}

%
% Useful abbreviations
%
\newcommand{\floats}{\mathbb{F}}
\newcommand{\reals}{\mathbb{R}}

\journal{Science of Computer Programming}

\begin{document}
%\title{Functors, CPS and monads, or how to generate efficient
%code from abstract designs}
\begin{frontmatter}
\title{Multi-stage programming with functors and monads:
eliminating abstraction overhead from generic code}
\author{Jacques Carette\thanksref{1}}
\address{McMaster University,
1280 Main St. West, Hamilton, Ontario Canada L8S 4K1}
\ead{carette@mcmaster.ca}
\ead[url]{http://www.cas.mcmaster.ca/\textasciitilde carette}
\author{Oleg Kiselyov}
\address{FNMOC, Monterey, CA 93943}
\ead{oleg@pobox.com}
\ead[url]{http://pobox.com/\textasciitilde oleg/ftp/}

\thanks[1]{Supported in part by NSERC Discovery Grant RPG262084-03.}

\begin{abstract}
We use multi-stage programming, monads and OCaml's
advanced module system to demonstrate how to eliminate all
abstraction overhead while avoiding any inspection of the resulting
code.  We demonstrate this clearly with LU decomposition as a 
representative family of symbolic and numeric algorithms, and also
include an application to solving ordinary differential equations 
(via a Runge-Kutta algorithm).
We parameterize our code to a great extent
(over domain, matrix representations, determinant tracking, 
pivoting policies, result types, etc) at no run-time cost.  Because
the resulting code is generated just right and not changed afterwards,
MetaOCaml guarantees that the generated code is well-typed.
We further demonstrate that various abstraction parameters (aspects)
can be made orthogonal and compositional, even in the presence of
name-generation for temporaries, and 
``interleaving'' of aspects.  We also show how to encode some
domain-specific knowledge so that ``clearly wrong'' compositions can
be rejected at or before generation time rather than during
the compilation or running of the generated code.
\end{abstract}

\begin{keyword}
MetaOCaml \sep linear algebra \sep genericity \sep generative \sep staging
\sep Functor \sep symbolic.
\end{keyword}
% Should use either PACS or MSC scheme
\end{frontmatter}

\section{Introduction}

In high-performance symbolic and numeric computing, there is a
well-known issue of balancing between maximal performance and the
level of abstraction at which code is written.  Furthermore, already
in linear algebra, there is a wealth of different aspects that
\emph{may} need to be addressed. Implementations of the
widely used LU decomposition algorithm (which subsumes Gaussian 
Elimination (GE)) --- the running
example of our paper --- may need to account for the representation of
the matrix, whether to compute and return the determinant or rank, how
and whether search for a pivot, etc. Furthermore, current architectures
demand more and more frequent tweaks which, in general, cannot be done by the
compiler because the tweaking often involves domain knowledge. 

A survey \cite{carette04} of
Gaussian elimination implementations in the industrial package Maple
found 6 clearly identifiable aspects and 35 different implementations of the
algorithm, as well as 45 implementations of directly related algorithms such as
LU decomposition, Cholesky decomposition, and so on.  We could
manually write each of these implementations optimizing for particular aspects
and using cut-and-paste to ``share'' similar pieces of code.
Or we can write a very generic procedure that accounts for
all the aspects with appropriate abstractions \cite{Axiom}. The
abstraction mechanisms however -- be they procedure, method or a
function call -- have a significant cost, especially for
high-performance numerical computing \cite{carette04}. 

A more appealing approach is generative programming
\cite{Czarnecki,Veldhuizen:1998:ISCOPE,musser94algorithmoriented,BOOST,POOMA,ATLAS}.
The approach is not without problems, e.g., making sure that the
generated code is well-formed. This is a challenge in string-based
generation systems, which generally do not offer any guarantees and
therefore make it very difficult to determine which part of the
generator is at fault when the generated code cannot be parsed. Other
problems is preventing accidental variable capture (so-called hygiene
\cite{HygienicMacros}) and ensuring the generated code is
well-typed. Lisp-style macros, Scheme hygienic macros, the camlp4
preprocessor \cite{camlp4}, C++ template meta-programming, and Template
Haskell \cite{conf/dagstuhl/CzarneckiOST03} solve some of the above
problems. Of the widely available maintainable languages, only
MetaOCaml \cite{CTHL03,metaocaml-org}  solves all the above problems
including the well-typing of both the generator and 
the generated code \cite{TahaSheard97,TahaThesis}.

But more difficult problems remain. Is the generated code optimal? Do
we still need post-processing to eliminate common subexpressions,
fold constants, and remove redundant bindings? Is the generator readable,
resembling the original algorithm? Is the generator extensible? Are the aspects
truly modular? Can we add another aspect to it or another instance of
the existing aspect without affecting the existing ones? Finally, can
we express domain-specific knowledge, e.g., one should not attempt to
use full division when dealing with matrices of exact integers, nor is
it worthwhile to use full pivoting on a matrix over $\mathbb Q$.

MetaOCaml is \emph{generative}: generated code can only be treated as
a black box: it cannot be inspected and it cannot be post-processed
(i.e., no intensional analysis). This approach gives a stronger
equational theory \cite{Taha2000}, and avoids the danger of creating
unsoundness \cite{TahaThesis}. Furthermore, intensional code analysis
essentially requires one to insert both an optimizing compiler and an
automated theorem proving system into the code generating system
\cite{Pueschel:05,Kennedy01Telescoping,dongarra7,Veldhuizen:2004}.
While this is potentially extremely powerful and an exciting area of
research, it is also extremely complex, which means that it is
currently more error-prone and difficult to ascertain the correctness
of the resulting code.

Therefore, in MetaOCaml, code must be generated just right (see
\cite{TahaThesis} for many simple examples).  For more complex
examples, new techniques are necessary, e.g., abstract interpretation
\cite{KiselyovTaha}.  But more problems remain
\cite{Padua:MetaOcaml:04}: generating binding forms (``names'')
when generating loop bodies or conditional branches; making
continuation-passing style (CPS) code clear.  Many authors
understandably shy away from CPS code as it quickly becomes
unreadable.  But this is needed for proper name generation.
The problems of compositionality of code generators, expressing
dependencies among them and domain-specific knowledge remain.

In this paper, we report on our continued progress \cite{CaretteKiselyov05}
\oleg{should we say in the footnote: ``compared to the earlier,
  conference version of this paper we describe a different
  version of our generator dealing with the complete LU decomposition
  and solving. We worked out previously missing aspects of in-place
  updates, representaing permutation matrix, augmented input matrix,
  and back-propagation. We have changed the representation of
  domain-specific knowledge about permissible compositions of aspects.''}
the code generating LU decomposition and solving 
solving these problems using linear solving and LU decomposition
as our running example. Specifically, our contributions:
\begin{itemize}
    \item Extending a let-insertion, memoizing monad of
      \cite{MSP:PADL04,KiselyovTaha} for generating control structures
      such as loops and conditionals. The extension is non-trivial
      because of control dependencies and because
      let-insertion, as we argue, is a control effect on its own.
      : e.g.,\\
      |let x = exp in ...| has a different \emph{effect} within a
      conditional branch.
    \item Implementation of the |perform|-notation (patterned after
      |do|-notation of Haskell) to make monadic code readable.
    \item Use of functors (including higher-order functors) to
      modularize the generator, express aspects (including results of
      various types) and \emph{assure composability of aspects} even
      for aspects that use state and have to be accounted in many
      places in the generated code.
    \item Encode domain-specific knowledge in the generators which 
      will catch domain-specific instantiation errors at generation
      time.
    \item Provide a thorough breakdown of the family of LU decomposition
      algorithms.
\end{itemize}

The rest of this paper is structured as follows: The next section
gives an overview of the design space of LU decomposition algorithms,
as well as the methodology we follow.  Then section~\ref{CPS}
introduces code generation in MetaOCaml, the problem of name
generation, and continuation-passing style (CPS) as a general
solution.  We also present a key monad and the issues of generating
control statements. Section~\ref{functors} describes the use of
parametrized modules of OCaml to encode all of the aspects of the
LU decomposition algorithm family in completely separate,
independent modules.  Section~\ref{s:ode} describes generating
Runge-Kutta solvers for ordinary differential equations (ODE).
We briefly discuss related work in
section~\ref{related}. We then outline the future work and conclude.
Appendices give samples of the generated code (which is available in
full at \cite{metamonadsURL}).

\section{The design space}\label{design}

Before studying the details of the technologies involved in the 
implementation, it is worthwhile to carefully study the design space involved.
A preliminary study~\cite{carette04} revealed a number of aspects of the 
family of Gaussian Elimination algorithms.  In the present work, we outline
a number of additional aspects involved in the faimily of LU decomposition 
algorithms.  These will first be presented in a somewhat ad hoc manner, 
roughly coresponding to the order in which they were ``discovered''.  These
will then be reorganized into sets of semantically related aspects, which will
form the basis of our design.  Finally, we will extract a methodology from
our experience.  

Throughout, we assume that the reader is familiar with the basic LU
decomposition algorithm, which factors a invertible matrix $A$ into a unit
lower triangular matrix $L$ and (usually) an upper triangular matrix $U$,
such that $A = LU$.  When pivoting is used, we get a unitary matrix $P$ such
that the factorization is now $A = PLU$.  The case of numeric matrices is well
covered in~\cite{Golub-vanLoan}.  When $A$ is singular, one can still get
a $PLU$ decomposition, with $L$ remaining unit lower-triangular but with a
$U$ which is no longer upper triangular but instead ``staggered''
in the upper triangle.

\subsection{Aspects}

We reuse the english word ``aspect'' for the various facets of the family
of LU decomposition algorithms.  While this use if very much in the same 
spirit as in aspect-oriented programming (AOP)~\cite{Kiczales}, our 
implementation methodology is radically different.  We firmly believe that
our typed generative methodogy is much better suited to the functional
programming paradigm than attempting to graft the program-trace-based
methodology of object-oriented versions of AOP.  

At this point in time, it is better to think of aspects as purely
design-time entities.  Here we are firmly influenced by Parnas' original
view of modules and information hiding~\cite{journals/cacm/parnas72a} as well
as his view of product families \cite{Parnas??}, and by Dijkstra's ideas on
separation of concerns \cite{EWD:EWD447}.
To apply these principles to the study of LU decomposition, we need
to understand what are the changes between different implementations, and 
what concerns need to be addressed.  We also need to study the degree
to which these concerns are independent.

The various aspects listed below all come from variations found in actual
implementations (in various languages and settings).

\begin{enumerate}
	\item \textbf{Domain}: In which (algebraic) domain do the matrix
		elements belong to.  Some implementations were very specific
		($\mathbb{Z}, \mathbb{Q}, \mathbb{Z_p}, 
		\mathbb{Z}_p\left[\alpha_1,\ldots,\alpha_n\right], 
		\mathbb{Z}\left[x\right]$, $\mathbb{Q}\left(x\right)$, 
		$\mathbb{Q}\left[\alpha\right]$, and floating point numbers 
		($\floats$) for 
		example), while others were generic for elements of a field,
		multivariate polynomials over a field, or elements of a division ring
		with possibly undecidable zero-equivalence.  In the roughly 85 pieces
		of code we surveyed, 20 different domains were encountered.
	\item \textbf{Representation of the matrix}: Whether the matrix
		was represented as an array of arrays, a one-dimensional array,
		a hash table, etc.  For the case of a one-dimensional array,
		whether indexing was done in C or Fortran style.  Additionally,
		if a particular representation had a special mechanism for efficient
		row exchanges, this was sometimes used.
	\item \textbf{Fraction-free}: Whether the 
		algorithm is allowed to use unrestricted division, or only
		exact (remainder-free) division.
	\item \textbf{Length measure (for pivoting)}:  For stability reasons
		(whether numerical or coefficient growth), if a domain possesses
		an appropriate length measure, this was sometimes used to choose
		an ``optimal'' pivot.  Not all domains have such a measure.
	\item \textbf{Full division}: Whether the input domain supports full
		division (i.e. is a \emph{field} or pretends to be ($\floats$)) 
		or only exact division (i.e. a \emph{division ring}).
	\item \textbf{Domain normalization}: Whether the arithmetic operations
		of the base domain keep the results in normal form, or whether
		an extra normalization step is required.  For example, some 
		representations of polynomials require an extra step for
		zero-testing.
	\item \textbf{Output choices}:  Whether just the reduced matrix
		(the `U' factor), both L and U, as well as
		the rank, the determinant, and/or the sequence of 
		pivots is to be returned.  For example, Maple's
		\texttt{LinearAlgebra:-LUDecomposition} routine has
		$2^6 + 2^5 + 2^2 = 100$ possible outputs, depending on whether
		one chooses a $PLU$, $PLU^{1}R$ or \emph{Cholesky} 
		decomposition.  We chose to only consider $PLU$ for now.
	\item \textbf{Rank}: Whether to explicitly track the rank of the matrix
		as the algorithm proceeds.
	\item \textbf{Determinant}:  Whether to explicitly track the determinant
		of the matrix as the algorithm proceeds.
	\item \textbf{Code representation}: Whether we are actually generating
		code or we are in fact representation the algorithm in ``direct
		style'', albeit with a lot of abstraction overhead.
	\item \textbf{Zero-equivalence}: Whether the 
		arithmetic operations require a specialized zero-equivalence 
		routine needs to be used.  It turns out that for certain classes
		of \emph{expressions}, it is convenient to use a zero-equivalence
		test which is separate from the domain normalization.  This is
		usually the case when zero-equivalence is formally undecidable
		but semi-algorithms or probabilistic algorithms do exist.
		See~\cite{ZhCaJeMo07} for an example.
    \item \textbf{Pivoting}: Whether to use no, 
        column-wise, or full pivoting.
    \item \textbf{Augmented Matrices}: Whether all or only some
      columns of the matrix participate in elimination.
	\item \textbf{Pivot representation}: Whether the pivot is represented
	  as a list of row (and/or column) exchanges, as a unitary matrix,
	  or as a permutation vector.
  \item \textbf{Lower matrix}: whether the matrix $L$ should be tracked
	  as the algorithm proceeds, reconstructed at the end of the
	  algorithm, or not tracked at all.
  \item \textbf{Input choices}: Whether the input matrix is an augmented
	  matrix or not, and if so, where is the end of the main matrix.
  \item \textbf{Packed}: Whether the output matrices $L$ and $U$ are
	  packed into a single matrix for output.
\end{enumerate}

\noindent \jacques{Absorb this in the above} These are separated out from the
others as they are cross-cutting concerns: in the case of the length measure, a
property of the domain will influence the pivoting method \emph{if} pivoting is
to be performed.\jacques{Also, should mention a few more aspects like
inplace, errors-on-singular, logging, sparsity, as things that are not
implemented}

\subsection{Organizing aspects}

\subsection{Methodology}

\section{Generating binding statements, CPS, and monad}\label{CPS}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We build code generators out of primitive ones using code generation 
combinators. MetaOCaml, as an instance of a multi-stage
programming system \cite{TahaThesis}, provides exactly the needed
features: to construct a code expression, to combine them, and to
execute them. The following shows the simplest code generator |one|,
and the simplest code combinators\footnote{%
$\Longrightarrow$ under an expression shows the result of its evaluation}:

\begin{code}
let one = .<1>. and plus x y = .<.~x + .~y>.
let simplest_code = let gen x y = plus x (plus y one) in
  .<fun x y -> .~(gen .<x>. .<y>.)>.
\evalresult{.<fun x_1 -> fun y_2 -> (x_1 + (y_2 + 1))>.}
\end{code}

We use MetaOCaml brackets |.<...>.| to generate code expressions,
i.e., to construct future-stage computations. MetaOCaml provides only
one mechanism of combining code expressions, by inlining
\oleg{splicing?} one into
another. The power of that operation, called escape |.~|, comes from
the fact that the expression to be spliced in (inlined) can be
computed: escape lets us perform an arbitrary immediate code-generating
computation \emph{while} we are
building the future-stage computation. The immediate computation in
|simplest_code| is the evaluation of the function |gen|, which in turn
applies |plus|. The function |gen| receives code expressions |.<x>.|
and |.<y>.| as arguments. At the generating stage, we can manipulate
code expressions as (opaque) values. The function |gen| returns a code
expression, which is inlined in the place of the escape. MetaOCaml can
print out code expressions, so we can see the final generated code. It
has no traces of |gen| and |plus|: their applications are done at the
generation stage.

The final MetaOCaml feature, |.!| (pronounced ``run'') 
executes the code expression: |.! simplest_code| is a function of two
integers, which we can apply: |(.! simplest_code) 1 2|. The original
|simplest_code| is not a function on integers -- it is a code
expression.

To see the benefit of code generation, we notice that we can easily
parameterize our code:

\begin{code}
let simplest_param_code plus one =
  let gen x y = plus x (plus y one) in
  .<fun x y -> .~(gen .<x>. .<y>.)>.
\end{code}
and use it to generate code that operates on integers, floating point
numbers or booleans -- in general, any domain that implements |plus|
and |one|:
\begin{code}
let plus x y = .<.~x +. .~y>. and one = .<1.0>. in
  simplest_param_code plus one
let plus x y = .<.~x || .~y>. and one = .<true>. in
  simplest_param_code plus one
\end{code}
Running the former expression yields the function on |float|s, whereas
the latter expression is the code expression for a boolean function.
This clearly shows the separation of concerns, namely of that for domain
operations.

Let us consider a more complex expression:
\begin{code}
let param_code1 plus one =
  let gen x y = plus (plus y one) (plus x (plus y one)) in
  .<fun x y -> .~(gen .<x>. .<y>.)>.
\end{code}
with two occurrences of |plus y one|,
which may be quite a complex computation and so we would rather not do
it twice. We may be tempted to rely on the compiler's
common-subexpression elimination optimization. When the generated code is
very complex, however, the compiler may overlook common subexpressions.  Or the
subexpressions may occur in such an imperative context where the compiler
might not be able to determine if lifting them is sound. So, being
conservative, the optimizer will leave the duplicates as they are. 
We may attempt to eliminate subexpressions as follows: 
\begin{code}
let param_code1' plus one =
  let gen x y = let ce = (plus y one) in  plus ce (plus x ce) in
  .<fun x y -> .~(gen .<x>. .<y>.)>.
param_code1' plus one
\evalresult{.<fun x_1 -> fun y_2 -> ((y_2 + 1) + (x_1 + (y_2 + 1)))>.}
\end{code}
However,
the result of |param_code1' plus one| still exhibits duplicate
sub-expressions.  Our |let|-insertion optimization saved the
computation at the generating stage.  We need a combinator that
inserts the |let| expression in the generat\emph{ed} code. We need a
combinator |letgen| to be used as
\begin{code}
let ce = letgen (plus y one) in plus ce (plus x ce)
\end{code}
yielding the code like 
\begin{code}
.<let t = y + 1 in t + (x + t)>.
\end{code}
But that seems impossible because |letgen exp| has to generate
the expression |.<let t = exp in body>.| but |letgen| does not
have the |body| yet. The body needs a temporary identifier |.<t>.|
that is supposed to be the result of |letgen| itself.  Certainly
|letgen| cannot generate only part of a let-expression, without the
|body|, as all generated expressions in MetaOCaml are well-formed and
complete.

The key is to use continuation-passing style (CPS). Its benefits were
first pointed out by \cite{Bondorf:92} in the context of partial
evaluation, and extensively used by \cite{MSP:PADL04,KiselyovTaha} for
code generation. Now, |param_code2 plus one| gives us the desired
code.

\begin{code}
let letgen exp k = .<let t = .~exp in .~(k .<t>.)>.
let param_code2 plus one =
  let gen x y k = letgen (plus y one)
                         (fun ce -> k (plus ce (plus x ce)))
  and k0 x = x
  in .<fun x y -> .~(gen .<x>. .<y>. k0)>.
param_code2 plus one
\evalresult{.<fun x_1 -> fun y_2 -> let t_3 = (y_2 + 1) in (t_3 + (x_1 + t_3))>.}
\end{code}

\subsection{Monadic notation, making CPS code clear}\label{monadicnotation}

Comparison of the let-insertion in the generator
\begin{code}
let ce = (plus y one) in  plus ce (plus x ce)
\end{code}
with the corresponding code generating let-insertion for the future
stage
\begin{code}
letgen (plus y one) (fun ce -> k (plus ce (plus x ce)))
\end{code}
clearly shows the difference between  direct-style and CPS code.
What was |let ce = init in ...| in direct style became
|init' (fun ce -> ...)| in CPS. For one, |let| became
``inverted''. For another, what used to be an expression that yields
a value, |init|, became an expression that takes an extra argument,
the continuation, and invokes it. The differences look negligible in
the above example. In larger expressions with many let-forms, the
number of parentheses around |fun| increases, the need to add and
then invoke the |k| continuation argument become increasingly annoying. The
inconvenience is great enough for some people to explicitly avoid CPS
or claim that numerical programmers (our users) cannot or will not
program in CPS. Clearly a better notation is needed.

The |do|-notation of Haskell \cite{Haskell98Report} shows that it is possible
to write CPS code in a conventional-looking style. The
|do|-notation is the notation for monadic code \cite{moggi-notions}.
Not only can monadic code represent CPS \cite{Filinski:Representing},
it also helps in composability by offering to add different
layers of effects (state, exception, non-determinism, etc) to the
basic monad \cite{liang-interpreter} in a controlled way.

A monad \cite{moggi-notions} is an abstract data type representing
computations that yield a value and may have an \emph{effect}.
The data type must have at least two operations, |return| to build
trivial effect-less computations and |bind| for combining
computations. These operations must satisfy \emph{monadic laws}:
|return| being the left and the right unit of |bind| and |bind| being
associative. Figure~\ref{ourmonad} defines the monad used throughout
the present paper and shows its implementation.

\begin{figure}
\begin{code}
type ('p,'v) monad = 's -> ('s -> 'v -> 'w) -> 'w
    constraint 'p = <state : 's; answer : 'w; ..>

let ret (a :'v) : ('p,'v) monad = fun s k -> k s a
let bind a f = fun s k -> a s (fun s' b -> f b s' k)
let fetch s k = k s s  and  store v _ k = k v ()

let k0 _ v = v
let runM m = fun s0 -> m s0 k0 

let l1 f = fun x     -> perform t <-- x; f t
let l2 f = fun x y   -> perform tx <-- x; ty <-- y; f tx ty

let retN a = fun s k -> .<let t = .~a in .~(k s .<t>.)>.

let ifL test th el = ret .< if .~test then .~th else .~el >.
let ifM test th el = fun s k -> 
  k s .< if .~test then .~(th s k0) else .~(el s k0) >.
\end{code}
\caption{Our monad}\label{ourmonad}
\end{figure}

Our monad represents two kinds of computational effects: reading and
writing a computation-wide state, and control effects. The latter are
normally associated with exceptions, forking of computations, etc. --
in general, whenever a computation ends with something other than
invoking its natural continuation in the tail position. In our case
the control effects manifest themselves as code generation.

In Figure~\ref{ourmonad}, the monad (yielding values of the type |v|)
is implemented as a function of two
arguments: the state (of type |s|) and the continuation. The
continuation receives the current state and the value, and
yields the answer of the type |w|.  The monad is polymorphic over the
three type parameters, which would require |monad| to be a type
constructor with three arguments. When we use this monad for code
generation, we will need yet another type variable, environment
classifier \oleg{cite Walid03?}. With type constructors taking more
and more arguments, it becomes more difficult to read and write
types -- which we will be doing extensively when writing module
signatures in Section XXX. The fact that OCaml renames all type
variables when printing out types confuses matters further. An elegant
solution to these kinds of problems has been suggested by 
Garrigue on the Caml mailing list 
(cited from
\url{http://groups.google.com/group/fa.caml/msg/e80b1245702d6b24}
no date, no exact ref). We use a single type parameter |'p| to
represent all parameters of our monad (all parameters but the type of
the monadic value |'v|). The type variable |'p| is constrained to be
the type of an object with methods (fields) |state| and |answer|. The
object may include more fields, represented by |..|. Values of that
type are not part of our computations and need not exist. We merely
use the object type, as an convenient way to specify extensible
\emph{type-level} records in OCaml.     

Our monad could be implemented in other ways. Except for the code in
Figure~\ref{ourmonad}, the rest of our code treats the monad as a
truly abstract data type. The implementation of the basic monadic
operations |ret| and |bind| is conventional and clearly satisfies the
monadic laws. Other monadic operations construct computations that do
have specific effects.  Operations |fetch| and |store v| construct
computations that read and write the state.

The operation |retN a| is the let-insertion operation, whose simpler
version we called |letgen| earlier. It is the first computation with
a control effect: indeed, the result of |retN a| is \emph{not} the
result of invoking its continuation |k|. Rather, its result is a |let|
code expression. Such a behavior is symptomatic of control operators
(in particular, |abort|).

Finally, |runM| runs our monad, that is, given the initial state,
performs the computation of
the monad and returns its result, which in our case is the code
expression. We run the monad by passing it the initial state and the
initial continuation |k0|. We can now re-write our |param_code2|
example of the previous section as |param_code3|.
\begin{code}
let param_code3 plus one =
  let gen x y = bind (retN (plus y one)) (fun ce -> 
                ret (plus ce (plus x ce)))
  in .<fun x y -> .~(runM (gen .<x>. .<y>.) ())>.
\end{code}
% param_code3 plus one;;
%
That does not seem like much of an improvement. With the help of
camlp4 pre-processor, we introduce the |perform|-notation \cite{metamonadsURL},
patterned after the |do|-notation of Haskell (see App.~\ref{app:perform}).
\begin{code}
let param_code4 plus one =
  let gen x y = perform ce <-- retN (plus y one);
                        ret (plus ce (plus x ce))
  in .<fun x y -> .~(runM (gen .<x>. .<y>.) ())>.
\end{code}
The function
|param_code4|, written in the |perform|-notation, is equivalent to
|param_code3| -- in fact, the camlp4 preprocessor will convert the
former into the latter. And yet, |param_code4| looks far more
conventional, as if it were indeed in direct style.

\subsection{Generating control statements}
We can write operations that generate code other than let-statements,
e.g., conditionals: see |ifL| in Figure~\ref{ourmonad}. The function |ifL|, 
albeit straightforward, is not as general as we wish: its arguments are
already generated pieces of code rather than monadic values. We
``lift it'':
\begin{code}
let ifM' test th el = perform
  testc <-- test; thc <-- th; elc <-- el;
  ifL testc thc elc
\end{code}
We define functions |l1|,
|l2|, |l3| (analogues of |liftM|, |liftM2|, |liftM3| of Haskell) 
to make such a lifting generic. However we also need
another |ifM| function, with the same
interface (see Figure~\ref{ourmonad}).
The difference between them is
apparent from the following example:
\begin{code}
let gen a i = ifM' (ret .<(.~i) >= 0>.) 
                   (retN .<Some (.~a).(.~i)>.) (ret .<None>.)
 in .<fun a i -> .~(runM (gen .<a>. .<i>.) ())>.
\evalresult{.<fun a_1 i_2 ->}
\textcolor{red}{      let t_3 = (Some a_1.(i_2)) in if (i_2 >= 0) then t_3 else None>.}
let gen a i = ifM (ret .<(.~i) >= 0>.) 
                  (retN .<Some (.~a).(.~i)>.) (ret .<None>.)
 in .<fun a i -> .~(runM (gen .<a>. .<i>.) ())>.
\evalresult{.<fun a_1 i_2 ->}
\textcolor{red}{      if (i_2 >= 0) then let t_3 = (Some a_1.(i_2)) in t_3 else None>.}
\end{code}
%
If we use |ifM'| to generate guarded array access code, the let-insertion
happened \emph{before} the if-expression, that is, before the test that
the index |i| is positive. If |i| turned out
negative, |a.(i)| would generate an out-of-bound array access
error. On the other hand, the code with |ifM| accesses the array only
when we have verified that the index is non-negative. This example
makes it clear that the code generation (such as the one in |retN|) is 
truly an effect and we have to be clear about the sequencing of
effects when generating control constructions such as conditionals.
The form |ifM| handles such effects correctly. 

We need similar operators for other OCaml control forms: for
generating sequencing, case-matching statements and |for|- and |while|-loops.
\begin{code}
let seqM a b = fun s k -> 
  k s .< begin .~(a s k0) ; .~(b s k0) end >.

let whileM cond body = fun s k -> 
  k s .< while .~(cond) do .~(body s k0) done >.

let matchM x som non = fun s k -> k s .< match .~x with
           | Some i -> .~(som .<i>. s k0)
           | None   -> .~(non s k0) >.

let genrecloop gen rtarg = fun s k -> 
  k s .<let rec loop j = .~(gen .<loop>. .<j>. s k0) in loop .~rtarg>.
\end{code}



\section{Aspects and Functors}\label{functors}

The monad represents fine-scale code generation. We need tools for
larger-scale modularization; we can use any abstraction
mechanisms we want to structure our code generators, as long as none
of those abstractions infiltrate the generated code.

Reviewing the various aspects outlined in section~\ref{aspects},
the simplest parametrization is to make the domain abstract. 
\jacques{This whole section needs to be edited to take into account
the different organization of the material}.
As it
turns out, we need the following to exist in our domains: $0$, $1$,
$+$, $*$, (unary and binary) $-$, at least \emph{exact} division,
normalization, and potentially a relative size measure. The simplest
case of such domain abstraction is |param_code1|.
There, code-generators such as |plus| and |one|
were passed as arguments. We need far more than
two parameters, so we have to group them. Instead of the grouping
offered by regular records, we use OCaml \emph{structures} (i.e.,
modules)
so we can take advantage of extensibility, type abstraction and constraints,
and especially parameterized structures (\emph{functors}).
We define the type of the domain, the signature |DOMAIN|, which
different domains must satisfy:

\begin{code}
type domain_kind = Domain_is_Ring | Domain_is_Field

module type DOMAIN = sig
  type v
  val kind : domain_kind
  val zero : v
  val one : v
  val plus : v -> v -> v
  val times : v -> v -> v
  val minus : v -> v -> v
  val uminus : v -> v
  val div : v -> v -> v
  val better_than : (v -> v -> bool) option
  val normalizer : (v -> v) option
end 

module IntegerDomain : DOMAIN = struct
    type v = int
    let kind = Domain_is_Ring
    let zero = 0
    let one = 1
    let plus x y = x + y
    let times x y = x * y
    let minus x y = x - y
    let uminus x = -x
    let div x y = x / y
    let normalizer = None
    let better_than = Some (fun x y -> abs x > abs y)
end
\end{code}

One particular domain instance is |IntegerDomain|. The notation\\
|module IntegerDomain : DOMAIN| makes the compiler verify that our
|IntegerDomain| is indeed a |DOMAIN|, that is, satisfies the required
signature. The constraint |DOMAIN| may be omitted; in that case, the
compiler will verify the type when we try to use that structure as a
|DOMAIN|. In any case, the errors such as missing ``methods'' or
methods with incorrect types will be caught statically, even
\emph{before} any code generation takes place. The variant
|domain_is_ring| of |domain_kind| encodes a semantic constraint 
that the full division
is not available. While the |DOMAIN| type may have looked daunting to
some, the implementation is quite straightforward.  Other domains such
as |float| and arbitrary precision exact rational numbers |Num.num|
are equally simple.


A more complex domain: |Zp|
\begin{code}
module ZpMake(P:sig val p:int end) = struct
    type v = int
    let kind = Domain_is_Field
    let zero = 0 and one = 1
    let plus x y = (x + y) mod P.p
    let times x y = (x * y) mod P.p
    \dots
    let normalizer = None and better_than = None
    let () = assert (is_prime P.p)
end
\end{code}

This domain is parametrized by a an integer number |p|, the
(modulus?). Thus, ZpMake is a functor. It creates a domain that is a
field, but with no defined order. Hence
|normalizer| and |better_than| are set to |None|. However, |Zp| forms
a field only when |p| is prime. Therefore, we must make this check,
see the last line of that code. The expression 
|assert (is_prime P.p)| is the initializing expression. It is executed
when the correspo0nding module is instantaited
\begin{code}
module Z19 = ZpMakeL(struct let p = 19 end)
\end{code}
if we replace |19| with |9| above, we receive an error. That is a
run-time error. It is raised however as we instantiate and
combine modules that will eventually make the generator. Thus,
although the error is reported at run-time rather than compile time as
one might have hoped, the error is raised when \emph{generating the
generator} -- well before the generation of the target code could
begin. In our code we make extensive use of these so-called preflight 
checks performed as part of module initialization. The checks seem to
offer a good compromise: they are dynamic and so do not require
complicated type systems; on the other hand, the checks are performed
quite early, when buiding code generators, and so ensure that no 
code violating the corresponding \emph{semantic} constraints 
will be generated. Although some may frown on the use of the module
initializing expressions (since that requires careful attention to the
sharing and problems of multiple instantiation of a module), these
concerns do not apply to our case: our preflight tests are all idempotent
and maintain no state.


Lifting:

We now define a lot of infrastructure.  We will be quite thorough, and
define base abstraction and lifted abstractions, This will involve a
lot of boilerplate code, which unfortunately cannot be so easily
automated in MetaOCaml -- that would require introspection.  It could
be done in camlp4, but that seems too much as well.  This 'base' could
be elided, but when we decide to make more use of Abstract
Interpretation, we'll regret it, so do it now.
\begin{code}
let lift x = .< x >.

let liftRef x = .< ref .~x >. 
let liftGet x = .< ! .~x >. 
let unitL = fun s k -> k s .< () >.

let liftPair x = (.< fst .~x >., .< snd .~x >.)

(* logic code combinators - plain and monadic *)
module Logic = struct
  let notL a        = .< not .~a >.
  let equalL a b    = .< .~a = .~ b >.
  let notequalL a b = .< .~a <> .~ b >.
  let andL a b     = .< .~a && .~b >. 
end

(* operations on code indices *)
module Idx = struct
  let zero = .< 0 >.
  let one = .< 1 >.
  let minusone = .< -1 >.
  let succ a = .< .~a + 1 >.
  let pred a = .< .~a - 1 >.
  let less a b = .< .~a < .~b >.
  let uminus a = .< - .~a >.
  let add a b = .< .~a + .~b >.

let cunit = .< () >.
let update a f = let b = f (liftGet a) in .< .~a := .~b >.
let assign a b = .< .~a := .~b >.
let apply  f x = .< .~f .~x >.
let updateM a f = ret (update a f)
let assignM a b = ret (assign a b)
let applyM  f x = ret (apply f x)
\end{code}


\noindent  The types above are
generally lifted twice: once from the value domain |v| to the code
domain |'a vc|, and once more from values to monadic computations
|('p,'a vc) monad|. 

\begin{code}
module S(T:
  sig
	(* Representation type of values,  to be specified *)
    type ('a, 'b) rep
  end) = struct

open T
module type DOMAINL = sig
  include DOMAIN
  type 'a vc = ('a,v) rep
  val zeroL : 'a vc
  val oneL : 'a vc
  val ( +^ ) : 'a vc -> 'a vc -> 'a vc
  val ( *^ ) : 'a vc -> 'a vc -> 'a vc
  val ( -^ ) : 'a vc -> 'a vc -> 'a vc
  val uminusL : 'a vc -> 'a vc
  val divL : 'a vc -> 'a vc -> 'a vc
  val better_thanL : ('a vc -> 'a vc -> ('a,bool) rep) option
  val normalizerL : ('a vc -> 'a vc) option
end 

module T = Domains_sig.S(struct type ('a, 'b) rep = ('a, 'b) code end)
open T

open Domains_common
(* because the operations are "syntactic" to a certain extent,
   we have to repeat ourselves a lot *)
module IntegerDomainL = struct
    include IntegerDomain
    type 'a vc = ('a,v) code
    let zeroL = .< 0 >.  
    let oneL = .< 1 >. 
    let (+^) x y = .<.~x + .~y>. 
    let ( *^ ) x y = .<.~x * .~y>.
    let ( -^ ) x y = .<.~x - .~y>.
    let uminusL x = .<- .~x>.
    let divL x y = .<.~x / .~y>. 
    let normalizerL = None
    let better_thanL = Some (fun x y -> .<abs .~x > abs .~y >. )
end
\end{code}



\begin{code}
module type CONTAINER2D = sig
  module Dom:DOMAINL
  type contr
  type 'a vc = ('a,contr) rep
  type 'a vo = ('a,Dom.v) rep
  val getL : 'a vc -> ('a,int) rep -> ('a,int) rep -> 'a vo
  val dim1 : 'a vc -> ('a,int) rep
  val dim2 : 'a vc -> ('a,int) rep
  val mapper : ('a vo -> 'a vo) option -> 'a vc -> 'a vc
  val copy : 'a vc -> 'a vc
  val init : ('a,int) rep -> ('a, int) rep -> 'a vc
  val augment : 'a vc -> ('a,int) rep -> ('a, int) rep -> 'a vc ->
                ('a, int) rep -> 'a vc
  val identity : ('a,int) rep -> ('a, int) rep -> 'a vc
  val swap_rows_stmt : 'a vc -> ('a, int) rep -> ('a, int) rep -> 
                       ('a,unit) rep
  val swap_cols_stmt : 'a vc -> ('a, int) rep -> ('a, int) rep -> 
                       ('a,unit) rep
  val row_head : 'a vc -> ('a, int) rep -> ('a, int) rep -> 'a vo
  val col_head_set : 'a vc -> ('a,int) rep -> ('a,int) rep -> 'a vo -> 
            ('a,unit) rep
end
\end{code}

Parameterizing by the kind of container representing a matrix is
almost as straightforward.  The type of our containers include the
lifted domain |Dom| as one of the component. Particular containers are
Our containers are  parametric
over a |DOMAINL|, i.e., functors from a |DOMAINL| module
to the actual implementation of a container. For example, the
following functor defines a matrix container represented as arrays of
rows. 

\begin{code}
module GenericArrayContainer(Dom:DOMAINL) =
  struct
  module Dom = Dom
  type contr = Dom.v array array (* Array of rows *)
  type 'a vc = ('a,contr) code
  type 'a vo = ('a,Dom.v) code
  let getL x n m = .< (.~x).(.~n).(.~m) >.
  let dim2 x = .< Array.length .~x >.       (* number of rows *)
  let dim1 x = .< Array.length (.~x).(0) >. (* number of cols *)
  \dots
\end{code}
%
We also have containers wheer elements are stored in a 1D array, in a
row-wise (C-like) or column-wise (Fortran-like) modes.

The signature |CONTAINER2D| specifies that a container must provide
functions |dim1| and |dim2| to extract the dimensions, functions |getL|
to generate container getters, the cloning
generator |copy| and functions that generate code for row and column
swapping. The inclusion of these functions in the signature of all
containers makes it simpler to optimize the relevant functions
depending on the actual representation of the container while not
burdening the users of containers with efficiency details.

The use of a |functor| for making a container parametric is fairly
straightforward.  More interesting is the aspect of what to return
from the LU algorithm.  One could create an algebraic data type (as
was done in \cite{carette04}) to encode the various choices: the
matrix, the matrix and the rank, the matrix and the determinant, the
matrix, rank and determinant, and so on. This is wholly unsatisfying
as we know that for any single use, only one of the choices is ever
possible, yet any routine which calls the generated code must deal
with these unreachable options.  Instead we use a module type with an
\emph{abstract} type |res| for the result type; different instances of
the signature set the result type differently. Given below is this
module type and one instantiation, which specifies the output of a LU
algorithm as a 3-tuple |contr * Det.outdet * int| of the U-factor, the
determinant and the rank.

\begin{code2}
module type OUTPUTDEP = sig 
    module PivotRep : PIVOTKIND 
    module Det      : DETERMINANT
end
(* The `keyword' list of all the present internal features *)
module type INTERNAL_FEATURES = sig
  module R      : TrackRank.RANK
  module P      : TRACKPIVOT
  module L      : LOWER
end

module type OUTPUT = functor(OD : OUTPUTDEP) -> sig
  module IF : INTERNAL_FEATURES
  type res
  val make_result : 'a wmatrix -> (\dots,res) monad
end
module OutDetRank(OD : OUTPUTDEP) = struct
  module IF = struct
      module R   = Rank
      module P   = DiscardPivot
      module L   = NoLower end
  type res = C.contr * C.Dom.v * int
  let make_result m = perform
    det  <-- OD.Det.fin ();
    rank <-- IF.R.fin ();
    ret (Tuple.tup3 m.matrix det rank)
  (* Initialization: check the preconditions of instantiation of this struct*)
  let _ = OD.Det.fin ()
  let _ = IF.R.fin ()
end
\end{code2}

The initialization expressions |OD.Det.fin ()| and |IF.R.fin ()| are
the pre-flight tests, to be explained in Section XXX.




\subsection{Maintaining the state}
another title: representing extensible state

different aspects may need to keep their own state. We wish to assure
modularity. One approach: using objects. The state is an object, each
aspect is an instnace variable with some particular name. The problem
is how to represent the initial `empty' state. Need to create the
object with all fields set to None. But we need to know the names of
all fields; as we add an aspect, our function that runs the generator
must change to account for the different initial object with different
slots.

A better approach: property list (ref MLTon). Property list represents
an extensible object. The initial object is just the empty list. Alas,
the literal MLton's approach doesn't apply to us well. First of all,
due to the environment classifiers, we need universes parameterized by
classifiers. Also, the propoerty names are generated automatically in
MLton approach, based on generativity of exceptions or reference
cells. That means if some particular aspect happens to be included
twice, the state will be incompatible. We will have to worry about
sharing or the lack of sharing of our aspects. We would rather prefer
our aspects to be stateless and work the same way whether two
instances of the aspect are shared or not. So, we find polymorphic
unions to be ideal. Manifest naming 

Encoding an object by its dual,
list of polymorphic variants.

Currently, we check at genertor-time that one cannot add a slot which
already exists (already the part of the state) nor we can obtain the
value of a non-existing slot. These problems may occur if our genetor
is wrong (calls fin method before decl method of an aspect). It is
possible to make these checks static (TFP2007, state-variable monad?)
state-changing monad...


\subsection{tracking}

As is apparent from the output choices, several different quantities
\emph{may} need to be tracked in a particular LU implementation.  We
therefore need to be able to conditionally generate variables
representing the tracking state, and weave in corresponding tracking
code. We may need to (independently) keep track of the rank, the
determinant and the permutation list.  The tracking state variables
then become part of the \emph{state} that is tracked by our monad.  To
have all this choice when needed, and yet have our code be modular and
composable as well as ensuring that the generated code does not
contain any abstraction artifacts, it is important to make this state
modular.  For example,
\begin{code}
module type DETERMINANT = sig
  type tdet = C.Dom.v ref
  type 'a lstate
  type ('pc,'v) lm = ('pc,'v) cmonad
    constraint 'pc = <state : [> `TDet of 'a lstate ]; classif : 'a; ..>
  type ('pc,'v) om = ('pc,'v) omonad
    constraint 'pc = <state : [> `TDet of 'a lstate ]; classif : 'a; ..>
  val decl : unit -> ('b,unit) lm (* could be unit rather than unit code...*)
  val upd_sign  : unit -> ('b,unit) om
  val zero_sign : unit -> ('b,unit) lm
  val acc       : ('a,C.Dom.v) abstract -> (<classif : 'a; ..>,unit) lm
  val get       : unit -> ('b,tdet) lm
  val set       : ('a,C.Dom.v) abstract -> (<classif : 'a; ..>,unit) lm
  val fin       : unit -> ('b,C.Dom.v) lm
end
\end{code}
\noindent  to track determinant we should be able to generate code
for: defining variables used for tracking (|decl|),
updating the sign or the absolute
value of the determinant, converting the tracking state
to the final determinant value of the type |outdet|. LU of a
floating-point matrix with no determinant tracking uses the
instantiation of |DETERMINANT| where |outdet| is |unit| and all the
functions of that module generate no code. For integer matrices, we
have to track some aspects of the determinant, even if we don't output
it. The determinant tracking aspect is complex because tracking
variables, if any, are to be declared at the beginning of LU; the sign
of the determinant has to be updated on each row or column
permutation; the value of the determinant should be updated per each
pivoting. We use |lstate| to pass the tracking state, e.g., a piece of
code for the value of the type |Dom.v ref|, among
various determinant-tracking functions. The |lstate| is a part of the
overall monadic state. Other aspects, e.g., rank tracking, may use the
monadic state for passing of rank tracking variables. To be able to
compose determinant and rank tracking functors -- each of which may
(or may not) use the monadic state for passing its own data -- we make
extensive use of open records (a list of polymorphic variants
appeared to be the easiest way to implement such a union, in a purely
functional way). This lets us freely compose determinant-tracking,
rank-tracking, and other aspects.

We have several instances of Det
\begin{code}
module NoDet =
  struct
  type tdet = C.Dom.v ref
  type 'a lstate = unit
  let decl () = unitL
  let upd_sign () = ret None
  let zero_sign () = unitL
  let acc _ = unitL
  let get () = ret (liftRef C.Dom.zeroL) (* hack alert! *)
  let set _ = unitL
  let fin () = failwith "Determinant is needed but not computed"
  type ('pc,'v) lm = ('pc,'v) cmonad
    constraint 'pc = <state : [> `TDet of 'a lstate ]; classif : 'a; ..>
  type ('pc,'v) om = ('pc,'v) omonad
    constraint 'pc = <state : [> `TDet of 'a lstate ]; classif : 'a; ..>
end

module AbstractDet =
  struct
  open C.Dom
  type tdet = v ref
  (* the first part of the state is an integer: which is +1, 0, -1:
     the sign of the determinant *)
  type 'a lstate = ('a,int ref) abstract * ('a,tdet) abstract
  let fin = fun () -> perform
      (det_sign,det) <-- mo_lookup ip;
      ifM (Logic.equalL (liftGet det_sign) Idx.zero) (ret zeroL)
      (ifM (Logic.equalL (liftGet det_sign) Idx.one) (ret (liftGet det))
          (ret (uminusL (liftGet det))))
end
\end{code}


Both contain the |fin ()| function to generate the code representing
the computed rank. Only the |NoRank| does not track any rank, and so 
|fin ()| raises an error. The code 
|let _ = IF.R.fin ()| in |OutDetRank| invokes that fin function, which
will produce the monadic code generating action, or raise teh
error. We do not run the action at that time -- we only make sure
there is an action to run. This is the preflight check again, to rule
out the semantic error when the user specified that rank should be
computed and returned and yet specified the |NoRank| aspects which
computes no rank at all. 

\begin{code}
(* The `keyword' list of all the present external features *)
module type FEATURES = sig
  module Det       : DETERMINANT
  module PivotF    : PIVOT
  module PivotRep  : PIVOTKIND
  module Update    : UPDATE
  module Input     : INPUT
  module Output    : OUTPUT
end
\end{code}

\begin{code2}
module GenGE(F : FEATURES) = struct
    module O = F.Output(F)

    let wants_pack = O.IF.L.wants_pack
    let can_pack   = 
        let module U = F.Update(F.Det) in
        (U.upd_kind = DivisionBased)
    (* some more pre-flight tests *)
    let _ = ensure ((not wants_pack) || can_pack) 
           "Cannot return a packed L in this case"

    let zerobelow mat pos = 
        let module IF = O.IF in
        let module U = F.Update(F.Det) in
        let innerbody j bjc = perform
            whenM (Logic.notequalL bjc C.Dom.zeroL ) (perform
                det <-- F.Det.get ();
                optSeqM (Iters.col_iter mat.matrix j (Idx.succ pos.p.colpos) 
               (Idx.pred mat.numcol) C.getL
                      (fun k bjk -> perform
                      brk <-- ret (C.getL mat.matrix pos.p.rowpos k);
                      U.update bjc pos.curval brk bjk 
                          (fun ov -> C.col_head_set mat.matrix j k ov) det) UP )
                      (IF.L.updt mat.matrix j pos.p.colpos C.Dom.zeroL 
                          (* this makes no sense outside a field! *)
                          (C.Dom.divL bjc pos.curval))) in
        perform
              seqM (Iters.row_iter mat.matrix pos.p.colpos
              (Idx.succ pos.p.rowpos)
              (Idx.pred mat.numrow) C.getL innerbody UP) 
                   (U.update_det pos.curval)

   let init input = perform
        let module IF = O.IF in
          (a,rmar,augmented) <-- F.Input.get_input input;
          r <-- IF.R.decl ();
          c <-- retN (liftRef Idx.zero);
          b <-- retN (C.mapper C.Dom.normalizerL (C.copy a));
          m <-- retN (C.dim1 a);
          rmar <-- retN rmar;
          n <-- if augmented then retN (C.dim2 a) else ret rmar;
          F.Det.decl ();
          IF.P.decl rmar;
          _ <-- IF.L.decl (if wants_pack then b else C.identity rmar m);
          let mat = {matrix=b; numrow=n; numcol=m} in
          ret (mat, r, c, rmar)

   let forward_elim (mat, r, c, rmar) = perform
        let module IF = O.IF in
          whileM (Logic.andL (Idx.less (liftGet c) mat.numcol)
                              (Idx.less (liftGet r) rmar) )
             ( perform
             rr <-- retN (liftGet r);
             cc <-- retN (liftGet c);
             let cp  = {rowpos=rr; colpos=cc} in
             let module Pivot = F.PivotF(F.Det)(IF.P) in
             pivot <-- l1 retN (Pivot.findpivot mat cp);
             seqM (matchM pivot (fun pv -> 
                      seqM (zerobelow mat {p=cp; curval=pv} )
                           (IF.R.succ ()) )
                      (F.Det.zero_sign () ))
                  (updateM c Idx.succ) )

   let gen input = perform
          (mat, r, c, rmar) <-- init input;
          seqM 
            (forward_elim (mat, r, c, rmar))
            (O.make_result mat)
end
\end{code2}

The LU generator functor itself is 
parameterized by the domain, container, pivoting policy (full, row,
nonzero, no pivoting), update policy (with either `fraction-less'
or full division), and the result specification. Some of the
argument modules such as |PIVOT| are functors themselves (parameterized
by the domain, the container, and the determinant functor). The sharing
constraints express obvious constraints on the instantiation of |Gen|,
for example, pivoting, determinant etc. components all use the same
domain. It must be stressed that all structures (i.e., module
instances) are stateless, and so we never have to worry that different
aspect functors (such as |CONTAINER2D| and |PIVOT|) are instantiated
with different but type-compatible instances of |DOMAIN|. That is, we
are not concerned at all about value sharing. Aspects such as
determinant tracking may be stateful so that the determinant update
code have access to the determinant tracking variables declared
previously. But that state is handled via the monadic state. As we
have shown, open unions make the overall monadic state compositional
with respect to the state of various aspects.

In addition to the ``regular'' type sharing constraints shown in the
|Gen| functor, there are also ``semantic'' sharing constraints, shown
in the following structure of the |UPDATE| signature:
\vspace*{-5pt}\begin{code}
module DivisionUpdate
  (Dom:DOMAIN with type kind = domain_is_field)
  (C:CONTAINER2D)
  (Det:DETERMINANT with type indet=Dom.v) = struct ... end
\end{code}
\vspace*{-4pt} 
This structure implements an update policy of using
|Dom.div| operation without restrictions -- which is possible only if
the domain has such an unrestricted operation. A domain such as the integer
domain may still provide |Dom.div| of the same type, but that operation may
only be used when we are sure that the division is exact. Our type
sharing constraint expresses such domain-specific knowledge:
instantiating |DivisionUpdate| with |IntegerDomain| leads to a
compile-time error, when compiling the \emph{generator} code. Thus, in
some cases we can use module types for ``semantic'' constraints
that cannot normally be expressed via the types of module members.
\vspace*{-5pt}
\begin{code}
module GVC_I = GenericVectorContainer(IntegerDomainL)
module G_GVC_I = GenLA(GVC_I)
open G_GVC_I
open G_GVC_I.GE
module GenIV5 = GenGE(struct 
    module Det = AbstractDet
    module PivotF = FullPivot
    module PivotRep = PermList
    module Update = FractionFreeUpdate
    module Input = InpJustMatrix
    module Output = OutDetRank end)

module GAC_F = GenericArrayContainer(FloatDomainL)
module G_GAC_F = GenLA(GAC_F)
open G_GAC_F
open G_GAC_F.GE

module GenFA1 = GenGE(struct
    module Det = NoDet
    module PivotF = RowPivot
    module PivotRep = PermList
    module Update = DivisionUpdate
    module Input = InpJustMatrix 
    module Output = OutJustMatrix end)
module GenFA9 = GenGE(struct 
    module Det = NoDet
    module PivotF = RowPivot
    module PivotRep = PermList
    module Update = DivisionUpdate
    module Input = InpJustMatrix
    module Output = Out_LU_Packed end)

let resIV5 = instantiate GenIV5.gen ;;
let rIV5 = runit {pf =  resIV5 };;

\end{code}
|GenFA1| is no-frills GE; GenFA9 has LU part

We can instantiate the |Gen| functor as shown above and inspect the generated
code, e.g., by printing |GenFA1.gen|. The code can then be ``compiled'' as 
|!. GenFA1.gen| or with off-shoring. The code for |GenIV5| (Appendix A) shows
full pivoting, determinant and rank tracking. The code for all these aspects is
fully inlined; no extra functions are invoked and no tests other than those
needed by the LU algorithm itself are performed. The GE?? function returns a
triple |int array * int * int| of the U-factor, determinant and the rank. The
code generated by |GenFA1| (Appendix B) shows absolutely no traces of
determinant tracking: no declaration of spurious variables, no extra tests,
etc. The code appears as if the determinant tracking aspect did not exist
at all. The generated code for the above and other instantiations of
|Gen| can be examined at \cite{metamonadsURL}. The website also 
contains benchmark code and timing comparisons.

\section{Runge-Kutta solvers}
\label{s:ode}

\section{Related and future work}\label{related}

The monad in this paper is similar to the one described in
\cite{MSP:PADL04,KiselyovTaha}.  However the latter papers used only
|retN| and fixpoints (for generation-time iterations).  This paper
does not involve monadic fixpoints because the generator is not
recursive, but heavily relies on monadic operations for generating
conditionals and loops.

|Blitz++| \cite{Veldhuizen:1998:ISCOPE} and {C++} template
meta-programming in general similarly eliminate levels
of abstraction.  With traits and concepts, some domain-specific
knowledge can also be encoded.  However overhead elimination
critically depends on full inlining of all methods by the compiler,
which has been reported to be challenging to insure. Furthermore, all
errors (such as type errors and concept violation errors, i.e.,
composition errors) are detected only when compiling the generated
code. It is immensely difficult to correlate errors (e.g., line
numbers) to the ones in the generator itself.

ATLAS \cite{ATLAS} is another successful project in this area.
However they use much simpler weaving technology, which leads them to
note that \emph{generator complexity tends to go up along with
  flexibility, so that these routines become almost insurmountable
  barriers to outside contribution}. Our results show how to surmount
this barrier, by building modular, composable generators. A
significant part of ATLAS' complexity is that the generator is
extremely error-prone and difficult to debug.  Indeed, when generating
C code in C using |printf|, nothing prevents producing code that
misses semicolons, open or close parentheses or variable
bindings. MetaOCaml gives us assurance that these errors, and more
subtle type errors, shall not occur in the generated code.  SPIRAL
\cite{Pueschel:05} is another such even more ambitious project.  But
SPIRAL does intentional code analysis, relying on a set of code
transformation ``rules'' which make sense, but which are not proved to
be either complete or confluent.  The strength of both of these
project relies on their platform-specific optimizations performed via
search techniques, something we have not attempted here.

The highly parametric version of our Gaussian Elimination is directly
influenced by the generic implementations available in Axiom
\cite{Axiom} and Aldor \cite{Watt:2002:HCA}.  Even though the Aldor
compiler frequently can optimize away a lot of abstraction overhead, 
it does not provide any guarantees that it will do so, unlike our
approach.

We should also mention early work \cite{Gluck95} on automatic
specialization of mathematical algorithms. Although it can eliminate
some overhead from a very generic implementation (e.g., by inlining
aspects implemented as higher-order functions), specialization cannot
change the type of the function and cannot efficiently handle aspects
that communicate via a private shared state.

The paper \cite{GluckJ97} describes early simple experiments in
\emph{automatic} and manual staging, and the multi-level language
based on an annotated subset of Scheme (which is untyped and has no
imperative features). The generated code requires post-processing to
attain efficiency.  

We are looking into encapsulating staging
annotations into just a few functors, so that the rest of the code (in
particular, the |Gen| functor that puts it all together) should be
annotation-free and thus can be used as is in a one-stage environment
(pure OCaml) as well as in a multi-stage environment (generating
extensions). The one-stage code is a good baseline for benchmarks and
regression tests. Obtaining a generating extension from properly
modularized OCaml code (along the lines of our |Gen|) is an exciting
area of our future research.

To the best of our knowledge, nobody has yet used functors to
abstract code generators, or even mixed functors and 
multi-stage programming.

We plan to further investigate the connection between delimited
continuations and our implementations of code generators like
|ifM|.  As well, by using some additional syntactic sugar
(for |ifM|, |whileM|, etc.), the available notation should be
even more direct-style, and potentially clearer.
We also would like to extend our monad to a monad transformer.

There are many more aspects which can also be handled:
Input variations (augmented
matrices), error reporting (i.e. asking for the determinant of a 
non-square matrix), memory hierarchy issues, loop-unrolling
\cite{Padua:MetaOcaml:04},
warnings when zero-testing is undecidable and
a value is only probabilistically non-zero, etc.  The larger program
family of LU decompositions contains more aspects still.

\section{Conclusion}\label{conclusion}
In this paper we have demonstrated numerical code extensively parameterized
by complex aspects at no run-time overhead.  The combination of
stateless functors and structures, and our monad with the
compositional state makes aspects freely composable without having to
worry about value aliasing. The only constraints to compositionality
are the typing ones plus the constraints we specifically
impose, including semantic constraints (e.g., rings do not have full
division).

There is an interesting relation with aspect-oriented code
\cite{kiczales97aspectoriented}: in AspectJ, 
aspects are (comparatively) lightly typed, and are post-facto extensions of an
existing piece of code.  Here aspects are weaved together ``from scratch'' to
make up a piece of code/functionality.  One can understand previous work to be
more akin to dynamically typed aspect weaving, while we have started
investigating statically typed one.

\subsection*{Acknowledgments}
We wish to thank Cristiano Calgano for his help in adapting camlp4 for
use with MetaOCaml. Many helpful discussions with Walid Taha are very
appreciated. The implementation of the monadic notation, |perform|,
was the joint work with Lydia van Dijk.

\bibliography{metamonads}
\bibliographystyle{elsart-num}
\section{Appendix 0}
\label{app:perform}
Grammar of our perform monad
We support four different constructs to introduce a monadic
expressions.

\begin{code}
  perform exp
  perform exp1; exp2
  perform x <-- exp1; exp2
  perform let x = foo in exp
\end{code}

which is almost literally the grammar of the Haskell's "do"-notation,
with the differences that Haskell uses |do| and |<-| where we use
|perform| and |<--|.

We support not only |let x = foo in ...|  expressions but arbitrarily
complex let-expressions, including |let rec| and |let module|.

The actual bind function of the monad defaults to |bind| and the
match-failure function to |failwith| (only used for refutable
patterns; see below).  To select a different function, use the
extended forms of |perform|. For example, use the function named 
|bind| from module |Mod|.  In
addition use the module's |failwith|-function in refutable patterns.
\begin{code}
        perform with module Mod in exp2
\end{code}
The code has full explanation...

\section{Appendix A}
The code generated for |GenIV5|, fraction-free LU of the integer matrix
represented by a flat vector, full pivoting, returning the |U|-factor,
the determinant and the rank.
\begin{code2}
val resIV5 : ('a, GVC_I.contr -> GenIV5.O.res) code =
  .<fun a_1 ->
   let t_2 = (ref 0) in
   let t_3 = (ref 0) in
   let t_4 = {arr = (Array.copy a_1.arr)} (a_1) in
   let t_5 = a_1.m in
   let t_6 = a_1.n in
   let t_7 = (ref 1) in
   let t_8 = (ref 1) in
   while (((! t_3) < t_5) && ((! t_2) < t_6)) do
    let t_13 = (! t_2) in
    let t_14 = (! t_3) in
    let t_15 = (ref (None)) in
    let t_34 =
     begin (* full pivoting *)
      for j_30 = t_13 to (t_6 - 1) do
       for j_31 = t_14 to (t_5 - 1) do
        let t_32 = (t_4.arr).((j_30 * t_4.m) + j_31) in
        if (t_32 <> 0) then
         (match (! t_15) with
          | Some (i_33) ->
             if ((abs (snd i_33)) > (abs t_32)) then
              (t_15 := (Some ((j_30, j_31), t_32)))
             else ()
          | None -> (t_15 := (Some ((j_30, j_31), t_32))))
        else ()
       done
      done;
      (match (! t_15) with
       | Some (i_16) -> (* swapping of columns *)
          if ((snd (fst i_16)) <> t_14) then begin
           let a_23 = t_4.arr
           and nm_24 = (t_4.n * t_4.m)
           and m_25 = t_4.m in
           let rec loop_26 =
            fun i1_27 ->
             fun i2_28 ->
              if (i2_28 < nm_24) then
               let t_29 = a_23.(i1_27) in
               a_23.(i1_27) <- a_23.(i2_28);
               a_23.(i2_28) <- t_29;
               (loop_26 (i1_27 + m_25) (i2_28 + m_25))
              else () in
           (loop_26 t_14 (snd (fst i_16)));
           (t_8 := (~- (! t_8))) (* adjust the sign of det *)
          end else ();
          if ((fst (fst i_16)) <> t_13) then begin (* swapping of rows?*)
           let a_17 = t_4.arr
           and m_18 = t_4.m in
           let i1_19 = (t_13 * m_18)
           and i2_20 = ((snd (fst i_16)) * m_18) in
           for i_21 = 0 to (m_18 - 1) do
            let t_22 = a_17.(i1_19 + i_21) in
            a_17.(i1_19 + i_21) <- a_17.(i2_20 + i_21);
            a_17.(i2_20 + i_21) <- t_22
           done;
           (t_8 := (~- (! t_8)))
          end else ();
          (Some (snd i_16))
       | None -> (None))
     end in
    (match t_34 with
     | Some (i_35) ->
        begin (* elimination loop *)
         for j_36 = (t_13 + 1) to (t_6 - 1) do
          let t_37 = (t_4.arr).((j_36 * t_4.m) + t_14) in
          if (t_37 <> 0) then begin
           for j_38 = (t_14 + 1) to (t_5 - 1) do
            (t_4.arr).((j_36 * t_4.m) + j_38) <-
             ((((t_4.arr).((j_36 * t_4.m) + j_38) * i_35) -
                ((t_4.arr).((t_13 * t_4.m) + j_38) * t_37)) / (! t_7))
           done;
           (t_4.arr).((j_36 * t_4.m) + t_14) <- 0
          end else ()
         done;
         (t_7 := i_35)
        end;
        (t_2 := ((! t_2) + 1)) (* advance the rank *)
     | None -> (t_8 := 0));
    (t_3 := ((! t_3) + 1))
   done;
   (t_4,
    if ((! t_8) = 0) then 0 (* adjust the sign of the determinant *)
    else if ((! t_8) = 1) then (! t_7)
    else (~- (! t_7)), (! t_2))>.
\end{code2}
\section{Appendix B}
The code generated for |GenFA1|, LU of the floating point matrix
represented by a 2D array, row pivoting, returning just the |U|-factor.
\begin{code2}
val resFA1 : ('a, GAC_F.contr -> GenFA1.O.res) code =
  .<fun a_1 ->
   let t_2 = (ref 0) in
   let t_3 = (ref 0) in
   let t_5 = (Array.map (fun x_4 -> (Array.copy x_4)) (Array.copy a_1)) in
   let t_6 = (Array.length a_1.(0)) in
   let t_7 = (Array.length a_1) in
   while (((! t_3) < t_6) && ((! t_2) < t_7)) do
    let t_10 = (! t_2) in
    let t_11 = (! t_3) in
    let t_12 = (ref (None)) in
    let t_18 =
     begin  (* row pivoting *)
      for j_15 = t_10 to (t_7 - 1) do
       let t_16 = (t_5.(j_15)).(t_11) in
       if (t_16 <> 0.) then
        (match (! t_12) with
         | Some (i_17) ->
            if ((abs_float (snd i_17)) < (abs_float t_16)) then
             (t_12 := (Some (j_15, t_16)))
            else ()
         | None -> (t_12 := (Some (j_15, t_16))))
       else ()
      done;
      (match (! t_12) with (* swapping of rows *)
       | Some (i_13) ->
          if ((fst i_13) <> t_10) then
           let t_14 = t_5.(t_10) in
           t_5.(t_10) <- t_5.(fst i_13);
           t_5.(fst i_13) <- t_14
          else ();
          (Some (snd i_13))
       | None -> (None))
     end in
    (match t_18 with
     | Some (i_19) -> (* elimination loop, elided?? *)
        begin
         for j_20 = (t_10 + 1) to (t_7 - 1) do
          let t_21 = (t_5.(j_20)).(t_11) in
          if (t_21 <> 0.) then begin
           for j_22 = (t_11 + 1) to (t_6 - 1) do
            (t_5.(j_20)).(j_22) <-
             ((t_5.(j_20)).(j_22) -. ((t_21 /. i_19) *. (t_5.(t_10)).(j_22)))
           done;
           (t_5.(j_20)).(t_11) <- 0.
          end else ()
         done;
         ()
        end;
        (t_2 := ((! t_2) + 1))
     | None -> ());
    (t_3 := ((! t_3) + 1))
   done;
   t_5>.
\end{code2}


\begin{code2}
val resFA9 : ('a, GAC_F.contr -> GenFA9.O.res) code =
  .<fun a_1 ->
   let t_2 = (ref 0) in
   let t_3 = (ref 0) in
   let t_5 = (Array.map (fun x_4 -> (Array.copy x_4)) (Array.copy a_1)) in
   let t_6 = (Array.length a_1.(0)) in
   let t_7 = (Array.length a_1) in
   let t_8 = (ref ([])) in
   while (((! t_3) < t_6) && ((! t_2) < t_7)) do
    let t_9 = (! t_2) in
    let t_10 = (! t_3) in
    let t_11 = (ref (None)) in
    let t_17 =
     begin
      for j_14 = t_9 to (t_7 - 1) do
       let t_15 = (t_5.(j_14)).(t_10) in
       if (t_15 <> 0.) then
        (match (! t_11) with
         | Some (i_16) ->
            if ((abs_float (snd i_16)) < (abs_float t_15)) then
             (t_11 := (Some (j_14, t_15)))
            else ()
         | None -> (t_11 := (Some (j_14, t_15))))
       else ()
      done;
      (match (! t_11) with
       | Some (i_12) ->
          if ((fst i_12) <> t_9) then begin
           let t_13 = t_5.(t_9) in
           t_5.(t_9) <- t_5.(fst i_12);
           t_5.(fst i_12) <- t_13;
           (t_8 := ((RowSwap ((fst i_12), t_9)) :: (! t_8)))
          end else ();
          (Some (snd i_12))
       | None -> (None))
     end in
    (match t_17 with
     | Some (i_18) ->
        begin
         for j_19 = (t_9 + 1) to (t_7 - 1) do
          let t_20 = (t_5.(j_19)).(t_10) in
          if (t_20 <> 0.) then
           for j_21 = (t_10 + 1) to (t_6 - 1) do
            (t_5.(j_19)).(j_21) <-
             ((t_5.(j_19)).(j_21) -. ((t_20 /. i_18) *. (t_5.(t_9)).(j_21)))
           done
          else ()
         done;
         ()
        end;
        (t_2 := ((! t_2) + 1))
     | None -> ());
    (t_3 := ((! t_3) + 1))
   done;
   (t_5, (! t_8))>.
\end{code2}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% all the text that used to be here is now in unused.tex
% same with any text in an \omitnow

