%% TODO: add a ref 
%%  Lars Birkedal's master thesis
%%   http://www.itu.dk/people/birkedal/papers/paresm.ps.gz

\begin{comment}
\authorinfo{Jacques Carette}
           {McMaster University}
           {carette@mcmaster.ca}
\authorinfo{Oleg Kiselyov}
           {FNMOC}
           {oleg@pobox.com}
\authorinfo{Chung-chieh Shan}
           {Rutgers University}
           {ccshan@cs.rutgers.edu}
\end{comment}

\begin{abstract}
\ifdim\parindent=0pt \parindent=1em \fi
We have built the first family of tagless interpretations for a
higher-order typed object
language in a typed metalanguage (Haskell or ML) that
require no dependent
types, generalized algebraic data types, or
postprocessing to eliminate tags.
The statically type-preserving interpretations include
an evaluator, a compiler (or staged evaluator), a partial
evaluator, and call-by-name and
call-by-value CPS transformers.

Our main idea is to encode
\ifshort HOAS \else de Bruijn or higher-order abstract syntax \fi
using combinator functions rather than data constructors.
In other words, we represent object terms not in an initial algebra
but using the coalgebraic structure of the $\lambda$-calculus.
Our representation also simulates inductive maps from types to
types, which are required for typed partial evaluation and CPS transformations.

Our encoding of an object term abstracts over the various ways to
interpret it, yet statically assures that the interpreters never get
stuck.  To achieve self\hyp interpretation and show Jones\hyp
optimality, we relate this exemplar of higher-rank and higher-kind
polymorphism \ifshort\else (provided by ML functors and Haskell~98 constructor
classes) \fi to plugging a term into a context of let\hyp polymorphic
bindings.
\end{abstract}

\begin{quote}
\small
    It should also be possible to define languages with a highly
    refined syntactic type structure. Ideally, such a treatment should
    be metacircular, in the sense that the type structure \linebreak[1] used in the
    defined language should be adequate for the defining language.
    \rm \ifshort \hfill John Reynolds~\else\\\fi\citep{reynolds-definitional}
\end{quote}

%\category{CR-number}{subcategory}{third-level}
%\terms term1, term2
%\keywords keyword1, keyword2

\section{Introduction}\label{intro}

A popular way to define and implement a language is to embed it in
another \citep{reynolds-definitional}.  Embedding means to represent
terms and values of the \emph{object language} as terms and values in the
\emph{metalanguage}.  Embedding is especially appropriate for domain\hyp
specific object languages because it supports rapid prototyping and integration
with the host environment \citep{hudak-building}.
If the metalanguage supports \emph{staging}, then
the embedding can compile object programs to the metalanguage and avoid the
overhead of interpreting them on the fly \citep{WalidICFP02}.  A staged
definitional interpreter is thus a promising way to build a domain\hyp specific
language (DSL)\@.

\begin{figure}
    \begin{floatrule}
    \begin{proofrules}
        \[ \[ [x:t_1] \proofoverdots e:t_2 \] \justifies \fun{x}e:t_1\to t_2 \]
        \[ \[ [f:t_1\to t_2] \proofoverdots e:t_1\to t_2 \] \justifies \fix{f}e:t_1\to t_2 \]
        \[ e_1:t_1\to t_2 \quad e_2:t_1 \justifies e_1 e_2: t_2 \]
        \[ \text{$n$ is an integer} \justifies n:\ZZ \]
        \[ \text{$b$ is a boolean} \justifies b:\BB \]
        \[ e:\BB \quad e_1:t \quad e_2:t \justifies \cond{e}{e_1}{e_2}:t \]
        \[ e_1:\ZZ \quad e_2:\ZZ \justifies e_1+e_2:\ZZ \]
        \[ e_1:\ZZ \quad e_2:\ZZ \justifies e_1 \times e_2:\ZZ \]
        \[ e_1:\ZZ \quad e_2:\ZZ \justifies e_1 \le e_2:\BB \]
    \end{proofrules}
    \end{floatrule}
    \caption{Our typed object language}
    \label{fig:object}
\end{figure}

We focus on embedding a \emph{typed} object language into a 
\emph{typed} metalanguage.
The benefit of types in this setting is to rule out meaningless object terms,
thus enabling faster interpretation and assuring that our interpreters
do not get stuck.
To be concrete, we use the typed object language in
Figure~\ref{fig:object} throughout this paper.  We aim not just for
evaluation of object programs but also for
compilation, partial evaluation, and other processing.

\Citet{WalidICFP02} and \citet{xi-guarded} motivated interpreting
a typed object language in a typed metalanguage as an interesting
problem.  The common solutions to this problem store object terms and
values in the metalanguage in a universal type, a generalized algebraic
data type (GADT), or a dependent type.  In the remainder of this section,
we discuss these solutions, identify their drawbacks, then summarize our
proposal and contributions.  
\ifshort
We leave aside the solved problem of writing a parser\slash type\hyp checker,
for embedding object language objects into the metalanguage
(whether using dependent types \citep{WalidICFP02} or not \citep{baars-typing}),
and just enter them by hand.
\fi

\subsection{The tag problem}\label{tagproblem}

\begin{SaveVerbatim}{2a}
type var = VZ | VS of var
type exp = V of var | B of bool | L of exp | A of exp * exp
\end{SaveVerbatim}
\begin{SaveVerbatim}[commandchars=\@\{\}]{2b}
let rec lookup (x::env) = function VZ -> x | VS v -> lookup env v
let rec eval0 env = function
| V v       -> lookup env v
| B b       -> b 
| L e       -> fun x -> eval0 (x::env) e
| A (e1,e2) -> (eval0 env e1) (eval0 env e2) 
\end{SaveVerbatim}
\begin{SaveVerbatim}{2c}
type u = UB of bool | UA of (u -> u)
\end{SaveVerbatim}
\begin{SaveVerbatim}{2d}
let rec eval env = function
| V v       -> lookup env v
| B b       -> UB b
| L e       -> UA (fun x -> eval (x::env) e)
| A (e1,e2) -> match eval env e1 with UA f -> f (eval env e2)
\end{SaveVerbatim}
\begin{SaveVerbatim}{test1}
let test1 = A (L (V VZ), B true)
\end{SaveVerbatim}

% see tagless\_interp1.ml, module Tagfull for the complete code.
% If you change the code in here, please adjust the .ml file
% accordingly. Let the paper and the accompanying code be in sync.
It is straightforward to create an algebraic data type, say in OCaml%
\ifshort, Figure~\ref{fig:tag-problem}(a)\fi, to
represent object terms such as those in Figure~\ref{fig:object}.
For brevity, we elide treating integers, conditionals, and fixpoint in
this section.
\ifshort\else\UseVerbatim{2a}\fi
We represent each variable using a unary de Bruijn index.%
\footnote{We use de Bruijn indices to simplify the comparison with
\citearound{'s work}\citet{WalidICFP02}.}
For example, we represent the object term $(\fun{x}x)\True$ as
\ifshort \BUseVerbatim{test1}.\else \UseVerbatim{test1}\fi
\ifshort

\begin{figure}
%
(a) \BUseVerbatim{2a}

\smallskip
(b) \BUseVerbatim{2b}

\smallskip
(c) \BUseVerbatim{2c}

\smallskip
(d) \BUseVerbatim{2d}

\medskip
\caption{OCaml code illustrating the tag problem}
\label{fig:tag-problem}
\end{figure}

\fi
Following \citet{WalidICFP02},
we try to implement an interpreter function |eval0|\ifshort,
Figure~\ref{fig:tag-problem}(b)\fi. It takes
an object term such as |test1| above and gives us its value.
The first argument to |eval0| is the environment, initially empty,
which is the list of values bound to free variables in the
interpreted code.
\ifshort\else\UseVerbatim{2b}\fi
If our OCaml-like metalanguage were untyped, the code above would be 
acceptable.
The |L e| line exhibits interpretive overhead:
|eval0| traverses the function body~|e| every time (the result of
evaluating) |L e| is applied. Staging can be used to remove this
interpretive overhead \citep[\S1.1--2]{WalidICFP02}.

However, the function |eval0| is ill-typed
if we use OCaml or some other typed language as the metalanguage.
The line |B b|
says that |eval0| returns a boolean, whereas the next line |L e| says
the result is a function, but all branches of a pattern-match form must
yield values of the same type. 
A related problem is the type of the environment |env|: a regular
OCaml list cannot hold both boolean and function values. 

The usual solution is to introduce a universal type \citep[\S1.3]
{WalidICFP02} containing both booleans and functions\ifshort,
Figure~\ref{fig:tag-problem}(c)\fi.
\ifshort\else\UseVerbatim{2c}\fi
We can then write a typed interpreter\ifshort,
Figure~\ref{fig:tag-problem}(d), \else\UseVerbatim{2d}\fi
whose inferred type is |u list -> exp -> u|. Now we can evaluate
\ifshort
\texttt{eval [] test1} obtaining |UB true|.
\else
\begin{code}
let test1r = eval [] test1
val test1r : u = UB true 
\end{code}
\fi
The unfortunate tag |UB| in the result reflects that |eval| is a partial
function.  
First, the pattern match |with UA f| in the line
|A (e1,e2)| is not exhaustive, so |eval| can fail if we apply a boolean,
as in the ill-typed term |A (B true, B false)|.
\ifshort\else
\begin{code}
let test2 = A (B true, B false)
let test2r = eval [] test2
Exception: Match_failure in eval
\end{code}
\fi
Second, the |lookup|
function assumes a nonempty environment, so |eval| can fail if we
evaluate an open term
\ifshort
|A (L (V (VS VZ)), B true)|.
\else
\begin{code}
let test3 = A (L (V (VS VZ)), B true)
let test3r = eval [] test3
Exception: Match_failure in lookup
\end{code}
\fi
After all, the type |exp| represents object
terms both well-typed and ill-typed, both open and closed.

Although |eval| never fails on
well-typed closed terms, this soundness is not obvious to the
metalanguage, whose type system we must still appease with the
nonexhaustive pattern matching in |lookup| and |eval| and the tags |UB|
and |UA| \citep[\S1.4]{WalidICFP02}.  In other words, the algebraic data
types above fail to express in the metalanguage that the object program
is well-typed.  This failure necessitates tagging and nonexhaustive
pattern\hyp matching operations that incur a performance penalty in
interpretation \citep{WalidICFP02} and impair optimality in partial evaluation
\citep{taha-tag}.  In short, the universal\hyp type solution is
unsatisfactory because it does not preserve the type of the encoded term.

\ifshort\else\subsection{Solutions using fancier types}\fi

It is commonly thought that the type-preserving interpretation of
a typed object language in a typed metalanguage is difficult and requires
GADTs or dependent types \citep{taha-tag}.  In fact, this problem
motivated much work on GADTs \citep{xi-guarded,peyton-jones-simple} and
on dependent types \citep{WalidICFP02,fogarty-concoqtion}\ifshort\else,
in order for the metalanguage's type system to allow the well-typed object term
|test1| but disallow the ill-typed object term |test2|\fi.
Yet other type systems
have been proposed to distinguish closed terms like |test1| from open
terms 
\ifshort\citep{WalidPOPL03,NanevskiJFP05,DaviesJACM01}\else
like |test3|
\citep{WalidPOPL03,NanevskiICFP02,NanevskiJFP05,DaviesJACM01,nanevski-contextual}\fi,
so that |lookup| never receives an empty environment.  We discuss these
proposals further in \S\ref{related}\ifshort\else;
here we just note that many
fancy type systems have been devised to ensure statically that an
object term is well-typed and closed\fi.

\subsection{Our final proposal}\label{ourapproach}

Following an old idea of \citet{reynolds-user-defined},
we represent object programs using ordinary functions rather than
data constructors.  These functions comprise the entire interpreter:
\ifshort
\begin{code3}
let varZ env    = fst env         let b (bv:bool) env = bv
let varS vp env = vp (snd env)    let lam e env   = fun x -> e (x,env)
let app e1 e2 env   = (e1 env) (e2 env)
\end{code3}
\else
\begin{code}
let varZ env        = fst env
let varS vp env     = vp (snd env)
let b (bv:bool) env = bv
let lam e env       = fun x -> e (x,env)
let app e1 e2 env   = (e1 env) (e2 env)
\end{code}
\fi
We now represent our sample term $(\fun{x}x)\True$ as
\ifshort
\texttt{let testf1 = app (lam varZ) (b true)}.
\else
\begin{code}
let testf1 = app (lam varZ) (b true)
\end{code}
\fi
This representation is almost the same as in \S\ref{tagproblem}, only
written with lowercase identifiers. To evaluate an object term is to
apply its representation to the empty environment\ifshort
, |testf1 ()|, obtaining |true|\fi.
\ifshort\else
\begin{code}
let testf1r = testf1 ()
val testf1r : bool = true
\end{code}
\fi
The result has no tags: the interpreter patently uses no tags and no
pattern matching. The term |b true| evaluates to a boolean and the term
|lam varZ| evaluates to a function, both untagged. The |app| function
applies |lam varZ| without pattern matching. What is more, evaluating an
open term such as
\ifshort
\texttt{app (lam (varS varZ)) (b true)}
\else
|testf3| below
\fi
gives a type error rather than a run-time error.
\ifshort\else
\begin{code}[commandchars=\\\{\}]
let testf3 = app (lam (varS varZ)) (b true)
let testf3r = testf3 \underline{()}
This expression has type unit but is here used with type 'a * 'b
\end{code}
\fi
The type error correctly complains
that the initial environment should be a tuple rather than~|()|.
In other words, the term is open.

In sum, using ordinary functions rather than data constructors
to represent well-typed terms, we achieve a tagless evaluator
for a typed object language in a metalanguage with a simple 
\ifshort
Hindley-Milner \fi
type system\ifshort\else\ \citep{hindley-principal,milner-theory}\fi.
We call this approach \emph{final} (in contrast to \emph{initial}),
because we represent each object term not by its abstract syntax
but by its denotation in a semantic algebra.  This representation
makes it trivial to implement a primitive recursive function over
object terms, such as an evaluator.  Or, as a referee puts it aptly, our
proposal is ``a way to write a typed fold function over a typed term.''

We emphasize ``typed'' and ``fold'' in the previous sentence.
Our encoding of the recursive type of terms \citep{bohm-automatic}
makes folds over terms much easier to write than functions over
terms that are not primitive recursive (or, compositional).
In contrast, \citearound{'s encoding of the sum type of
terms}\citet{JFP-Mogensen} does not privilege folds.
In exchange, we statically express object types in the metalanguage
and prevent both kinds of run-time errors in
\S\ref{tagproblem}, due to evaluating ill-typed or open terms.
Because the new interpreter
uses no universal type or pattern matching, it never gives a
run-time error, and is in fact total.  Because this safety is obvious
not just to us but also to the metalanguage implementation, we avoid
the serious performance penalty \citep{WalidICFP02}
that inevitably arises \citep{Gluck-jones-optimality}
of error checking at run time.

Our solution does \emph{not} involve Church-encoding the
universal type. The Church encoding of the type~|u| in \S\ref{tagproblem}
requires two continuations; the function |app| in the interpreter above would
have to provide both to the encoding of~|e1|. The continuation
corresponding to the |UB| case of~|u| must either raise an error or
loop. For a well-typed object term, that error continuation is never
invoked, yet it must be supplied. In contrast, our interpreter has no error
continuation at all.

The evaluator above is wired directly into
functions such as |b|, |lam|, and |app|, whose names appear
free in |testf1| above.
\ifshort We \else In the rest of this paper, we \fi
explain how to abstract over these functions' definitions
and apply different folds to the same object language, so as
to process the same term using many other
interpreters: we can
\begin{itemize}
    \item evaluate the term to a value in the metalanguage;
    \item measure the length of the term;
    \item compile the term, with staging support such as in MetaOCaml;
    \item partially evaluate the term, online; and
    \item transform the term to continuation\hyp passing style (CPS),
        even call-by-name (CBN) CPS in a call-by-value (CBV) metalanguage,
        so as to isolate the evaluation
        order of the object language from that of the metalanguage.\ifshort
\footnote{Due to serious lack of space, 
we refer the reader to the accompanying code for this.}\fi
\end{itemize}
We have programmed all our interpreters and examples in OCaml (and, for staging,
\citet{metaocaml}) and standard Haskell. The complete code is
available at \url{http://okmij.org/ftp/packages/tagless-final.tar.gz}
to supplement the paper. 
\ifshort For simplicity, main examples in the paper will be in MetaOCaml;
all examples have also been implemented in Haskell.
\else Except for the basic definitions in \S\ref{encoding},
we show our examples in (Meta)OCaml even though some of our
claims are more obvious in Haskell, for consistency and because
MetaOCaml provides convenient, typed staging facilities.
\fi

\subsection{Contributions}\label{contributions}

We attack the problem of tagless (staged) type-preserving
interpretation exactly as it was posed
by \citet{WalidICFP02} and \citet{xi-guarded}.
We use their running examples and achieve the
result they call desirable.  Our contributions are as follows.
\begin{enumerate}
\item We build the first \emph{family} of interpreters, each instantiating the
   \emph{same} signature, that evaluate (\S\ref{language}),
   compile (\S\ref{S:compiler}), and 
   partially evaluate (\S\ref{PE}) a typed higher-order object language
   in a typed metalanguage, in direct and continuation\hyp passing
   styles\ifshort\else\ (\S\ref{variations})\fi.
\item These interpreters use no type tags
    and need no advanced type-system features such as GADTs, dependent types,
    or intentional type analysis.
    Yet the type system of the metalanguage
    assures statically that each object program is well-typed and closed,
    and that each interpreter preserves types and never gets stuck.
    In particular, our (online) partial evaluator and CPS transformers
    avoid GADTs in their implementation and stay portable across
    Haskell 98 and ML, by expressing in their interface an inductive
    map from input types to output types.
\item Our clean, comparable implementations using OCaml modules and Haskell
    type classes show how to parametrize our final representation of object
    terms over multiple ways to assign them meanings.
\item We point a clear way to extend the object language with more features
    such as state\ifshort\else~(\S\ref{state})\fi.\ifshort\footnote{Again, please see our code.}\fi
    \ Our term encoding is contravariant in the object language, so
    extending the language does not invalidate terms already encoded.
\item We describe an approach to self\hyp interpretation compatible with the
  above\ifshort\else~(\S\ref{selfinterp})\fi.  Self\hyp interpretation turned
  out to be harder than expected.\ifshort\footnotemark[\value{footnote}]\fi
\end{enumerate}
Our code is surprisingly simple and obvious in hindsight, but
it has been cited as a difficult problem (\cite{sumii-hybrid}
notwithstanding) to interpret a typed object language in a typed metalanguage
without tagging or type\hyp system extensions.  For example, \citet{taha-tag}
say that ``expressing such an interpreter in a statically typed
programming language is a rather subtle matter. In fact, it is only
recently that some work on programming type-indexed values in ML
\citep{yang-encoding} has given a hint of how such a function can be
expressed.''  We discuss related work in~\S\ref{related}.

To reiterate, we do \emph{not} propose any new language
feature or \ifshort new \else even any new programming \fi technique.
\ifshort
We
\else
Rather, we
\fi
solve a problem that was stated in the published record as open and
likely unsolvable in ML or Haskell 98 without extensions, by a novel
combination of simple types and techniques already described in the
literature that use features present in mainstream functional languages.
In particular, we follow \citets{yang-encoding} encoding of type-indexed
values, \citets{Sperber-SelfApplicable} and \citets{asai-binding-time}
construction of dynamic terms alongside static terms, and
\citets{Thiemann-combinators} deforestation of syntax
constructors.  These techniques require just
a Hindley-Milner type system with either module
functors or constructor classes, as realized in all variants of ML and
Haskell.
The simplicity of our solution and its
use of only mainstream features \ifshort\else are virtues that \fi make it more practical to build typed,
embedded DSLs.

\ifshort\else
However we represent an object term,
the representation can be created either by hand (for example, by
entering object terms at a metalanguage interpreter's prompt) or
by parsing and type-checking text.
It is known how to write such a type checker
for a higher-order object language such as ours,
whether using fancy types \citep{Guillemette-Monier-PLPV,WalidICFP02} or not \citep{baars-typing}.
We have ourselves implemented a type checker for our object
language (in the accompanying source file |IncopeTypecheck.hs|),
which maps an ordinary syntax tree to (either a type error or) a finally
encoded object term that can then be interpreted in multiple ways
without repeated type-checking.  We leave this problem aside in the
rest of this paper.
\fi

\section{The object language and its tagless interpreters}\label{language}

Figure~\ref{fig:object} shows our object language, a simply-typed
$\lambda$-calculus with fixpoint, integers, booleans, and comparison.
The language is close to \citets{xi-guarded}, without their polymorphic
lift but with more constants so as to more conveniently express Fibonacci,
factorial, and power.
In contrast to \S\ref{intro}, in the rest of the paper 
we use higher-order
abstract syntax (HOAS) \citep{miller-manipulating,pfenning-higher-order}
rather than de Bruijn indices to encode binding and
ensures that our object programs are closed.
We find HOAS to be more convenient, but we have also implemented our
approach using de Bruijn indices
(in \S\ref{S:de-Bruijn} and the accompanying source file
|incope-dB.ml|).


\subsection{How to make encoding flexible: abstract the interpreter}
\label{encoding}

\ifshort
\begin{SaveVerbatim}{3a}
class Symantics repr where
  int :: Int  -> repr Int;       bool :: Bool -> repr Bool
  lam :: (repr a -> repr b) -> repr (a -> b)
  app :: repr (a -> b) -> repr a -> repr b
  fix :: (repr a -> repr a) -> repr a

  add :: repr Int -> repr Int -> repr Int
  mul :: repr Int -> repr Int -> repr Int
  leq :: repr Int -> repr Int -> repr Bool
  if_ :: repr Bool -> repr a -> repr a -> repr a
\end{SaveVerbatim}
\else
\begin{SaveVerbatim}{3a}
class Symantics repr where
  int  :: Int  -> repr Int
  bool :: Bool -> repr Bool

  lam :: (repr a -> repr b) -> repr (a -> b)
  app :: repr (a -> b) -> repr a -> repr b
  fix :: (repr a -> repr a) -> repr a

  add :: repr Int -> repr Int -> repr Int
  mul :: repr Int -> repr Int -> repr Int
  leq :: repr Int -> repr Int -> repr Bool
  if_ :: repr Bool -> repr a -> repr a -> repr a
\end{SaveVerbatim}
\fi
\begin{SaveVerbatim}{3b}
testpowfix () = lam (\x -> fix (\self -> lam (\n ->
                 if_ (leq n (int 0)) (int 1)
                     (mul x (app self (add n (int (-1))))))))
\end{SaveVerbatim}
\begin{SaveVerbatim}{3c}
testpowfix7 () = lam (\x -> app (app (testpowfix ()) x) (int 7))
\end{SaveVerbatim}

We embed our language in (Meta)OCaml and Haskell.  In Haskell,
the functions that construct object terms are methods in a type class
|Symantics| (with a parameter |repr| of kind |* -> *|)\ifshort,
Figure~\ref{fig:symantics-haskell}(a)\fi. The class is so named
because its interface gives the syntax of the object language and its
instances give the semantics.
\ifshort\else\UseVerbatim{3a}\fi
For example, we encode the term |test1|, or $(\fun{x}x)\True$, from
\S\ref{tagproblem} above as \texttt{app (lam (\textbackslash x -> x)) (bool True)},
whose inferred type is \texttt{Symantics repr => repr Bool}.
For another example, the classical $\mathit{power}$ function is
\ifshort in Figure~\ref{fig:symantics-haskell}(b)
\else\UseVerbatim{3b}\fi
and the partial application $\fun{x} \mathit{power}\;x\;7$ is
\ifshort in Figure~\ref{fig:symantics-haskell}(c).
\else\UseVerbatim{3c}\fi
The dummy argument |()| above is to avoid the monomorphism
restriction, to keep the type of |testpowfix| and |testpowfix7|
polymorphic in |repr|. \ifshort\else Instead of supplying this dummy
argument, we could have given the terms explicit polymorphic
signatures.  We however prefer for
Haskell to infer the object types for us. We could also
avoid the dummy argument by switching off the monomorphism restriction
with a compiler flag. \fi
The methods |add|, |mul|, and |leq| are quite similar, and so are
|int| and |bool|. Therefore, we often elide all but
one method of each group. The
accompanying code has the complete implementations.

\ifshort
\begin{figure}
(a) \BUseVerbatim{3a}

\smallskip
(b) \BUseVerbatim{3b}

\smallskip
(c) \BUseVerbatim{3c}

\medskip
\caption{Symantics in Haskell}
\label{fig:symantics-haskell}
\end{figure}
\fi

\begin{SaveVerbatim}{ocaml-simple}
module type Symantics = sig type ('c, 'dv) repr
  val int : int  -> ('c, int) repr
  val bool: bool -> ('c, bool) repr

  val lam : (('c, 'da) repr -> ('c, 'db) repr) -> ('c, 'da -> 'db) repr
  val app : ('c, 'da -> 'db) repr -> ('c, 'da) repr -> ('c, 'db) repr
  val fix : ('x -> 'x) -> (('c, 'da -> 'db) repr as 'x)

  val add : ('c, int) repr -> ('c, int) repr -> ('c, int) repr
  val mul : ('c, int) repr -> ('c, int) repr -> ('c, int) repr
  val leq : ('c, int) repr -> ('c, int) repr -> ('c, bool) repr
  val if_ : ('c, bool) repr
            -> (unit -> 'x) -> (unit -> 'x) -> (('c, 'da) repr as 'x)
end
\end{SaveVerbatim}
\begin{SaveVerbatim}{ocaml-examples}
module EX(S: Symantics) = struct open S
  let test1 () = app (lam (fun x -> x)) (bool true)
  let testpowfix () =
       lam (fun x -> fix (fun self -> lam (fun n ->
        if_ (leq n (int 0)) (fun () -> int 1)
            (fun () -> mul x (app self (add n (int (-1))))))))
  let testpowfix7 = lam (fun x -> app (app (testpowfix ()) x) (int 7))
end
\end{SaveVerbatim}

\ifshort
\begin{figure}[t]
\begin{tabular}{@{}l@{}}
\ifx\relax\normalbaselineskip\else\baselineskip\normalbaselineskip\fi
\BUseVerbatim[baseline=b]{ocaml-simple}\\[\smallskipamount]
\ifx\relax\normalbaselineskip\else\baselineskip\normalbaselineskip\fi
\BUseVerbatim[baseline=t]{ocaml-examples}
\end{tabular}

\medskip
\caption{A simple (Meta)OCaml embedding of our object language, 
    and examples}
\label{fig:ocaml-simple}
\label{fig:ocaml-examples}
\end{figure}
\else
\begin{figure}[t]
\begin{floatrule}
\BUseVerbatim{ocaml-simple}
\end{floatrule}
\caption{A simple (Meta)OCaml embedding of our object language}
\label{fig:ocaml-simple}
\end{figure}
\begin{figure}[t]
\begin{floatrule}
\BUseVerbatim{ocaml-examples}
\end{floatrule}
\caption{Examples using the embedding in Figure~\ref{fig:ocaml-simple} of our object language}
\label{fig:ocaml-examples}
\end{figure}
\fi

To embed the same object language in (Meta)OCaml, we replace the \ifshort type
class \fi |Symantics| \ifshort\else type class \fi and its instances by a
module signature |Symantics| and its implementations.
Figure~\ref{fig:ocaml-simple} shows a simple
signature that suffices until~\S\ref{PE}.  The two differences are:
the additional type parameter |'c|, an
\emph{environment classifier} \citep{WalidPOPL03} required by MetaOCaml for
code generation in~\S\ref{S:compiler}; and the $\eta$-expanded type for
|fix| and thunk types in |if_| since OCaml is a call-by-value
language.
We shorten some of the types using OCaml's |as| syntax.

The functor |EX| in Figure~\ref{fig:ocaml-examples} encodes 
our running examples |test1| and the $\mathit{power}$ function
(|testpowfix|).
The dummy argument to |test1| and |testpowfix| is an artifact of
MetaOCaml: in order for us to run a
piece of generated code, it must be polymorphic in its environment
classifier (the type variable |'c| in Figure~\ref{fig:ocaml-simple}),
so we must define our object terms as syntactic values to satisfy
the value restriction.
(Alternatively, we could have used
OCaml's rank-2 record types to maintain the necessary polymorphism.)
\ifshort\else\par\fi
Thus, we represent an object expression in
OCaml as a functor from |Symantics| to a semantic domain. This
is essentially the same as the constraint \texttt{Symantics repr =>} in the
Haskell embedding.

Comparing |Symantics| with Figure~\ref{fig:object}
shows how to represent \emph{every} well-typed object term in the
metalanguage.
We formalize this representation by defining $H$ and~$M$,
two inductive maps from terms and types in our object language
to terms and types in Haskell and OCaml:
\begin{align}
    H(\ZZ) &= \texttt{Int} &
    M(\ZZ) &= \texttt{int} \notag\\
    H(\BB) &= \texttt{Bool} &
    M(\BB) &= \texttt{bool} \notag\\
    H(t_1 \to t_2) &= H(t_1) \mathbin{\texttt{->}} H(t_2) &
    M(t_1 \to t_2) &= M(t_1) \mathbin{\texttt{->}} M(t_2) \displaybreak[0] \\
    H(x) &= x &
    M(x) &= x \notag\\
    H(\fun{x}e) &= \texttt{lam (\textbackslash $x$ -> $H(e)$)} &
    M(\fun{x}e) &= \texttt{lam (fun $x$ -> $M(e)$)} \notag\\
    H(\fix{f}e) &= \texttt{fix (\textbackslash $x$ -> $H(e)$)} &
    M(\fix{x}e) &= \texttt{fix (fun $x$ -> $M(e)$)} \notag\\
    H(e_1 e_2) &= \texttt{app $H(e_1)$ $H(e_2)$} &
    M(e_1 e_2) &= \texttt{app $M(e_1)$ $M(e_2)$} \notag\\
    H(n) &= \texttt{int $n$} &
    M(n) &= \texttt{int $n$} \notag\\
    H(\True) &= \texttt{bool True} &
    M(\True) &= \texttt{bool true} \notag\\
    H(\False) &= \texttt{bool False} &
    M(\False) &= \texttt{bool false} \notag\\
    \!H(\cond{e}{e_1}{e_2}) &= \rlap{\texttt{if\_ $H(e)$ $H(e_1)$ $H(e_2)$}} \notag\\
    \!M(\cond{e}{e_1}{e_2}) &= \rlap{\texttt{if\_ $M(e)$ (fun () -> $M(e_1)$) (fun () -> $M(e_2)$)}} \notag\\
    H(e_1 + e_2) &= \texttt{add $H(e_1)$ $H(e_2)$} &
    M(e_1 + e_2) &= \texttt{add $M(e_1)$ $M(e_2)$} \notag\\
    H(e_1 \times e_2) &= \texttt{mul $H(e_1)$ $H(e_2)$} &
    M(e_1 \times e_2) &= \texttt{mul $M(e_1)$ $M(e_2)$} \notag\\
    H(e_1 \le e_2) &= \texttt{leq $H(e_1)$ $H(e_2)$} &
    M(e_1 \le e_2) &= \texttt{leq $M(e_1)$ $M(e_2)$}
\end{align}
These definitions assume that our object language, Haskell, and OCaml
use the same variable names~$x$ and integer literals~$n$.
If $\Gamma$ is a typing context $x_1:t_1,\dotsc,x_n:t_n$ in the object
language, then we define the metalanguage contexts
\begin{align}
    \texttt{repr\;$H(\Gamma)$}
    &= x_1:\texttt{repr}\;H(t_1),\dotsc,x_n:\texttt{repr}\;H(t_n) \text, \\
    \texttt{('c,\:$M(\Gamma)$)\;repr}
    &= x_1:\texttt{('c,\:$M(t_1)$)\;repr},\dotsc,x_n:\texttt{('c,\:$M(t_n)$)\;repr} \text.
\end{align}

The following proposition states the trivial but fundamental fact that
this representation preserves types.
\begin{proposition}\label{prop:typing}
If an object term~$e$ has the type~$t$ in the context~$\Gamma$,
then the Haskell term~$H(e)$ has the type \texttt{repr\;$H(t)$}
in the context
\[
    \texttt{repr}:\star\to\star,\quad
    \texttt{Symantics repr},\quad
    \texttt{repr}\;H(\Gamma)
    \text,
\]
and the OCaml term~$M(e)$ has the type \texttt{('c,\:$M(t)$)\;repr}
in the context
\[
    \texttt{S:Symantics},\quad
    \texttt{open S},\quad
    \texttt{'c}:\star,\quad
    \texttt{('c,\:$M(\Gamma)$)\;repr}
    \text.
\]
\end{proposition}
\begin{proof}
By structural induction on the derivation in the object language
that $e$ has type~$t$ in~$\Gamma$.
\end{proof}
\begin{corollary}\label{cor:typing}
If a closed object term~$e$ has the type~$t$,
then the Haskell term~$H(e)$ has the type
\[
    \texttt{forall repr. Symantics repr => repr $H(t)$}
\]
and the OCaml functor
\[
    \texttt{functor (S:Symantics) -> struct open S let term () = $M(e)$ end}
\]
has the signature
\[
    \texttt{functor (S:Symantics) -> sig val term: unit -> ('c,\:$M(t)$)\;S.repr end}
    \text{.}
\]
\end{corollary}

Conversely, the type system of the metalanguage checks that the
represented object term is well-typed and closed.
If we err, say replace |int 7| with |bool True| in
|testpowfix7|, the type checker will complain there that the expected type
|Int| does not match the inferred |Bool|.  Similarly, the object term
$\fun{x}xx$ and its
encoding |lam (\x -> app x x)| both fail occurs-checks in type checking.
Both Haskell's and MetaOCaml's type checker also flags syntactically invalid
object terms, such as if we forget |app| somewhere above.

\subsection{Two tagless interpreters}
\label{S:interpreter-RL}

Now that our term representation is independent of any particular interpreter,
we are ready to present a series of interpreters.  Each interpreter is an
instance of the |Symantics| class in Haskell and a module implementing
the |Symantics| signature in OCaml.

The first interpreter evaluates an object term to its value in the
metalanguage.  The module |R| below is metacircular in that it
\emph{runs} each object\hyp language
operation by executing the corresponding metalanguage operation.
\ifshort
\begin{code3}
module R = struct type ('c,'dv) repr = 'dv (* no wrappers *)
  let int  (x:int)  = x         let bool (b:bool) = b
  let lam  f        = f         let app  e1 e2    = e1 e2
  let fix  f        = let rec self n = f self n in self
  let add  e1 e2    = e1 + e2   let mul  e1 e2    = e1 * e2
  let leq  e1 e2    = e1 <= e2
  let if_  eb et ee = if eb then et () else ee () end
\end{code3}
\else
\begin{code}
module R = struct
  type ('c,'dv) repr = 'dv (* no wrappers *)

  let int  (x:int)  = x
  let bool (b:bool) = b
  let lam  f        = f
  let app  e1 e2    = e1 e2
  let fix  f        = let rec self n = f self n in self
  let add  e1 e2    = e1 + e2
  let mul  e1 e2    = e1 * e2
  let leq  e1 e2    = e1 <= e2
  let if_  eb et ee = if eb then et () else ee ()
end
\end{code}
\fi
%
As in~\S\ref{ourapproach},
this interpreter is patently tagless, using neither a universal type nor
any pattern matching: the operation |add| is really
OCaml's addition, and |app| is OCaml's application. To run our
examples, we instantiate the |EX| functor from~\S\ref{encoding}
with~|R|\ifshort: \texttt{module EXR = EX(R)}\fi.
\ifshort\else
\begin{code}
module EXR = EX(R)
\end{code}
\fi
Thus, |EXR.test1 ()| evaluates to the untagged boolean value |true|.
\begin{comment}
%% commenting out this Haskell in JFP version as well
In Haskell, we define
\begin{code}
newtype R a = R {unR::a}
instance Symantics R where ...
\end{code}
Although |R| looks like a tag, it is only
a |newtype|.  The types |a| and |R a| are represented differently
only at compile time, not at run time.  Pattern matching against~|R|
cannot ever fail and is assuredly compiled away.
\end{comment}
It is obvious to the compiler that
pattern matching cannot fail, because there is no
pattern matching. Evaluation can only fail to yield a value
due to interpreting |fix|.
The soundness of the object language's type system with respect to
the dynamic semantics specified by a definitional interpreter
follows from the soundness of the metalanguage's type system.
\ifshort
(The source code shows a total interpreter |L| that measures
the length of each object term.)
\fi
\ifshort
We can also generalize from~|R| to all interpreters;
these propositions follow immediately from the soundness of the
metalanguage's type system.
\fi
\begin{proposition}
If a closed object term~$e$ has type~$t$,
and the OCaml module |I| implements the signature |Symantics|,
then under the OCaml module definition
\[
    \texttt{\begin{tabular}{@{}l@{}}
    module RESULT = \\
    \quad (functor (S:Symantics) -> struct open S let term () = $M(e)$ end) \\
    \quad (I)
    \end{tabular}}
\]
evaluating the expression \texttt{RESULT.term ()} never gets stuck: it either
does not terminate or evaluates to a value of type
\texttt{('c,\:$M(t)$)\;I.repr} (polymorphic over~|'c|).
\end{proposition}
\begin{proof}
By Corollary~\ref{cor:typing} and the type soundness of (this fragment of) OCaml.
\end{proof}
\begin{corollary}
If a closed object term~$e$ has type~$t$,
then under the OCaml module definition
\[
    \texttt{\begin{tabular}{@{}l@{}}
    module RESULT = \\
    \quad (functor (S:Symantics) -> struct open S let term () = $M(e)$ end) \\
    \quad (R)
    \end{tabular}}
\]
evaluating the expression \texttt{RESULT.term ()} never gets stuck: it either
does not terminate or evaluates to a value of type~$M(t)$.
\end{corollary}
\ifshort\else
For variety, we show another interpreter~|L|, which measures the
\emph{length}
of each object term, defined as the number of term
constructors.
\begin{code}
module L = struct
  type ('c,'dv) repr = int

  let int  (x:int)  = 1
  let bool (b:bool) = 1
  let lam  f        = f 0 + 1
  let app  e1 e2    = e1 + e2 + 1
  let fix  f        = f 0 + 1
  let add  e1 e2    = e1 + e2 + 1
  let mul  e1 e2    = e1 + e2 + 1
  let leq  e1 e2    = e1 + e2 + 1
  let if_  eb et ee = eb + et () + ee () + 1
end
\end{code}
Now the OCaml expression
|let module E = EX(L) in E.test1 ()|
evaluates to |3|. This interpreter is not only tagless but also
total. It ``evaluates'' even seemingly divergent terms; for instance,
|app (fix (fun self -> self)) (int 1)| evaluates to $3$.
\fi

\begin{comment}
\begin{code}
module EX1(S: Symantics) = struct
 open S
 let tfix () = app (fix (fun self -> self)) (int 1)
end;;
let module E =EX1(R) in E.tfix ();;
let module E =EX1(L) in E.tfix ();;
\end{code}
\end{comment}

\subsection{Higher-order abstract syntax versus de Bruijn indices}
\label{S:de-Bruijn}

\begin{figure}
\begin{floatrule}
\begin{BVerbatim}
module type Symantics = sig
  type ('c,'h,'dv) repr
  type ('c,'dv) vr			(* variable representation *)

  val vz  : ('c, ('c,'d) vr * 'h, 'd) repr
  val vs  : ('c, 'h, 'd) repr -> ('c, _ * 'h, 'd) repr

  val int : int  -> ('c,'h,int) repr
  val bool: bool -> ('c,'h,bool) repr

  val lam : ('c, ('c,'da) vr * 'h, 'db) repr -> ('c,'h,'da->'db) repr
  val app : ('c,'h,'da->'db) repr -> ('c,'h,'da) repr -> ('c,'h,'db) repr
  val fix : ('c, ('c,'da->'db) vr * 'h, 'da->'db) repr
            -> ('c, 'h, 'da->'db) repr

  val add : ('c,'h,int) repr -> ('c,'h,int) repr -> ('c,'h,int) repr
  val mul : ('c,'h,int) repr -> ('c,'h,int) repr -> ('c,'h,int) repr
  val leq : ('c,'h,int) repr -> ('c,'h,int) repr -> ('c,'h,bool) repr
  val if_ : ('c,'h,bool) repr
            -> (unit -> 'x) -> (unit -> 'x) -> (('c,'h,'da) repr as 'x)
end

module R = struct
  type ('c,'h,'dv) repr = 'h -> 'dv
  type ('c,'d) vr = 'd

  let vz   (x,_) = x
  let vs v (_,h) = v h

  let int  (x:int)  h = x
  let bool (b:bool) h = b
  let lam  f        h = fun x -> f (x,h)
  let app  e1 e2    h = (e1 h) (e2 h)
  let fix  f        h = let rec self n = f (self,h) n in self
  let add  e1 e2    h = e1 h + e2 h
  let mul  e1 e2    h = e1 h * e2 h
  let leq  e1 e2    h = e1 h <= e2 h
  let if_  eb et ee h = if eb h then et () h else ee () h
end
\end{BVerbatim}
\end{floatrule}
\caption{Embedding and evaluating our object language using de Bruijn indices}
\label{fig:de-Bruijn}
\end{figure}

Because Haskell and ML allow case analysis on $\lambda$-bound variables,
one might worry that our HOAS representation of the object language
allows \emph{exotic terms} and is thus inadequate.  To the contrary,
because the representation of an object term is \emph{parametrically}
polymorphic over the type constructor |repr| of the interpreter,
$\lambda$-bound object variables cannot be case-analyzed.
We thus follow \citet{washburn-boxes-jfp} in ``enforcing term
parametricity with type parametricity'' to represent and fold over
abstract syntax.

Although the rest of this paper continues to represent binding
using HOAS\@, our approach is compatible with de Bruijn indices.
The accompanying source file |incope-dB.ml| implements this
alternative, starting with the |Symantics| signature and the |R|
evaluator in Figure~\ref{fig:de-Bruijn}.
In this encoding of the object language, |vz| represents the
innermost variable, |vs vz| represents the second-to-innermost variable,
and so on.  The new type argument |'h| to |repr| tracks the type of
the environment as a nested tuple, each of whose components is a
value of type |('c,'dv) vr| representing a variable of type~|'dv|.
The evaluator~|R| interprets each object term as a function
from its environment to its value.

\section{A tagless compiler (or, a staged interpreter)}\label{S:compiler}

Besides immediate evaluation, we can compile our object language
into OCaml code using MetaOCaml's staging facilities. MetaOCaml
represents future-stage expressions of type~$t$
as values of type |('c, |$t$|) code|, where |'c| is the
environment classifier \citep{WalidPOPL03,calcagno-ml-like}. Code values are created
by a \emph{bracket} form |.<|$e$|>.|, which quotes the expression~$e$ for
evaluation at a future stage. The \emph{escape} |.~|$e$ must occur
within a bracket and specifies that the expression~$e$ must be evaluated
at the current stage; its result, which must be a code value, is
spliced into the code being built by the enclosing bracket. The \emph{run} form |.!|$e$ evaluates
the future-stage code value~$e$ by compiling and linking it at run time.
Bracket, escape, and run are akin to
quasi-quotation, unquotation, and |eval| of Lisp.

% this code does not have the 'sv parameter. It shows up later.
\ifshort
\begin{SaveVerbatim}{5a}
module C = struct type ('c,'dv) repr = ('c,'dv) code
  let int (x:int)  = .<x>.            let bool (b:bool) = .<b>.
  let lam f        = .<fun x -> .~(f .<x>.)>.
  let app e1 e2    = .<.~e1 .~e2>.
  let fix f =  .<let rec self n = .~(f .<self>.) n in self>.
  let add e1 e2    = .<.~e1 + .~e2>.  let mul e1 e2 = .<.~e1 * .~e2>.
  let leq e1 e2    = .<.~e1 <= .~e2>.
  let if_ eb et ee = .<if .~eb then .~(et ()) else .~(ee ())>. end
\end{SaveVerbatim}
\else
\begin{SaveVerbatim}{5a}
module C = struct
  type ('c,'dv) repr = ('c,'dv) code

  let int (x:int)   = .<x>.
  let bool (b:bool) = .<b>.
  let lam f         = .<fun x -> .~(f .<x>.)>.
  let app e1 e2     = .<.~e1 .~e2>.
  let fix f         = .<let rec self n = .~(f .<self>.) n in self>.
  let add e1 e2     = .<.~e1 + .~e2>.
  let mul e1 e2     = .<.~e1 * .~e2>.
  let leq e1 e2     = .<.~e1 <= .~e2>.
  let if_ eb et ee  = .<if .~eb then .~(et ()) else .~(ee ())>.
end
\end{SaveVerbatim}
\fi
\begin{SaveVerbatim}{5b}
let module E = EX(C) in E.test1 ()
\end{SaveVerbatim}
\begin{SaveVerbatim}{5c}
let module E = EX(C) in E.testpowfix7
\end{SaveVerbatim}
\begin{SaveVerbatim}{5d}
.<fun x_1 -> (fun x_2 -> let rec self_3 = fun n_4 ->
   (fun x_5 -> if x_5 <= 0 then 1 else x_2 * self_3 (x_5 + (-1)))
   n_4 in self_3) x_1 7>.
\end{SaveVerbatim}

To turn the evaluator~|R| into a simple compiler, we bracket the
computation on values to be performed at run time, then escape the code
generation from terms to be performed at compile time.  Adding these
stage annotations yields the compiler~|C|
\ifshort in Figure~\ref{fig:interpreter-C}(a).\else below.
\UseVerbatim{5a}
\fi
\ifshort
\begin{figure}[t]
(a) \BUseVerbatim{5a}

\smallskip
(b) \BUseVerbatim{5b}

\smallskip
(c) \BUseVerbatim{5c}

\smallskip
(d) \BUseVerbatim{5d}

\medskip
\caption{The tagless staged interpreter \texttt{C}}
\label{fig:interpreter-C}
\end{figure}
\fi
This is a straightforward staging of
|module R|.
This compiler produces
unoptimized code. For example, interpreting our |test1| with
\ifshort Figure~\ref{fig:interpreter-C}(b) \else \UseVerbatim{5b}\fi
gives the code value |.<(fun|~|x_6|~|->|~|x_6)| |true>.|
of inferred type |('c,|~|bool)| |C.repr|.  Interpreting |testpowfix7|
with
\ifshort Figure~\ref{fig:interpreter-C}(c) \else \UseVerbatim{5c}\fi
gives a code value with many apparent $\beta$- and $\eta$-redexes\ifshort,
Figure~\ref{fig:interpreter-C}(d). \else: \UseVerbatim{5d}\fi
This compiler does not incur
any interpretive overhead: the
code produced for $\fun{x}x$ is simply |fun|~|x_6|~|->|~|x_6|\ifshort\else\
and does not
call the interpreter, unlike the recursive calls to |eval0| and
|eval| in the |L e| lines in \S\ref{tagproblem}\fi.
The resulting code obviously contains no tags and no pattern matching.
The environment classifiers here, like the tuple types in \S\ref{ourapproach},
make it a type error to run an open expression.
\ifshort
The accompanying code shows the Haskell implementation. 
\else
\begin{proposition}
If an object term~$e$ has the type~$t$
in the context $x_1:t_1,\dotsc,x_n:t_n$,
then in a MetaOCaml environment
\[
    \texttt{open C},\quad
    x_1 \mapsto \texttt{.<$y_1$>.},\enspace
    \dotsc,\enspace
    x_n \mapsto \texttt{.<$y_n$>.}
\]
where each $y_i$ is a future-stage variable of type $M(t_i)$,
the MetaOCaml term~$M(e)$ evaluates to a code value,
of type~\texttt{('c,\:$M(t)$)\;code} (polymorphic over~|'c|),
that contains no pattern-matching operations.
\end{proposition}
\begin{proof}
    By structural induction on the typing derivation of~$e$.
\end{proof}
\begin{corollary}
If a closed object term~$e$ has type~$t$,
then under the OCaml module definition
\[
    \texttt{\begin{tabular}{@{}l@{}}
    module RESULT = \\
    \quad (functor (S:Symantics) -> struct open S let term () = $M(e)$ end) \\
    \quad (C)
    \end{tabular}}
\]
the expression \texttt{RESULT.term ()} evaluates to a code value,
of type~\texttt{('c,\:$M(t)$)\;code} (polymorphic over~|'c|),
that contains no pattern-matching operations.
\end{corollary}

We have also implemented this compiler in Haskell. 
Since Haskell
has no convenient facility for typed staging, we emulate
it by defining a data type |ByteCode| with
constructors such as |Var|, |Lam|, |App|, |Fix|, and |INT|.
(Alternatively, we could use Template Haskell \citep{sheard-template} as our staging facility:
\texttt{ByteCode} can be mapped to the abstract syntax of Template
Haskell. The output of our compiler would then be assuredly type-correct
Template Haskell.)
Whereas our representation of object terms uses HOAS,
our bytecode uses integer-named
variables to be realistic. 
We then define 
\begin{code}
newtype C t = C (Int -> (ByteCode t, Int)) 
\end{code}
where |Int| is the counter for creating fresh variable
names. We define the compiler by making |C| an instance of the
class |Symantics|.
The implementation is quite similar (but slightly more
verbose) than the MetaOCaml code above. (The implementation uses
GADTs because we also wanted to write a typed interpreter for 
the \texttt{ByteCode} \emph{data type}.) The
accompanying code gives the full details.
\fi

%------------------------------------------------------------------------
% This is the version for the APLAS paper.
\ifshort
\input{tagless-final-aplas}
%------------------------------------------------------------------------
% This is the longer version of the section
\else

\section{A tagless partial evaluator}\label{PE}
Surprisingly, this |Symantics| interface extends to
encompass an online partial evaluator that uses no universal type and no tags
for object types.  We present this partial evaluator
in a sequence of three attempts to express the types
of residualization and binding-time
analysis.  Our partial evaluator is a modular extension of the evaluator
in~\S\ref{S:interpreter-RL} and the compiler in~\S\ref{S:compiler}, in
that it uses the former to reduce static terms and the latter to build
dynamic terms.

\subsection{Avoiding polymorphic lift}
\label{S:PE-lift}

Roughly, a partial evaluator interprets each object term to yield either
a static (present-stage) term (using the evaluator~|R|) or
a dynamic (future-stage) term (using the compiler~|C|).  To
distinguish between static and dynamic terms, we might try to define
|repr| in the partial evaluator as follows.
In the phase tags |S0| and~|D0|, the digit zero indicates
our initial attempt.
\begin{code}
type ('c,'dv) repr = S0 of ('c,'dv) R.repr | D0 of ('c,'dv) C.repr
\end{code}
To extract a dynamic term from this type, we create the function
\begin{code}
let abstrI0 (e : ('c,int) repr) : ('c,int) C.repr =
  match e with S0 e -> C.int e | D0 e -> e
\end{code}
and the similar function |abstrB0| for dynamic boolean terms. Here, 
|C.int| is used to convert a static term (of type |('c,int) R.repr|, 
which is just |int|) to a dynamic term. We can now define the following
components required by the |Semantics| signature:
\begin{code}
let int  (x:int)  = S0 (R.int x)
let bool (x:bool) = S0 (R.bool x)
let add e1 e2 = match (e1,e2) with
  | (S0 e1, S0 e2) -> S0 (R.add e1 e2)
  | _ -> D0 (C.add (abstrI0 e1) (abstrI0 e2))
\end{code}
Integer and boolean literals are immediate, present-stage
values. Addition yields a static term (using~|R.add|) if and only 
if both operands are static; otherwise we extract the dynamic terms 
from the operands and add them using~|C.add|.

Whereas |mul| and |leq| are as easy to define as |add|, we encounter
a problem with |if_|.  Suppose that the first argument to |if_| 
is a dynamic term
(of type |('c,bool) C.repr|), the second a static term 
(of type |('c,'a) R.repr|), and the third a
dynamic term (of type |('c,'a) C.repr|). We then need to convert
the static term to dynamic, but there is no polymorphic ``lift''
function, of type |'a -> ('c,'a) C.repr|, to send a value to a future stage
\citep{xi-guarded,WalidPOPL03}.
\begin{comment}
(By the way, if we
were to add polymorphic \texttt{lift} to the type class
\texttt{Symantics repr}, then \texttt{repr} would become an instance of
\texttt{Applicative} and thus \texttt{Functor}:\texttt{ fmap
f = app (lift f)~}.)
\end{comment}

Our |Symantics| signature only includes separate lifting methods |bool| and
|int|, not a polymorphic lifting method, for good reason:
When compiling to a first-order target language such as machine code,
booleans, integers, and functions may well be represented differently.
Compiling a polymorphic lift function thus requires intensional type
analysis.  To avoid needing polymorphic lift, we turn to
\citets{Sperber-SelfApplicable} and \citets{asai-binding-time} technique of
building a dynamic term alongside every static term \citep{sumii-hybrid}.

\subsection{Delaying binding-time analysis}
\label{S:PE-problem}

We start building the partial evaluator anew and
switch to the data type
\begin{code}
type ('c,'dv) repr = P1 of ('c,'dv) R.repr option * ('c,'dv) C.repr
\end{code}
so that a partially evaluated term always contains a dynamic
component and sometimes contains a static component.
The two
alternative constructors of an |option| value, |Some| and |None|,
tag each partially evaluated term to indicate whether its value is
known statically at the present stage.
This tag is not an object type tag: all pattern matching below
is exhaustive. Now that the future-stage component is always available, we
can define the polymorphic function
\begin{code}
let abstr1 (P1 (_,dyn) : ('c,'dv) repr) : ('c,'dv) C.repr = dyn
\end{code}
to extract it without needing polymorphic lift into~|C|.  We then try
to define the term combinators\nobreak\hspace{0pt}---and get as far as
the first-order constructs of our object language, including |if_|.
\begin{code}
let int (x:int) = P1 (Some (R.int x), C.int x)
let add e1 e2 = match (e1,e2) with
  | (P1 (Some n1, _), P1 (Some n2, _)) -> int (R.add n1 n2)
  | _ -> P1 (None, C.add (abstr1 e1) (abstr1 e2))
let if_ eb et ee = match eb with
  | P1 (Some s, _) -> if s then et () else ee ()
  | _ -> P1 (None, C.if_ (abstr1 eb) (fun () -> abstr1 (et ()))
                                     (fun () -> abstr1 (ee ())))
\end{code}
However, we stumble on functions.  Given how we just
defined~|repr|, a partially evaluated object function, such as the
identity $\fun{x}x$ (of type $\ZZ\to\ZZ$) embedded in OCaml as
|lam (fun x -> x)| (of type |('c,int->int) repr|), consists of
a dynamic part (of type |('c,int->int) C.repr|) and optionally
a static part (of type |('c,int->int) R.repr|).  The dynamic part is useful
when this function is passed to another function that is only
dynamically known, as in $\fun{k}k(\fun{x}x)$.  The static part is
useful when this function is applied to a static argument, as in
$(\fun{x}x)\True$.  Neither part, however, lets us \emph{partially}
evaluate the function, that is, compute as much as possible statically
when it is applied to a mix of static and dynamic inputs.  For example,
the partial evaluator should turn $\fun{n}(\fun{x}x)n$ into $\fun{n}n$
by substituting $n$ for~$x$ in the body of $\fun{x}x$ even though $n$ is
not statically known.  The same static function, applied to
different static arguments, can give both static and dynamic results: we
want to simplify $(\fun{y}x\times y)0$ to~$0$ but $(\fun{y}x\times y)1$
to~$x$.

To enable these simplifications, we delay binding-time analysis
for a static function until it is applied, that is, until |lam f|
appears as the argument of |app|.  To do so, we have to incorporate |f|
as is into |lam f|: the type |('c,'a->'b) repr| should be one of
\begin{code}
S1 of ('c,'a) repr -> ('c,'b) repr | E1 of ('c,'a->'b) C.repr
P1 of (('c,'a) repr -> ('c,'b) repr) option * ('c,'a->'b) C.repr
\end{code}
unlike |('c,int) repr| or |('c,bool) repr|.
That is, we need a nonparametric data type, something akin to
type-indexed functions and type-indexed types, which
\citet{oliveira-typecase} dub the \emph{typecase} design pattern.
Thus, typed partial evaluation, like typed CPS transformation
(see \S\ref{S:CPS}),
inductively defines a map from source types to target types that
performs case distinction on the source type. In Haskell, typecase
can be implemented using either GADTs or
type-class functional dependencies
\citep{oliveira-typecase}. The accompanying code shows both
approaches (|Incope.hs| and |incope1.hs|), 
neither of which is portable to OCaml. In addition,
the problem of non\hyp exhaustive pattern\hyp matching reappears in
the GADT approach because GHC 6.8 and prior cannot see that a particular
type of GADT value precludes certain constructors. Although this
is an implementation issue of GHC,
it indicates that assuring exhaustive pattern match with GADTs
requires non-trivial reasoning (beyond the abilities of GHC at the moment);
certainly GADTs fail to
make it \emph{syntactically} apparent that pattern matching is exhaustive.

%% \subsection{Eliminating tags from typecase}
%% \label{S:PE-GADT}

%% Two common ways to provide typecase in Haskell are
%% GADTs and type-class functional dependencies
%% \citep{oliveira-typecase}.  These
%% methods are equivalent, and here we use GADTs; |incope1.hs|
%% in the accompanying source code shows the latter.
%% We introduce a GADT with four data constructors.
%% \begin{code}
%% data P t where
%%   VI :: Int  -> P Int
%%   VB :: Bool -> P Bool
%%   VF :: (P a -> P b) -> P (a -> b)
%%   E  :: C t -> P t
%% \end{code}
%% The constructors |VI|, |VB|, and |VF| build static terms (like |S0|
%% in~\S\ref{S:PE-lift}), and |E| builds dynamic terms (like |D0|).  However,
%% the type |P t| is no longer parametric in~|t|: the constructor |VF| takes an
%% operand of type |P a -> P b| rather than |a -> b|.  We define a function
%% like |abstr1| above to extract a future-stage computation from a 
%% value of type |P t|.
%% \begin{code}
%% abstr :: P t -> C t
%% abstr (VI i) = int i
%% abstr (VB b) = bool b
%% abstr (VF f) = lam (abstr . f . E)
%% abstr (E x)  = x
%% \end{code}
%% The cases of this function |abstr| are type-indexed.  In particular, the |VF f|
%% case uses the method |lam| of the |C| interpreter to compile~|f|.

%% We may now make |P| an instance of
%% |Symantics| and implement the partial evaluator as follows. We elide
%% |mul|, |leq|, |if_|, and |fix|.
%% \begin{code}
%% instance Symantics P where
%%   int x               = VI x
%%   bool b              = VB b
%%   add (VI n1) (VI n2) = VI (n1 + n2)
%%   add e1 e2           = E (add (abstr e1) (abstr e2))
%%   lam                 = VF
%%   app (VF f) ea       = f ea
%%   app (E f)  ea       = E (app f (abstr ea))
%% \end{code}
%% The implementations of |int|, |bool|, and |add| are like 
%% in~\S\ref{S:PE-problem}. The interpretation of |lam f| is |VF f|, 
%% which just wraps the HOAS function |f|. 
%% We can always compile |f| to a code value,
%% but we delay it to apply |f| to concrete arguments. The interpretation of
%% |app ef ea| checks to see if |ef| is such a delayed
%% HOAS function |VF f|. If it is, we apply |f| to the
%% concrete argument |ea|, giving us a chance to perform static
%% computations (see example |testpowfix7| in~\S\ref{S:PE-solution}). If |ef| is a
%% dynamic value |E f|, we residualize.

%% This solution using GADTs works but is not quite satisfactory. First, it
%% cannot be ported to MetaOCaml, as GADTs are unavailable there.  Second,
%% the problem of nonexhaustive pattern\hyp matching reappears in
%% |app| above: the type |P t| has four constructors, of which the pattern in
%% |app| matches only |VF| and~|E|. One may say that the
%% constructors |VI| and |VB| obviously cannot occur because they do not
%% construct values of type |P (a -> b)| as required by the type of |app|.
%% Indeed, the metalanguage implementation could reason thus:
%% if we use inductive families (as in Coq) or logical
%%   frameworks with canonical forms (as in Twelf with its coverage checker),
%%   we can prove the pattern matching to be exhaustive.
%% Then again, the metalanguage implementation may not reason thus:
%% GHC cannot and issues warnings.
%% Although this point may seem minor, it is the heart of
%% the tagging problem and the purpose of tag elimination. A typed tagged
%% interpreter contains many pattern\hyp matching forms that look partial
%% but never fail in reality. The
%% goal is to make this exhaustiveness \emph{syntactically} apparent.


\subsection{The ``final'' solution}
\label{S:PE-solution}

The problem in the last section is that we want to write
\begin{code}
type ('c,'dv) repr = P1 of ('c,'dv) static option * ('c,'dv) C.repr
\end{code}
where |static| is the type function defined
% inductively because P below depends on static
by
\begin{code}
('c,int)    static = ('c,int) R.repr
('c,bool)   static = ('c,bool) R.repr
('c,'a->'b) static = ('c,'a) repr -> ('c,'b) repr
\end{code}
Although we can use type classes to define this type function
in Haskell, that is not portable to OCaml. However,
the three typecase alternatives of |static| are already present in existing
methods of |Symantics|.
Thus emerges
a simple and portable solution, if a long-winded one:
we bake |static| into the signature |Symantics|. 
In Figure~\ref{fig:ocaml-simple},
the |repr| type constructor took two arguments |('c,'dv)|;
in Figure~\ref{fig:ocaml},
we add an argument |'sv| for the type |('c,'dv) static|.
\begin{figure}
\begin{floatrule}
\begin{code2}
module type Symantics = sig
  type ('c,'sv,'dv) repr

  val int : int  -> ('c,int,int) repr
  val bool: bool -> ('c,bool,bool) repr

  val lam : (('c,'sa,'da) repr -> ('c,'sb,'db) repr as 'x)
            -> ('c,'x,'da -> 'db) repr
  val app : ('c,'x,'da -> 'db) repr
            -> (('c,'sa,'da) repr -> ('c,'sb,'db) repr as 'x)
  val fix : ('x -> 'x) -> (('c, ('c,'sa,'da) repr -> ('c,'sb,'db) repr,
                                'da -> 'db) repr as 'x)

  val add : ('c,int,int) repr -> ('c,int,int) repr -> ('c,int,int) repr
  val mul : ('c,int,int) repr -> ('c,int,int) repr -> ('c,int,int) repr
  val leq : ('c,int,int) repr -> ('c,int,int) repr -> ('c,bool,bool) repr
  val if_ : ('c,bool,bool) repr
            -> (unit -> 'x) -> (unit -> 'x) -> (('c,'sa,'da) repr as 'x)
end
\end{code2}
\end{floatrule}
\caption{A (Meta)OCaml embedding of our object language that supports
  partial evaluation}
\label{fig:ocaml}
\end{figure}

\begin{figure}
\begin{floatrule}
\begin{code2}[commandchars=\@\[\]]
module P = struct
  type ('c,'sv,'dv) repr = {st: 'sv option; dy: ('c,'dv) code}
  let abstr {dy = x} = x
  let pdyn x = {st = None; dy = x}

  let int  (x:int ) = {st = Some (R.int  x); dy = C.int  x}
  let bool (x:bool) = {st = Some (R.bool x); dy = C.bool x}

  let add e1 e2 = match e1, e2 with
                  | {st = Some 0}, e | e, {st = Some 0} -> e
                  | {st = Some m}, {st = Some n} -> int (R.add m n)
                  | _ -> pdyn (C.add (abstr e1) (abstr e2))
  let if_ eb et ee = match eb with
                     | {st = Some b} -> if b then et () else ee ()
                     | _ -> pdyn (C.if_ (abstr eb) (fun () @!->@! abstr (et @!()))
                                                   (fun () @!->@! abstr (ee @!())))

  let lam f = {st = Some f; dy = C.lam (fun x -> abstr (f (pdyn x)))}
  let app ef ea = match ef with
                  | {st = Some f} -> f ea
                  | _ -> pdyn (C.app (abstr ef) (abstr ea))
  let fix f = let fdyn = C.fix (fun x -> abstr (f (pdyn x)))
              in let rec self = function
                                | {st = Some @!_} as e -> app (f (lam self)) e
                                | e -> pdyn (C.app fdyn (abstr e))
                 in {st = Some self; dy = fdyn}
end
\end{code2}
\end{floatrule}
\caption{Our partial evaluator (\texttt{mul} and \texttt{leq}
  are elided)}
\label{fig:pe}
\end{figure}

The interpreters |R|, |L| and~|C| in \S\ref{S:interpreter-RL} and~\S\ref{S:compiler}
only use the old
type arguments |'c| and~|'dv|, which are treated by the new signature
in the same way.  Hence, all that needs to change in these interpreters
to match the new signature is to add a phantom type
argument~|'sv| to~|repr|.
For example, the compiler |C| now begins
\begin{code}
module C = struct
  type ('c,'sv,'dv) repr = ('c,'dv) code
\end{code}
with the rest the same.

Figure~\ref{fig:pe} shows the partial evaluator~|P|.
Its type |repr| expresses the definition for |static| given
at the start of this section, with |'sv| taking the crucial place of |('c,'dv) static|.
The function |abstr|
extracts a future-stage code value from the result of
partial evaluation.  Conversely, the function |pdyn| injects a
code value into the |repr| type. As
in~\S\ref{S:PE-problem}, we build dynamic terms alongside
any static ones to express how the lift function is indexed
by the dynamic type.  What is new is that we analogously
build a static type alongside the dynamic type to express
how the static type is indexed by the dynamic type.

The static portion of the interpretation of |lam f| is |Some f|, 
which just wraps the HOAS
function |f|. The interpretation of |app ef ea| 
checks to see if |ef| is such a wrapped
HOAS function. If it is, we apply |f| to the
concrete argument |ea|, so as to perform static
computations (see the example below). If
|ef| has only a dynamic part, we residualize.

To illustrate how to add optimizations, we improve |add| (and |mul|,
elided) to simplify the generated code using the monoid (and ring)
structure of~|int|: not only is addition performed statically
(using~|R|) when both operands are statically known, but it is
eliminated when one operand is statically~$0$; similarly for
multiplication by~$0$ or~$1$.  
Although our basic machinery for partial evaluation is independent of
such algebraic simplifications, it makes them easy to add and
to abstract over the specific domains (such as monoid or ring) where they
apply.  These simplifications and abstractions help a lot
in a large language with more base types and primitive operations.
Incidentally, the accompanying code actually contains a more general
implementation mechanism for such features, inspired in part by previous work
in generative linear algebra~\citep{CaretteKiselyov05}.

Any partial evaluator must decide how much to unfold recursion
statically: unfolding too little can degrade the residual code, whereas
unfolding too much risks nontermination.  Our partial evaluator is no
exception, because our object language includes |fix|.  The code in
Figure~\ref{fig:pe} takes the na\"\i ve approach of ``going all the
way'', that is, whenever the 
argument is static, we unfold |fix| rather than residualize it.
A conservative alternative is to unfold recursion only once, then residualize:
\begin{code}
let fix f = f (pdyn (C.fix (fun x -> abstr (f (pdyn x)))))
\end{code}
Many sophisticated approaches have been developed to decide how much to unfold
\citep{Jones-Mix,jones-partial}, but this issue is 
orthogonal to our presentation.
A separate concern in our treatment of |fix| is possible code bloat in
the residual program, which calls for let-insertion
\citep{BondorfDanvy,SwadiTahaKiselyovPasalic2006}.


Given this implementation of~|P|, our running example
\begin{code}
let module E = EX(P) in E.test1 ()
\end{code}
evaluates to
\begin{code}
{P.st = Some true; P.dy = .<true>.}
\end{code}
of type |('a, bool, bool) P.repr|.  Unlike with~|C| in~\S\ref{S:compiler},
a $\beta$-reduction has been statically performed to yield |true|.  More
interestingly, whereas |testpowfix7| compiles to a code value with many
$\beta$-redexes in~\S\ref{S:compiler}, the partial evaluation
\begin{code}
let module E = EX(P) in E.testpowfix7
\end{code}
gives the desired result
\begin{code}
{P.st = Some <fun>;
 P.dy = .<fun x -> x * (x * (x * (x * (x * (x * x)))))>.}
\end{code}

All pattern\hyp
matching in~|P| is \emph{syntactically} exhaustive, so it is patent to the
metalanguage implementation that |P| never gets stuck.  Further,
|P| uses pattern\hyp matching
only to check if a value is known statically,
never to check what type a value has dynamically.
In other words, our partial evaluator tags
phases (with |Some| and |None|) but not object types, so it
is patent that the \emph{output} of~|P| never gets stuck.

Predating us, \citet{Thiemann-combinators} and \citet{sumii-hybrid} deforested
the object term representation and expressed a partial evaluator as a collection
of term combinators in a typed metalanguage.  Like us, \citeauthor{sumii-hybrid}
follow \citet{Sperber-SelfApplicable} and \citet{asai-binding-time} in building
static and dynamic terms in tandem, to combine offline and online partial
evaluation.
\citearound{'s earlier self-reducer for the untyped
$\lambda$-calculus}\Citet{JFP-Mogensen} also
builds static and dynamic terms in tandem.  However, it
builds a static term for every object term, even a bound variable,
so it moves some work from |app| to~|pdyn| (in terms of Figure~\ref{fig:pe})
and remains untyped.  In contrast, we follow Sperber, Asai,
and \citeauthor{sumii-hybrid} in leaving the static term
optional, so as to perform lifting without
juggling explicit type indices in the encoding of an object term.

Our contribution to the literature on partial evaluation is to use mere
Hindley-Milner types in the metalanguage to assure statically and patently that
partially evaluating a well-typed object program not only never gets stuck but
also, if it terminates, produces a well-typed output program that never gets
stuck.  Moreover, these types form an instance of a general |Symantics|
signature that encompasses other interpreters such as evaluation and
compilation.  This early and manifest assurance of type safety contrasts, for
example, with \citearound{'s compiler generator (cogen) for
ML}\citet{Birkedal-PE-ML}, which transforms a program into its tagless
generating extension.  Because that cogen uses a universal type, the fact that
it never generates an ill-typed generating extension from a well-typed input
program is only manifest when each generating extension is type-checked, and the
fact that the generating extension never generates an ill-typed residual program
from well-typed static input is only manifest when each residual program is
type-checked.  Similarly, the fact that \citet{fiore:nbe-ppdp2002} and
\citets{balat:tdpe-popl2004} partial evaluator using delimited control
operators never turns well-typed code into ill-typed code is not assured by the
metalanguage, whether or not as part of a typed family of interpreter modules.
\begin{comment}
% Removed the following comment in view of Section 4.5 of Danvy's
% original TDPE paper (POPL 1996)
It is
type-directed, so the user must represent, as a term, the type of every
term to be partially evaluated.  We shift this work to the type checker
of the metalanguage.
By avoiding term-level type representations, our
approach makes it easier to perform algebraic simplifications (as
in~\S\ref{S:PE-solution}).
\end{comment}

Our partial evaluator reuses the
compiler~|C| and the evaluator~|R| by composing them.  This situation is
simpler than \citets{SperberThiemann:TwoForOne} composition of a partial
evaluator and a compiler, but the general ideas are similar.
\fi


% don't even have space for CPS
\ifshort\else
\section{Continuation\hyp passing style}\label{variations}

Our approach accommodates
several variants, including
a call-by-name CPS interpreter and a call-by-value CPS
transformation.
\ifshort\label{state}\label{S:CPS}%
This lets us decouple the evaluation strategy of the object language
from that of the metalanguage. The accompanying code shows the CBN CPS
interpreter (module |RCN| implementing |Symantics|) and a CBV CPS
transformer |CPST|. The latter explicitly maps CPS interpretations to
(direct) interpretations performed by the base interpreter~|S|. All
these interpreters are typed, tagless and \emph{type-preserving} (as
well as fully polymorphic in the answer-type). The type preservation
is the consequence of the type soundness of the metalanguage.  We can
modify the CBV CPS transformation to pass a piece of state along with
the continuation. This technique lets us support mutable state.  Due
to the severe lack of space we cannot describe these interpreters and
refer the reader to the accompanying code.

\else

\subsection{Call-by-name CPS interpreters}\label{S:CPS}

The object language generally inherits the evaluation strategy from
the metalanguage---call-by-value (CBV) in OCaml, call-by-name (CBN) in
Haskell.\footnote{To be more precise, most Haskell implementations
use call-by-need, which is observationally equivalent to call-by-name
because sharing is not observable \citep{ariola-call-by-need-popl}.}
To represent a CBN object language in a CBV metalanguage,
\citet{reynolds-definitional,reynolds-relation} and \citet{PlotkinCBN}
introduce CPS to make the evaluation strategy of a definitional
interpreter indifferent to that of the metalanguage. To achieve the same
indifference in the typed setting, we build a CBN CPS interpreter for
our object language in OCaml.

The interpretation of an object term is a function
mapping a continuation~|k| to the answer
returned by~|k|.
\begin{code}
let int (x:int) = fun k -> k x
let add e1 e2 = fun k -> e1 (fun v1 -> e2 (fun v2 -> k (v1 + v2)))
\end{code}
In both |int| and |add|, the interpretation has type 
|(int -> 'w)|\texttt{ }|-> 'w|, where |'w| is the (polymorphic) answer type.

Unlike CBV CPS, the CBN CPS interprets
abstraction and application as follows:
\begin{code}
let lam f = fun k -> k f
let app e1 e2 = fun k -> e1 (fun f -> f e2 k)
\end{code}
Characteristic of CBN, |app e1 e2|
does not evaluate the argument~|e2| by applying it to the
continuation~|k|. Rather, it passes |e2| unevaluated to the abstraction.
Interpreting $\fun{x} x+1$ yields type
\begin{code}
((((int -> 'w1) -> 'w1) -> (int -> 'w1) -> 'w1) -> 'w2) -> 'w2
\end{code}

We would like to collect those interpretation functions into a module
with signature |Symantics|, to include the CBN CPS interpreter within our
general framework. Alas, as in~\S\ref{S:PE-problem}, the type of
an object term inductively determines the type of its interpretation:
the interpretation of an object term of type~$t$ may not have type
|(|$t$|->'w)->'w|, because $t$ may be a function type.  Again we
simulate a type function with a typecase distinction, using an extra
type argument to |repr|. Luckily, the type function |static| needed for
the partial evaluator 
in~\S\ref{S:PE-solution} is precisely the same type function we
need for CBN CPS\@.
\begin{code}
module RCN = struct
  type ('c,'sv,'dv) repr = {ko: 'w. ('sv -> 'w) -> 'w}
  let int (x:int) = {ko = fun k -> k x}
  let add e1 e2 = {ko = fun k ->
      e1.ko (fun v1 -> e2.ko (fun v2 -> k (v1 + v2)))}
  let if_ eb et ee = {ko = fun k ->
      eb.ko (fun vb -> if vb then (et ()).ko k else (ee ()).ko k)}
  let lam f = {ko = fun k -> k f}
  let app e1 e2 = {ko = fun k -> e1.ko (fun f -> (f e2).ko k)}
  let fix f = let rec fx f n = app (f (lam (fx f))) n in lam (fx f)
  let run x = x.ko (fun v -> v)
end
\end{code}

This interpreter~|RCN| is fully polymorphic over the answer type,
using higher-rank polymorphism through OCaml record types.
To avoid this higher-rank polymorphism in the core language, which
Standard ML does not support, we could also define |RCN| as
a functor parameterized over
the answer type.
\begin{code}
module RCN(W : sig type w end)= struct
  type ('c,'sv,'dv) repr = ('sv -> W.w) -> W.w
  ...
\end{code}
This allows a translation of these techniques to, for example, Standard ML\@.
Unfortunately, the loss of polymorphism in the answer type makes the 
CPS evaluator less pleasant to use than the other implementations.

Because |RCN| has the signature |Symantics|, we can instantiate our previous
examples with it, and all works as expected.  More interesting
is the example $(\fun{x}1)\bigl((\fix{f}f)\mathinner2\bigr)$, which terminates
under CBN but not CBV\@.
\begin{code}
module EXS(S: Symantics) = struct open S
 let diverg () = app (lam (fun x -> int 1)) 
                     (app (fix (fun f->f)) (int 2))
end
\end{code}
Interpreting |EXS| with the |R| interpreter of
\S\ref{S:interpreter-RL} does not terminate.
\begin{code}
let module M = EXS(R) in M.diverg ()
\end{code}
In contrast, the CBN interpreter gives the result~|1|.
\begin{code}
let module M = EXS(RCN) in RCN.run (M.diverg ())
\end{code}

\subsection{CBV CPS transformers}

Changing one definition turns our CBN CPS interpreter into CBV\@.
\begin{code}
module RCV = struct include RCN
  let lam f = {ko = fun k -> k
      (fun e -> e.ko (fun v -> f {ko = fun k -> k v}))}
end
\end{code}
Now an applied abstraction
evaluates its argument before proceeding. This approach is in
line with \citets{reynolds-relation}, albeit typed. The
interpreter~|RCV| is useful for CBV evaluation of the object language
whether the metalanguage is CBV or CBN\@.

We turn to a more general approach to CBV CPS: a CPS transformer that
turns any implementation of |Symantics| into a CPS version of that
evaluator.
This functor on interpreters performs a textbook
CPS transformation on the object language.
\begin{code}
module CPST(S: Symantics) = struct
  let int i = S.lam (fun k -> S.app k (S.int i))
  let add e1 e2 = S.lam (fun k -> S.app e1 (S.lam (fun v1 ->
                                  S.app e2 (S.lam (fun v2 ->
                                  S.app k (S.add v1 v2))))))
  let lam f = S.lam (fun k -> S.app k
              (S.lam (fun x -> f (S.lam (fun k -> S.app k x)))))
  let app e1 e2 = S.lam (fun k -> S.app e1 (S.lam (fun f ->
                                  S.app e2 (S.lam (fun v ->
                                  S.app (S.app f v) k)))))
  let fix = S.fix
end
\end{code}
This (abbreviated) code explicitly maps CPS interpretations to
(direct) interpretations performed by 
the base interpreter~|S|.

The module returned by |CPST| does not define |repr|
and thus does not have signature |Symantics|.
The reason is again the type of |lam f|. Whereas
|int| and |add| return the (abbreviated) type
|('c, ..., (int -> 'w) -> 'w) S.repr|,
the type of \texttt{lam (add (int~1))} is
\begin{code}
('c, ..., ((int -> (int -> 'w1) -> 'w1) -> 'w2) -> 'w2) S.repr
\end{code}
Hence, to write the type equation defining |CPST.repr| we again need
a type function with a typecase distinction, similar to |static|
in~\S\ref{S:PE-solution}. Alas, the type function we need is not
identical to |static|, so we need to add another type argument to
|repr| in the |Symantics| signature. As in~\S\ref{S:PE-solution}, the
terms in previous implementations of |Symantics| stay unchanged, but the
|repr| type equations in those implementations have to take a new
(phantom) type argument.
The verbosity of these types is the only difficulty in defining a
new signature to replace |Symantics| that the output of |CPST| matches.

For brevity, we just
use the module returned by |CPST| as is. Because it does not
match the signature |Symantics|, we cannot apply the |EX| functor to it.
Nevertheless, we can write the tests.
\begin{code}
module T = struct
  module M = CPST(C)
  open M
  let test1 () =
       app (lam (fun x -> x)) (bool true)  (* same as before *)
  let testpowfix () = ...                  (* same as before *)
  let testpowfix7 =                        (* same as before *)
       lam (fun x -> app (app (testpowfix ()) x) (int 7))
end
\end{code}
We instantiate |CPST| with the desired base interpreter~|C|,
then use the result |M| to
interpret object terms. Those terms are \emph{exactly} as before.
Having to textually copy the terms is the
price we pay for this simplified treatment.
Our discussion of self\hyp interpretation in~\S\ref{selfinterp} shows
that this copying is not frivolous but represents plugging a term into
a context, which is one of the many faces of polymorphism.

With 
|CPST| instantiated by the compiler~|C| above,
|T.test1| gives
\begin{code}
.<fun x_5 -> (fun x_2 -> x_2 (fun x_3 x_4 -> x_4 x_3))
             (fun x_6 -> (fun x_1 -> x_1 true)
                         (fun x_7 -> x_6 x_7 x_5))>.
\end{code}
This output is a na\"{\i}ve CPS transformation of $(\fun{x}x)\True$,
containing several apparent $\beta$-redexes.  To reduce these
redexes, we just change~|T| to instantiate |CPST| with |P| instead.
\begin{code}
{P.st = Some <fun>; P.dy = .<fun x_5 -> x_5 true>.}
\end{code}

\subsection{State and imperative features}
\label{state}

\begin{figure}
    \begin{floatrule}
    \begin{proofrules}
        \[ \justifies \deref:t_s \]
        \[ e:t_s \justifies \set e:t_s \]
        \[ e_1:t_1 \quad \[ [x:t_1] \proofoverdots e_2:t_2 \] \justifies \lapp{e_1}{x}{e_2}:t_2 \]
    \end{proofrules}
    \end{floatrule}
    \caption{Extending our typed object language with mutable state of type~$t_s$}
    \label{fig:state}
\end{figure}

We can modify a CBN or CBV CPS transformation to pass a piece of state
along with the continuation. This technique lets us support mutable
state. As Figure~\ref{fig:state} shows, we extend our object language
with three imperative features.
\begin{enumerate}
    \item ``$\deref$'' gets the current state;
    \item ``$\set e$'' sets the state to the value of~$e$ and returns
        the previous value of the state;
    \item the let-form ``$\lapp{e_1}{x}e_2$'' evaluates $e_1$
        before~$e_2$ even if $e_2$ does not use~$x$.
\end{enumerate}
If $x$ does not appear in~$e_2$, then ``$\lapp{e_1}{x}e_2$'' is same as
the more familiar sequencing form ``$e_1;e_2$''.
We can embed this extended object language into OCaml by extending the
|Symantics| signature in Figure~\ref{fig:ocaml}.
\begin{code}
module type SymSI = sig
  include Symantics
  type state
  type 'c states       (* static version of the state *)
  val lapp : (('c,'sa,'da) repr as 'x) -> ('x -> 'y)
             -> (('c,'sb,'db) repr as 'y)
  val deref : unit -> ('c, 'c states, state) repr
  val set   : (('c, 'c states, state) repr as 'x) -> 'x
end
\end{code}
In HOAS\@, we write the term ``$\lapp{e_1}{x}e_2$'' as |lapp e1 (fun x -> e2)|;
the type of |lapp| is that of function application with
the two arguments swapped.  We can encode the term
``$\lapp{\deref}{x} (\set 2;\, x+\deref)$''
as the OCaml functor
\begin{code}
module EXSI_INT(S: SymSI
  with type state = int and type 'c states = int) = struct open S
  let test1 () = lapp (deref ()) (fun x -> 
                  lapp (set (int 2)) (fun _ -> add x (deref ())))
end
\end{code}
The accompanying source code shows several more tests, including
a test for higher-order state and a power function that uses state
as the accumulator.

The state-passing interpreter extends the CBN CPS
interpreter |RCN| of~\S\ref{S:CPS}.
\begin{code}
module RCPS(ST: sig 
  type state 
  type 'c states 
  type ('c,'sv,'dv) repr = 
      {ko: 'w. ('sv -> 'c states -> 'w) -> 'c states -> 'w}
end) = struct
  include ST
  type ('c, 'sv, 'dv) result = 'c states -> 'sv
  ... 
  let lapp e2 e1 = {ko = fun k ->
      e2.ko (fun v -> (app (lam e1) {ko = fun k -> k v}).ko k)}
  let deref () = {ko = fun k s -> k s s}
  let set e = {ko = fun k -> e.ko (fun v s -> k s v)}
  let get_res x = fun s0 -> x.ko (fun v s -> v) s0
end
\end{code}
The implementations of |int|, |app|, |lam|, and so on are
\emph{identical} to those of |RCN| and elided. New are the extended type
|repr|,
which now includes the state, and the functions
|lapp|, |deref|, and |set| representing imperative features. The
interpreter is still CBN, so evaluating |app ef ea| might not
evaluate |ea|, but evaluating |lapp ea ef| always does.
For first-order state, such as of type~$\ZZ$, we 
instantiate the interpreter as
\begin{code}
module RCPSI = RCPS(struct 
  type state = int
  type 'c states = int
  type ('c,'sv,'dv) repr = 
      {ko: 'w. ('sv -> 'c states -> 'w) -> 'c states -> 'w}
end)
\end{code}
If the state has a higher-order type, then the types |state| and |'c states|
are no longer the same, and |'s states| is mutually
recursive with the type |('c,'sv,'dv) repr|, as demonstrated in the
accompanying source code.

Because the |SymSI| signature extends |Symantics|, any encoding of
a term in the pure object language (that is, any functor that takes
a |Symantics| module as argument) can also be used as a term in the
extended object language (for example, applied to an implementation of
|SymSI|).  In particular,
|RCPSI| matches the |Symantics| signature and implements the
unextended object language: we can pass |RCPSI|
to the functor |EX| (Figure~\ref{fig:ocaml-simple}) and run 
the example |test1| from there. The main use for |RCPSI| is to interpret the 
extended object language.
\begin{code}
module EXPSI_INT = EXSI_INT(RCPSI)
let cpsitesti1 = RCPSI.get_res (EXPSI_INT.test1 ()) 100
val cpsitesti1 : int = 102
\end{code}

We reiterate that this implementation adding state and imperative
features is very close to the CPS interpreter and uses no new
techniques.
We can also add mutable references to the object language using
mutable references of the metalanguage, as shown in the accompanying
code.
\fi
\fi

\ifshort\else
\section{Self-interpretation}\label{selfinterp}

We turn to interpreting the object language in the object language, to
clarify how expressive our typed object language can be and to argue that our
partial evaluator is Jones\hyp optimal.

Given an \emph{encoding} of each object term~$e$ as an \emph{object}
term~$\Encode{e}$, a \emph{self\hyp interpreter} is usually defined as
an object function~$\si$ such that any object term~$e$ is
observationally equivalent to the object application $\si\Encode{e}$
\citep{jones-partial,taha-tag,Danvy-tagging-encoding}.  A particular
use of self-interpreters is in defining the notion of optimality of
partial evaluation.  A partial evaluator~$\pe$ maps object terms~$e$
to observationally equivalent object terms~$\pe(e)$.  Recall that
$\si\Encode{e}$ is also observationally equivalent to $e$ but less
efficient (reducing $\si\Encode{e}$ takes more resources). A
partial evaluator is said to be \emph{optimal} with respect to~|si|
\citep{jones-challenging} if the partial evaluator removes all the 
ineffiency in $\si\Encode{e}$ added by the self-interpreter: that is,
for all $e$, $\pe(\si\Encode{e})$ is $\alpha$\hyp
equivalent to~$e$ (or in some accounts, no less efficient than~$e$).

Self\hyp interpretation in our framework is straightforward at the
term level: the functions comprising the interpreters
in~\S\ref{S:interpreter-RL} may as well be written in our object
language, as in Figure~\ref{fig:self-eval}.
\begin{figure}
\begin{align*}
    \ident{int} &= \fun{x} x \\
    \ident{add} &= \fun{x} \fun{y} x+y \\
    \ident{if\_}&= \fun{b} \fun{t} \fun{e} \cond{b}{t\,0}{e\,0}
        \displaybreak[0] \\
    \ident{lam} &= \fun{f} f \\
    \ident{app} &= \fun{f} \fun{x} fx \\
    \ident{fix} &= \fun{g} \fix{f} \fun{x} gfx
\end{align*}
\caption{The \emph{object} functions implementing an
evaluator.  (We use the number~$0$ in lieu of a unit value.)}
\label{fig:self-eval}
\end{figure}
We thus map each object term~$e$ to an object term~$\encode{e}$ as follows.
We call this mapping \emph{pre-encoding}.
\begin{equation}
\begin{split}
    \encode{x} &= x \\
    \encode{n} &= \ident{int}\, n \\
    \encode{\fun{x}e} &= \ident{lam} (\fun{x} \encode{e}) \\
    \encode{e_1 + e_2} &= \ident{add} \encode{e_1} \encode{e_2} \\
    \encode{\cond{b}{t}{e}} &= \rlap{$\ident{if\_} \encode{b}
        \left(\fun{\_}\encode{t}\right) \left(\fun{\_}\encode{e}\right)$} \\
    \encode{fx} &= \ident{app} \encode{f} \encode{x} \\
    \encode{\fix{f}e} &= \ident{fix} (\fun{f} \encode{e})
\end{split}
\end{equation}
The metavariables $x$ and~$n$ stand for a variable and an integer,
respectively.
This pre-encoding is just like how we represent object terms in the
metalanguage in the preceding sections, but it produces
terms in the object language rather than the metalanguage.

To evaluate~$\encode{e}$, then, we
instantiate the free variables in~$\encode{e}$ such as $\ident{int}$,
$\ident{lam}$, and $\ident{add}$ by their definitions given in
Figure~\ref{fig:self-eval}.  For
example, the familiar object term $(\fun{x}x)\True$ pre-encodes to
\begin{equation}
    \encode{(\fun{x}x)\True} = \ident{app}
    (\ident{lam} (\fun{x} x))\, (\ident{bool}\, \True),
\end{equation}
and to evaluate this pre-encoded term is to evaluate the object term
\begin{equation}
    (\fun{f} \fun{x} fx) \,
    ((\fun{f} f) (\fun{x} x))\, ((\fun{b} b) \True).
\end{equation}
Because the evaluator in Figure~\ref{fig:self-eval} mostly consists 
of glorified identity
functions, our simple partial evaluator reduces the
result of this instantiation to~$e$.  In general, to
interpret~$\encode{e}$ using an interpreter is to instantiate its free
variables by that interpreter's definitions.

\subsection{Avoiding higher polymorphism}

Any approach to self\hyp interpretation needs to spell out first how to
encode object terms~$e$ to object terms~$\Encode{e}$, and then how to
interpret~$\Encode{e}$ in the object language.  For our approach, we
want to define encoding in terms of pre-encoding, and interpretation
using some notion of instantiation.  Unfortunately, the simple type
structure of our object language hinders both tasks.  To continue with
the example term above, we could try to define
\begin{equation}
    \Encode{e} =
    \fun{\ident{app}} \fun{\ident{lam}} \fun{\ident{bool}} \encode{e},
\end{equation}
in particular
\begin{equation}
    \Encode{(\fun{x}x)\True} =
    \fun{\ident{app}} \fun{\ident{lam}} \fun{\ident{bool}}
    \ident{app} (\ident{lam} (\fun{x} x))\, (\ident{bool}\, \True).
\end{equation}
To type-check this encoded term, we give the bound variable $\ident{lam}$ the
simple type $(\BB\to\BB)\to\BB\to\BB$.
We then define the self\hyp interpreter
\begin{equation}
    \si = \fun{e} e
    (\fun{f} \fun{x} fx)
    (\fun{f} f)
    (\fun{b} b)
\end{equation}
and apply it to the encoded term.  The result is the object term
\begin{equation}
\kern-\mintagsep
    \bigl(\fun{e} e (\fun{f} \fun{x} fx) (\fun{f} f) (\fun{b} b)\bigr)
    \bigl(
    \fun{\ident{app}} \fun{\ident{lam}} \fun{\ident{bool}}
    \ident{app} (\ident{lam} (\fun{x} x))\, (\ident{bool}\, \True)
    \bigr),
\end{equation}
which partially evaluates to~$\True$ easily.
However, encoding fails on a term with multiple $\lambda$\hyp
abstractions at different types.  For example, the pre-encoding
\begin{equation}
\label{e:pre-encoding-example}
    \encode{\fun{f}\fun{x}fx}
    = \ident{lam} (\fun{f} \ident{lam} (\fun{x} \ident{app} f x))
\end{equation}
does not type-check in any typing environment, because $\ident{lam}$ needs
to take two incompatible types.  In sum, we need more polymorphism in the
object type system to type $\ident{lam}$, $\ident{app}$, $\ident{fix}$,
and~$\ident{if\_}$ (and $\Encode{e}$ and~$\si$).
(The polytypes in |Symantics| given by Haskell's type classes and OCaml's
modules supply this polymorphism.)  Moreover, we need to encode any
polymorphism of the object language \emph{into} the object language to achieve
\emph{self}\hyp interpretation.

\subsection{Introducing let-bound polymorphism}

Instead of adding higher-rank and higher-kind polymorphism to our object
language (along with polymorphism over kinds!), we add let-bound polymorphism.
As usual,
we can add a new typing rule
\begin{equation}
\label{e:let}
    \let\vcenter\vbox
    \begin{prooftree}
        e_1:t_1 \quad \subst{e_2}{x}{e_1}:t_2
        \justifies \be{x=e_1} e_2 : t_2
    \end{prooftree}
    .
\end{equation}
The pre-encoding of a let\hyp expression is trivial.
\begin{align}
    \encode{\be{x=e_1}e_2} \quad &= \quad \be{x=\encode{e_1}} \encode{e_2}
\intertext{A \emph{context} is an object term with a hole~$[~]$.  The
hole may occur under a binder, so plugging a term into the context may
capture free variables of the term.  By pre-encoding a hole to a hole,
we extend pre-encoding from a translation on terms to one on
contexts.}
    \encode{[~]} \quad &= \quad [~]
\end{align}
We define an interpreter in the object language to be not a term but
a context.  For example, the evaluator is the context
\begin{align}
\label{e:evaluator}
    \si[~] &=
    \begin{tabular}[t]{@{}Ml@{}>{{}}Ml@{}Ml@{}}
        \be{\ident{int} &= \fun{x} x&} \\
        \be{\ident{add} &= \fun{x} \fun{y} x+y&} \\
        \be{\ident{if\_}&= \fun{b} \fun{t} \fun{e} \cond{b}{t\,0}{e\,0}&} \\
        \be{\ident{lam} &= \fun{f} f&} \\
        \be{\ident{app} &= \fun{f} \fun{x} fx&} \\
        \be{\ident{fix} &= \fun{g} \fix{f} \fun{x} gfx&} [~],
    \end{tabular}
\intertext{and the length\hyp measurer at the end of~\S\ref{S:interpreter-RL} is the context}
\label{e:length-measurer}
    \mathrm{L}[~] &=
    \begin{tabular}[t]{@{}Ml@{}>{{}}Ml@{}Ml@{}}
        \be{\ident{int} &= \fun{x} 1&} \\
        \be{\ident{add} &= \fun{x} \fun{y} x+y+1&} \\
        \be{\ident{if\_}&= b + t\,0 + e\,0&} \\
        \be{\ident{lam} &= \fun{f} f\,0 + 1&} \\
        \be{\ident{app} &= \fun{f} \fun{x} f + x + 1&} \\
        \be{\ident{fix} &= \fun{g} g\,0 + 1&} [~].
    \end{tabular}
\end{align}
To interpret an object term~$e$ using an interpreter $I[~]$ is to
evaluate the object term~$I[\encode{e}]$.  $\si$~is
a self\hyp interpreter in the following sense.
\begin{proposition}
    $\si[\encode{e}]$ is observationally equivalent to~$e$.
\end{proposition}
As a corollary, we can pre-encode $\si$ itself as
a context: the term $\si[\encode{\si[\encode{e}]}]$ is observationally
equivalent to $\si[\encode{e}]$, and in turn to~$e$.  In other words,
$\si$ can interpret itself.  Our partial evaluator is optimal with respect to
the self\hyp interpreter~$\si$.
\begin{proposition}
    Let $\pe$ be the partial evaluator~|P| in~\S\ref{S:PE-solution}.
    Then the object terms $\pe(\si[\encode{e}])$ and~$\pe(e)$ are
    either both undefined or both defined and
    equal up to $\alpha$\hyp conversion.
\end{proposition}

\subsection{Contexts clarify polymorphism}
\label{S:clarify}

We always type-check a pre-encoded term~$\encode{e}$ in the context of
a particular interpreter~$I[~]$, never alone.  For example, to
type-check the pre-encoded term~\eqref{e:pre-encoding-example}, we must
plug it into an interpreter, such as the evaluator~\eqref{e:evaluator}.
This treatment has the drawback that we must duplicate the pre-encoding
of a term in order to interpret it in multiple ways, that is, to plug it
into multiple interpreters such as the evaluator~\eqref{e:evaluator} and
the length\hyp measurer~\eqref{e:length-measurer}.  In return, we avoid
adding polymorphism to the object language's type system, because we can
state the let rule~\eqref{e:let} in terms of substitution rather than by
generalizing and instantiating types.  In other words, we use contexts
and plugging in the object language in place of the type-class and
module machinery in the metalanguages.

In the presence of let-bound polymorphism, we can understand a term
waiting to be plugged into a context as a higher-rank and higher-kind
abstraction over the context.  Even though our object language does not support
higher abstraction, our metalanguages do, so they can type-check an object term
separately from its interpreter---either as a functor from a |Symantics| module
containing a type constructor
(in OCaml), or a value with a |Symantics| constraint over a type
constructor (in Haskell).  Thus,
``context'' is a euphemism for a polymorphic argument, and ``plugging''
is a euphemism for application.

\begin{comment}
\jacques{But how 
do you create, in either Haskell or MetaOCaml, an untypechecked 
interpreter-with-a-hole [UIH] ?}
\oleg{Well, one can make an argument that we already have such an
interpreter with polymorphic let and the hole: incope. In Haskell, the
declaration of an instance of Symantics is like the sequence of
polymorphic lets. We construct terms where lam, add, etc, are free
variables. We apply the interpreter to the semantics (plug the hole)
by instantiating these terms (binding the free variables lam, etc. to
the particular instance of Symantics). The unRR construction does
this plugging in explicitly.}
Again, what is different from the above is that we can
typecheck terms separately, without inserting them first within the
hole of a particular interpreter. Rank-2 type of |repr| helps. It lets
enough of the type information out so the typechecking can
proceed. So, |repr| is the representation of the polymorphic
interpreter context with the hole, which permits separately
typecheckable terms (the evaluation still entails `duplication' so to
speak -- which is one way how polymorphism is resolved).

\oleg{Mention the RR interpreter: for any term E, (RR E) is equivalent to E.
RR is not an identity: it is an interpreter that encapsulates another
interpreter. The RR interpreter can be made self if we treat RR as a
special form and interpret it always with itself (similar to let and
hole below).}
\end{comment}

\begin{comment}

The crucial role of the higher-order type parameter r

The type constructor "r" above represents a particular interpreter.  The
meta-type "r tau" hides how the interpreter represents the object type
"tau" yet exposes enough of the type information so we can type-check
the encoding of an object term without knowing what "r" is.  The checked
term is then well-typed in any interpreter.  Each instance of Symantics
instantiates "r" to interpret terms in a particular way. The L
interpreter is quite illustrative. We need the above semantics to be
able to represent both R and L (the latter returns only Int as the
values) in the same framework.

We encode a term like |add 1 2| as
\texttt{app \_add (app \_int 1) (app \_int 2)} where |_add| and |_int| are just
`free variables'. Now, how to typecheck such a term? Some type should
be assigned to these free variables. The goal is to complete the work
without needing any type annotations (so we don't have to introduce any
type language), with all types inferred and all terms typed. It seems
the second-order type R neatly separates the typechecking part from
the representation of R: it hides aspects that depend on the
particular interpreter, and yet lets enough type information through
(via its type argument) to permit the typechecking of terms, and infer
all the types. 



The only approach that does seem to work
is the one in incope.hs or incope.ml. If we de-sugar away records and
type-classes, the type of a term L of the inferred type tau is
$$ 
  (\ZZ \rightarrow r \ZZ) \rightarrow
  (\BB \rightarrow r \BB) \rightarrow
  \forall \alpha \beta. (r \alpha \rightarrow r \beta)
      \rightarrow r (\alpha\rightarrow\beta) \rightarrow ... r \tau
$$
% (Int -> r Int) ->
% (Bool -> r Bool) ->
% (forall alpha beta. (r alpha -> r beta) -> r (alpha->beta)) -> ... r tau

or, if we denote the sequence of initial arguments as |S r|, terms have
the type |S r -> r tau|
The interpreter has the type
|(forall r. S r -> r tau) -> r' tau|

The higher-order type (variable) of kind |*->*| seems essential. So, at
least we need some fragment of Fw (somehow our OCaml code manages to
avoid the full Fw; probably because the module language is separated
from the term language). Thus, we seem to need a fragment of Fw. It
seems the inference is possible, as our Haskell and OCaml code
constructively illustrates. Perhaps we need to characterize our
fragment.

\end{comment}
\fi

\section{Related work}\label{related}

\ifshort
Our initial motivation came from several papers 
\citep{WalidICFP02,taha-tag,xi-guarded,peyton-jones-simple}
that use embedded interpreters to justify advanced
type systems, in particular GADTs.
\else
Our initial motivation came from several papers that justify advanced
type systems, in particular GADTs, by embedded interpreters
\citep{WalidICFP02,taha-tag,xi-guarded,peyton-jones-simple} and
CPS transformations \citep{Guillemette-Monier-PLPV,shao-type-toplas,chen-typeful}.
\fi
We admire all this technical machinery, but
these motivating examples do not need it.
Although GADTs may indeed be simpler and more flexible, they are
unavailable in mainstream ML, and their implementation in GHC
6.6.1 fails to
detect exhaustive pattern matching.  We also wanted to find the minimal
set of widespread language features needed for tagless
type-preserving interpretation.

Even a simply typed $\lambda$-calculus obviously supports self\hyp
interpretation, provided we use universal types \citep{taha-tag}.  The
ensuing tagging overhead motivated \citet{Makholm-TagElim,taha-tag} 
to propose tag
elimination, which however does not statically guarantee that all tags
will be removed \citep{WalidICFP02}.

\Citet{WalidICFP02}, \citet{taha-tag}, \citet{xi-guarded}, and
\citet{peyton-jones-simple} seem to argue as follows that a self\hyp
interpreter of a typed language cannot be tagless or Jones\hyp optimal:
\begin{shortlist}
\item One needs to encode a typed language in a typed language based on
a sum type (at some level of the hierarchy)\\
\item A \emph{direct} interpreter 
for such an encoding of a typed language
in a typed language requires either
advanced types or tagging overhead\\
\item Thus, an indirect interpreter is necessary, which needs a universal
  type and hence tagging\ifshort\else\\
\item Thus, any self-interpreter must have tags and cannot be 
  Jones-optimal\fi.
\end{shortlist}
While the logic is sound, we (following \citet{yang-encoding}) showed that the
first step's premise is not valid.

\citet{Danvy-tagging-encoding} discuss Jones optimality at length and
apply HOAS to typed self\hyp interpretation.  However, their source
language is untyped.  Therefore, their object\hyp term encoding has
tags, and their interpreter can raise run-time errors.
Nevertheless, HOAS lets the partial
evaluator remove all the tags. In contrast, our object encoding and
interpreters do not have tags to start with and obviously cannot
raise run-time errors.

Our partial evaluator establishes a bijection |static| between static
and dynamic types (the valid values of |'sv| and |'dv|), and between
static and dynamic terms.  It is customary to implement such a bijection
using an injection\hyp projection pair, as done for interpreters
\ifshort \citep{Ramsey-ML-module-mania,Benton-embedded-interpreters}\else
by \citet{Ramsey-ML-module-mania} and \citet{Benton-embedded-interpreters}\fi,
partial evaluation \ifshort \citep{Danvy-TDPE}\else by \citet{Danvy-TDPE}\fi,
and type-level functions \ifshort \citep{oliveira-typecase}\else by
\citet{oliveira-typecase}\fi.  As explained in~\S\ref{S:PE-solution}, we
avoid injection and projection at the type level by adding an argument
to |repr|.
Our solution could have been even more straightforward if MetaOCaml
provided total type-level functions such as |static| in
\S\ref{S:PE-solution}---simple type-level computations 
ought to become mainstream.

Our separation between the |Symantics| interface and its many
implementations codifies the common practice of implementing an embedded
DSL by specifying an abstract syntax of object\hyp language pervasives,
such as addition and application, then providing multiple
interpretations of them.  \Citet{JonesNielsen-D58} prefigured this
separation when they decomposed a denotational definition of an untyped
object language into a core semantics (which we call abstract syntax)
and multiple interpretations.  When implementing an embedded DSL in this
way, it is also common practice to use phantom types to rule out
ill-typed object terms, as done in Lava
\citep{Lava} and by \citet{Rhiger-thesis}. However, these two approaches
are not tagless because they still use universal types, such as Lava's
\texttt{Bit} and \texttt{NumSig}, and Rhiger's \texttt{Raw} (his Figure~2.2)
and \texttt{Term} (his Chap.~3), which incur the attendant overhead of
pattern matching.  The universal type also
greatly complicates the soundness and completeness proofs of embedding
\citep{Rhiger-thesis}, whereas our proofs are trivial.
Rhiger's approach does not support typed CPS transformation (his~\S3.3.4).
\begin{comment}
Rhiger's But Fig 2.2, p33: universal type Raw.  He uses phantom type
upon the Exp datatype. But that is cheating: phantom type means
essentially we can easily do coerce. We use real types.  That's why he
had to do tedious proofs in Sec 2 of soundness and completeness of
embedding. Whereas our proofs are obvious.  His sec 3 is based on data
representation of terms. They have type tags.  We do nothing of that
kind: See Sec 3.1.2. See numerous "data Term" in Sec3, which is the U
type.  In Sec 3.3.4 (p76) Rhiger specifically says that his encoding
cannot do typed CPS transformation -- whereas our does. BTW, Rhiger
thesis contains the definitions of the interpreter and the compiler,
in the beginning. Use this in response to Rev1)
\end{comment}


We are not the first to implement a typed interpreter for a typed
language.  \Citet{laod93} use type classes to implement a metacircular
interpreter (rather than a self\hyp interpreter) of a
typed version of the SK language, which is quite different from our
object language.  Their interpreter
appears to be tagless, but they could not have implemented a
compiler or partial evaluator in the same way, since they rely
heavily on injection\hyp projection pairs.

% The following paragraph was not in the version submitted to APLAS,
% yet was not commented out.  Of course, if we had space, we should add
% this, but it is difficult to see how.
\ifshort\else
Using Haskell, \citet{Guillemette-Monier-PLPV} implement a CPS transformation
for HOAS terms and statically assure that it preserves object types.
They represent proofs of type preservation as terms of a GADT, which is not
sound (as they admit in \S4.2) without a separate totality check because
any type is trivially inhabited by a nonterminating term in Haskell.
In contrast, our CPS transformations use simpler types than GADTs and
assure type preservation at the (terminating) type level rather than
the term level of the metalanguage.
\Citeauthor{Guillemette-Monier-PLPV} review other
type\hyp preserving CPS transformations (mainly in the context of typed intermediate
languages), in particular
\citets{shao-type-toplas} and \citets{chen-typeful}.
These approaches use de Bruijn indices and fancier
type systems with type-level functions, GADTs, or type\hyp equality
proofs.
\fi


We encode terms in elimination form, as a coalgebraic structure.
\Citet{Pfenning-Lee} first described this basic idea and applied it to
metacircular interpretation.
Our approach, however, can be implemented in mainstream ML and supports
type inference, typed CPS transformation and partial evaluation. In contrast,
\citeauthor{Pfenning-Lee} conclude that partial evaluation and program
transformations ``do not seem to be expressible'' even using their
extension to~$F_\omega$, perhaps because their avoidance of general
recursive types compels them to include the polymorphic lift that we
avoid in~\S\ref{S:PE-lift}.
\begin{comment}
It seems that Pfenning and Lee embed $F_2$ with type constructions in 
(pure) $F_3$.  We embed $F_1$ in (weak?) $F_2$, as I see it.  In a way, what 
we do is very similar to what they do (Figure 1, p.152), except that we 
do it in standard programming languages.  It is unclear if their work can 
be implemented (yet) in any language.  And we preserve type-inference, 
while their solution needs explicit types!
The following line of their conclusion is worth citing: "... this does 
not imply that the same language is also suitable for type 
metaprogramming. ... such as partial evaluation... do not seem to be 
expressible".
I suspect you're right, but I'm still reading the paper.  See also page
146: "for a term M in $F_1$ (a simply-typed term), the representation
$\bar{M}$ will be in $F_2$".  The move from $F_2$ to $F_3$ 
and beyond reminds me
strongly of our attempts at self-interpretation without the notion of a
syntactic hole.
\end{comment}

Our encoding of the type function |static| in \S\ref{S:PE-solution}
emulates type-indexed types and is related to intensional type analysis
\citep{Morrisett-intensional,Generic-Haskell}. However, our object
language and running examples in HOAS include |fix|,
which intensional type analysis cannot handle
\citep{xi-guarded}.


We could not find work that establishes that
the \emph{typed} $\lambda$-calculus has a final coalgebra structure.
\ifshort
(See \Citet{honsell99coinductive} for the untyped case.)
\else
\Citet{HonsellLenisa,honsell99coinductive}
investigate the untyped $\lambda$-calculus
along this line.  
In particular, they use
contexts with a hole \citep[p.\,13]{honsell99coinductive} to define
\emph{observational equivalence}
(see our~\S\ref{selfinterp}).
\citearound{'s bibliography}\Citet{honsell99coinductive} refers to the
foundational work in this important area.  
Particularly intriguing is the link to the
coinductive aspects of B\"{o}hm trees, as pointed out by
\citet{berarducci-models} and Jacobs \citeyearpar[Example 4.3.4]{jacobs-coalgebra}.
\fi

\ifshort We observe that \else As \S\ref{S:clarify} observes, \fi
higher-rank and higher-kind
polymorphism lets us type-check and compile object terms separately from
interpreters.  This \ifshort\else observation \fi is consistent with the role of
polymorphism in the separate compilation of modules
\citep{shao-typed}.

\section{Conclusions}\label{conclusion}

We solve the problem of embedding a typed object language in a typed
metalanguage without using GADTs, dependent types, or a universal type.
Our family of interpreters includes an evaluator, a compiler, a partial
evaluator, and CPS transformers.  It is patent that they never get stuck,
because we represent object types as metalanguage types.  This work
makes it safer and more efficient to embed DSLs
in practical metalanguages such as Haskell and ML\@.

Our main idea is to represent object programs not in an initial algebra
but using the existing coalgebraic structure of the $\lambda$-calculus.
More generally, to squeeze more invariants out of a type system as
simple as Hindley-Milner, we shift the burden of representation and
computation from consumers to producers: encoding object terms as calls
to metalanguage functions (\S\ref{ourapproach}); build dynamic terms
alongside static ones (\S\ref{S:PE-lift}); simulating type functions for
partial evaluation (\S\ref{S:PE-solution}) and CPS
transformation\ifshort\else~(\S\ref{S:CPS})\fi.
This shift also underlies fusion,
functionalization, and amortized complexity analysis.
\ifshort\else
When the metalanguage does provide higher-rank and higher-kind
polymorphism, we can type-check and compile an object term separately
from any interpreters it may be plugged into.
\fi
