First reviewer's review

This paper is about the problem of building tagless staged
interpreters for typed languages. This is a long-standing issue in
interpretation, metaprogramming and type systems. Tagless interpreters
for simply-typed languages are a standard example in work on GADTs,
dependently typed languages, metaprogramming systems and so on. The
authors claim to have solved this problem without any fancy type
trickery by using "cogen functions rather than data constructors" and
"by representing terms not in an initial algebra but using the final
coalgebraic structure of the lambda calculus".

Whilst I do understand the sense in which the above claims are
valid-ish (Church encodings, double-negation, whatever), it doesn't
really amount to a solution to the original problem. Looking at
section 1.3 I see a compiler, not an interpreter. Or in other
language, the solution here is to replace a deep embedding (an
interpreter) with a shallow embedding (compiling the object language
into the metalanguage). Section 6 calls identity functions "self
interpretation" and calls the translation (compilation) of the
metalanguage "pre-encoding", which is, erm, cheeky.

Furthermore, of course, shallow embeddings of this kind are not
exactly new. Even the idea of having multiple interpretations of the
pervasives of a standard language (as in the Symantics structure) has
been exploited by many (see e.g. the Lava and Hawk work, Augustsson's
clever two-level re-interpretation of Haskell (to generate residual
functions in Excel (!)), Rhiger's thesis, and many DSLs. Some of these
tricks are pretty neat, but I don't think there's enough originality
for an ICFP paper.



Second reviewer's review

This is a nice paper. I enjoyed reading it. 

It's an important issue, the tagging problem, and the authors present
a nice approach. I think this issue should be of interest to the
general FP audience and this paper makes interesting and fairly
comprehensible contributions. Even to FPers that are not directly
interested in interpreters or partial evaluators, this paper presents
some interesting techniques. The sub-communities interested in typed
functional languages and partial evaluation have not historically
payed very much attention to each other. It would be good to get this
presented to a general FP audience and hopefully elicit a bit more
interest in the cross-over of these two topics of partial evaluation
in modern HM-typed languages.


If there is any room for improvement in the presentation it is in
trying to explain to the FPers who are not quite so familiar with
partial evaluation (and many are not) what the problem with tags is,
why it's a problem in typed but not untyped languages and how it's a
barrier to building realistic partial evaluators. You could make it
sound a little more exciting, "interpreting a typed object language in
a typed metalanguage" isn't just an interesting problem! It's also
pretty much essential for building partial evaluators for our nice
typed languages, and we should really want realistic partial
evaluators for our languages as they provide some many opportunities
for writing clearer or faster programs.

Another minor presentation thing, in some of the code snippets, not
all of the function/variable/constructor names were immediately
obvious to me. If space allows, 3 letter var names are much more
obvious than 1 letter ones, for example, "A" vs "App".

Using both Haskell and OCaml examples is a nice touch, not just
because it demonstrates your point about not using any especially
advanced type system features but also just because it'll help readers
who are more familiar with one language than the other.

I do like the embedding of the type of the object language into the
host language giving you the soundness proof (Proposition 3) just in
terms of the soundness of the host language's type system. That's very
nice.

I'm not quite sure the expression size example is worth the space it
takes up. Finding the size of the divergent expression isn't very
surprising. I suppose one could worry that the construction of the ast
(parameterised over the symantics) is necessarily recursive for fix
and this size example demonstrates that it is not, but I never had
that worry.

For the staging facility for Haskell you emulate it via a ByteCode
GADT. I was rather hoping it could have been emulated via
TemplateHaskell. I realise TH is untyped and a compile-time staging
system. The claim would have been that the TH code produces will
always be type correct. We could still map the typed ByteCode data
type to untyped TH abstract syntax. That would provide a nice
practical way for Haskell programmers to use the bits of code
generated by the compiler and partial evaluator. I look forward to
trying this out with your full code when the review period is over.

I like the presentation of the partial evaluator via a sequence of
attempts. I'm sure this is easier to understand than a direct
presentation of the final solution.

The section on self-interpretation is relatively comprehensible on a
second reading. I'm afraid I have no concrete suggestions on how to
make this more immediately comprehensible. It would be nice to have a
simple characterisation of what type system features of the host are
needed to encode particular type system features of the object
language.


Third reviewer's review

This paper describes some fancy type-programming, observing that for
certain applications, dependent types or GADTs are not necessary. In
particular, it uses a Church-like encoding for the venerable "term"
GADT and give several examples of functions defined with this
encoding. (I.e. typed partial evaluation and CPS transformation.)

As an example of pushing the limits of existing type-systems, this
paper is great. It is a fun paper to read.

Unfortunately, the basic idea of this paper (the encoding of the term
GADT as its elimination form, i.e. as a coalgebraic structure) is not
new to this work. It appeared many years ago in: Metacircularity in
the polymorphic lambda-calculus, Frank Pfenning and Peter Lee.
Theoretical Computer Science 89 (1991) 137-159. (Other encodings of
GADTs have appeared since Pfenning and Lee's work, for example, in
work on generic programming.)

Furthermore, I am not convinced that this paper provides a solution
for practical language design. It is not clear that working with
these encodings is as efficient as working with a GADTs, yet that is
the purpose of the tagless interpreter. Also, GADTs are simply more
flexible and easier to use. This representation limited to primitive
recursive folds over the datatype (as that is the elimination form
provided.) That means that some operations are easy implement
(interpretation, size calculation, etc.), some can be done with effort
(one-pass cps, and other mutually recursive functions), and perhaps
some cannot be implemented at all (those that are not primitive
recursive). For example, can you implement a transformation that
eliminates eta-expansions from a term?

SPECIFIC COMMENTS

Type-indexed types have been around since at least Harper &
Morrisett's Compiling Polymorphism Using Intensional Type Analysis,
POPL 1995. They also were supported by Generic Haskell (Hinze,
Juering, Loeh, Type Indexed Datatypes, SCP 2004).

In 4.3, please carefully distinguish the limitation of GHC's
implementation of GADTs from the type theory. The pattern match in 4.3
is statically exhaustive, and can be shown so in other systems. If
this code were implemented using inductive families Coq, for example,
the user would be able to (and in fact required) to prove that the
other cases could not occur.

"Alas, the type function we need is not identical to repr_pe, so we
need to add another type argument to repr in the Semantics signature."
This continual modification of your framework is disturbing. Is there a
general case that parameterizes the type by three types---the case
for int, the case for bool and the case for arrow?



